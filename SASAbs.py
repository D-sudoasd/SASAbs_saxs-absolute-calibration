import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import argparse
import sys
import numpy as np
import fabio
import pyFAI
import matplotlib
matplotlib.use("TkAgg")
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.figure import Figure
from pathlib import Path
import traceback
import math
import pandas as pd
import datetime
import re
import json
import concurrent.futures
import threading
from types import SimpleNamespace

try:
    from saxs_ui_kit import apply_ios_theme, promote_primary_buttons, toggle_theme, ToolTip
except Exception:
    def apply_ios_theme(root):
        return None

    def promote_primary_buttons(root):
        return None

    def toggle_theme(root):
        return None

    class ToolTip:
        def __init__(self, widget, text):
            self.widget = widget
            self.text = text

try:
    from saxs_core import load_session, session_geometry
except Exception:
    def load_session(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)

    def session_geometry(session_payload):
        if not isinstance(session_payload, dict):
            return {}
        geom = session_payload.get("geometry", {})
        return geom if isinstance(geom, dict) else {}

try:
    import saxs_mpl_style
except Exception:
    class _SaxsMplStyleFallback:
        @staticmethod
        def apply_nature_style():
            return None

    saxs_mpl_style = _SaxsMplStyleFallback()

_SRC_DIR = Path(__file__).resolve().parent / "src"
if _SRC_DIR.exists() and str(_SRC_DIR) not in sys.path:
    sys.path.insert(0, str(_SRC_DIR))

try:
    from saxsabs.core.calibration import estimate_k_factor_robust
except Exception:
    estimate_k_factor_robust = None

# --- ç‰©ç†å¸¸æ•° ---
NIST_SRM3600_DATA = np.array([
    [0.008, 35.0], [0.010, 34.2], [0.020, 30.8], [0.030, 28.8], 
    [0.040, 27.5], [0.050, 26.8], [0.060, 26.3], [0.080, 25.4], 
    [0.100, 23.6], [0.120, 20.8], [0.150, 15.8], [0.180, 10.9],
    [0.200, 8.4],  [0.220, 6.5],  [0.250, 4.2]
])

# 30 keV ä¼°ç®—å€¼
XCOM_30KEV = {
    "Ti": 1.17, "V": 1.54, "Al": 0.11, "Nb": 7.56, "Zr": 7.15,
    "Sn": 11.23, "Mo": 6.05, "Fe": 2.26, "Ni": 3.01, "Cr": 1.58, "Cu": 3.44
}

FLOAT_PATTERN = re.compile(r"[-+]?\d*\.?\d+(?:[eE][-+]?\d+)?")
HC_KEV_A = 12.398419843320025  # E(keV) * lambda(A)
MONITOR_NORM_MODES = ("rate", "integrated")

class BL19B2_RobustApp:
    def __init__(self, root):
        self.root = root
        self.root.title("BL19B2 SAXS Workstation v8.1 (Error Bars)")
        self.root.geometry("1280x900")
        
        # Apply Nature style globally
        saxs_mpl_style.apply_nature_style()
        
        self.set_style()
        self._tooltips = []
        
        # Top bar for theme toggle
        top_bar = ttk.Frame(self.root)
        top_bar.pack(fill="x", padx=10, pady=(10, 0))
        top_bar.columnconfigure(0, weight=1)
        ttk.Label(top_bar, text="SAXS Absolute Intensity Calibration", style="Title.TLabel").grid(row=0, column=0, sticky="w")
        ttk.Button(top_bar, text="ğŸŒ“ åˆ‡æ¢æ·±è‰²/æµ…è‰²æ¨¡å¼", command=lambda: toggle_theme(self.root)).grid(row=0, column=1, sticky="e")
        
        # === å…¨å±€å…±äº«çŠ¶æ€ ===
        self.global_vars = {
            "k_factor": tk.DoubleVar(value=1.0),
            "poni_path": tk.StringVar(),
            "bg_path": tk.StringVar(),
            "dark_path": tk.StringVar(),
            "bg_exp": tk.DoubleVar(value=1.0),
            "bg_i0": tk.DoubleVar(value=1.0),
            "bg_t": tk.DoubleVar(value=1.0),
            "monitor_mode": tk.StringVar(value="rate"),
            "apply_solid_angle": tk.BooleanVar(value=True),
            "k_solid_angle": tk.StringVar(value="unknown"),
        }
        self.session_geometry_fallback = {}

        # === å¸ƒå±€ ===
        self.nb = ttk.Notebook(root)
        self.nb.pack(expand=1, fill="both")

        self.tab1 = ttk.Frame(self.nb)
        self.tab2 = ttk.Frame(self.nb)
        self.tab3 = ttk.Frame(self.nb)
        self.tab_help = ttk.Frame(self.nb)

        self.nb.add(self.tab1, text="1. K-Factor Calibration (ç¨³å¥æ ‡å®š)")
        self.nb.add(self.tab2, text="2. Batch Processing (2Dè¿ç®—+è¯¯å·®æ£’)")
        self.nb.add(self.tab3, text="3. External 1D -> Abs")
        self.nb.add(self.tab_help, text="4. Help (æ–°æ‰‹æŒ‡å—)")

        self.init_tab1_k_calc()
        self.init_tab2_batch()
        self.init_tab3_external_1d()
        self.init_tab_help()
        promote_primary_buttons(self.root)

    def set_style(self):
        apply_ios_theme(self.root)
        style = ttk.Style()
        try: style.theme_use("clam")
        except: pass
        style.configure("Bold.TLabel", font=("Segoe UI", 9, "bold"))
        style.configure("Title.TLabel", font=("Segoe UI", 11, "bold"), foreground="#2c3e50")
        style.configure("Group.TLabelframe.Label", font=("Segoe UI", 9, "bold"), foreground="#2980b9")
        style.configure("Hint.TLabel", font=("Segoe UI", 8), foreground="#4f5b66")

    def add_tooltip(self, widget, text):
        if widget is None or not text:
            return
        self._tooltips.append(ToolTip(widget, text))

    def add_hint(self, parent, text, wraplength=420):
        lbl = ttk.Label(parent, text=f"æ³¨é‡Š: {text}", style="Hint.TLabel", justify="left", wraplength=wraplength)
        lbl.pack(fill="x", padx=3, pady=(1, 3))
        return lbl

    # =========================================================================
    # æ ¸å¿ƒè§£æå™¨
    # =========================================================================
    def _norm_key(self, key):
        return str(key).strip().lower().replace("_", "").replace(" ", "")

    def _extract_float(self, value):
        if value is None:
            return None
        if isinstance(value, (int, float, np.number)):
            return float(value)

        s = str(value).strip()
        if not s:
            return None

        # æ”¯æŒæ¬§æ´²å°æ•°é€—å·ï¼Œé¿å… "0,85" æ— æ³•è§£æ
        if "," in s and "." not in s:
            s = s.replace(",", ".")
        else:
            s = s.replace(",", "")

        m = FLOAT_PATTERN.search(s)
        if not m:
            return None
        try:
            return float(m.group(0))
        except Exception:
            return None

    def _normalize_transmission(self, trans, raw=None, key=None):
        if trans is None:
            return None
        t = float(trans)
        raw_s = str(raw).strip().lower() if raw is not None else ""
        key_s = self._norm_key(key) if key is not None else ""

        # é€è¿‡ç‡å½’ä¸€åŒ–ç­–ç•¥ï¼š
        # 1) æ˜ç¡®ç™¾åˆ†å·/percent/pct -> æŒ‰ç™¾åˆ†æ•°å¤„ç†
        # 2) 1.0~2.0 è§†ä¸ºè½»å¾®æ¼‚ç§»ï¼Œå¤¹ç´§åˆ° 1.0ï¼ˆé¿å…æŠŠ 1.25 è¯¯åˆ¤æˆ 1.25%ï¼‰
        # 3) 2.0~100 è§†ä½œç™¾åˆ†æ•°å­—é¢é‡ï¼ˆå¦‚ 85 -> 0.85ï¼‰
        has_pct_hint = (
            "%" in raw_s
            or "percent" in raw_s
            or "pct" in raw_s
            or "percent" in key_s
            or "pct" in key_s
        )
        if has_pct_hint:
            t /= 100.0
        elif 1.0 < t <= 2.0:
            # ç§»é™¤æ¿€è¿›æˆªæ–­ï¼Œä¿ç•™ç‰©ç†çœŸå®æ€§
            pass
        elif 2.0 < t <= 100.0:
            t /= 100.0
        return t

    def _assert_same_shape(self, a, b, a_name, b_name):
        if a.shape != b.shape:
            raise ValueError(f"Shape mismatch: {a_name}{a.shape} vs {b_name}{b.shape}")

    def get_monitor_mode(self):
        mode = str(self.global_vars["monitor_mode"].get()).strip().lower()
        if mode not in MONITOR_NORM_MODES:
            raise ValueError(f"I0 å½’ä¸€åŒ–æ¨¡å¼ä»…æ”¯æŒ: {', '.join(MONITOR_NORM_MODES)}")
        return mode

    def monitor_norm_formula(self, mode):
        if mode == "rate":
            return "exp * I0 * T"
        if mode == "integrated":
            return "I0 * T"
        raise ValueError(f"æœªçŸ¥ I0 å½’ä¸€åŒ–æ¨¡å¼: {mode}")

    def compute_norm_factor(self, exp, mon, trans, mode):
        if mon is None or trans is None:
            return np.nan
        try:
            mon_v = float(mon)
            trans_v = float(trans)
        except Exception:
            return np.nan

        if not (np.isfinite(mon_v) and np.isfinite(trans_v)):
            return np.nan
        if mon_v <= 0 or trans_v <= 0:
            return np.nan

        if mode == "rate":
            if exp is None:
                return np.nan
            try:
                exp_v = float(exp)
            except Exception:
                return np.nan
            if not np.isfinite(exp_v) or exp_v <= 0:
                return np.nan
            return exp_v * mon_v * trans_v

        if mode == "integrated":
            return mon_v * trans_v

        raise ValueError(f"æœªçŸ¥ I0 å½’ä¸€åŒ–æ¨¡å¼: {mode}")

    def parse_header(self, filepath, header_dict=None):
        meta = {}

        def add_meta(k, v):
            if k is None or v is None:
                return
            nk = self._norm_key(k)
            if nk:
                meta[nk] = str(v).strip()

        exp_keys = ["exposuretime", "counttime", "acqtime", "exposure", "time"]
        mon_keys = ["monitor", "beammonitor", "ionchamber", "mon", "i0", "flux"]
        trans_keys = ["sampletransmission", "transmission", "trans", "abs"]
        exp_exact_only = {"time"}
        mon_exact_only = {"mon", "i0"}
        trans_exact_only = {"abs"}

        def get_val(keys, exact_only=None):
            exact_only = set(exact_only or [])
            # 1) exact
            for k in keys:
                if k in meta:
                    return meta[k], k

            # 2) prefix/suffixï¼ˆé¿å…é€šé… contains è¯¯å‘½ä¸­ï¼‰
            for mk, mv in meta.items():
                for k in keys:
                    if k in exact_only:
                        continue
                    if mk.startswith(k) or mk.endswith(k):
                        return mv, mk

            # 3) contains ä»…ç”¨äºè¾ƒé•¿å…³é”®å­—
            for mk, mv in meta.items():
                for k in keys:
                    if k in exact_only or len(k) < 6:
                        continue
                    if k in mk:
                        return mv, mk
            return None, None

        def has_keys():
            exp_raw, _ = get_val(exp_keys, exact_only=exp_exact_only)
            mon_raw, _ = get_val(mon_keys, exact_only=mon_exact_only)
            trans_raw, _ = get_val(trans_keys, exact_only=trans_exact_only)
            return (exp_raw is not None) and (mon_raw is not None) and (trans_raw is not None)

        # ä¼˜å…ˆè¯»å– FabIO headerï¼ˆå¯¹ tiff/edf æ›´ç¨³å¥ï¼‰
        need_text_fallback = True
        if header_dict is not None:
            for k, v in header_dict.items():
                add_meta(k, v)
            need_text_fallback = not has_keys()
        else:
            try:
                img = fabio.open(filepath)
                for k, v in getattr(img, "header", {}).items():
                    add_meta(k, v)
                need_text_fallback = not has_keys()
            except Exception:
                need_text_fallback = True

        # å›é€€ï¼šä»æ–‡ä»¶æ–‡æœ¬å¤´æå–
        if need_text_fallback:
            try:
                with open(filepath, "rb") as f:
                    head_bytes = f.read(65536)
                # æŸäº› TIFF å¤´å­—æ®µç”± NUL åˆ†éš”ï¼Œå…ˆæ›¿æ¢å¯é™ä½é”®å€¼ç²˜è¿é£é™©
                head_str = head_bytes.decode("utf-8", errors="ignore").replace("\x00", "\n")
                for line in head_str.splitlines():
                    line = line.strip().lstrip("#").strip()
                    if not line:
                        continue
                    parts = []
                    if "=" in line:
                        parts = line.split("=", 1)
                    elif ":" in line:
                        parts = line.split(":", 1)
                    else:
                        parts = line.split(None, 1)
                    if len(parts) == 2:
                        k = str(parts[0]).strip()
                        # é™åˆ¶ key å½¢æ€ï¼Œé™ä½ä»äºŒè¿›åˆ¶å™ªå£°ä¸­è¯¯è§£æçš„æ¦‚ç‡
                        if not re.match(r"^[A-Za-z_][A-Za-z0-9_\- ]{0,64}$", k):
                            continue
                        add_meta(k, parts[1])
            except Exception:
                pass

        exp_raw, exp_key = get_val(exp_keys, exact_only=exp_exact_only)
        mon_raw, _ = get_val(mon_keys, exact_only=mon_exact_only)
        trans_raw, trans_key = get_val(trans_keys, exact_only=trans_exact_only)

        exp = self._extract_float(exp_raw)
        mon = self._extract_float(mon_raw)
        trans = self._extract_float(trans_raw)

        # æ—¶é—´å•ä½å…¼å®¹ï¼šms/us è‡ªåŠ¨è½¬ä¸ºç§’
        if exp is not None:
            exp_tag = f"{exp_key or ''} {exp_raw or ''}".lower()
            if "ms" in exp_tag:
                exp /= 1000.0
            elif "us" in exp_tag:
                exp /= 1_000_000.0

        trans = self._normalize_transmission(trans, raw=trans_raw, key=trans_key)
        return exp, mon, trans

    def normalize_header_dict(self, header_dict):
        meta = {}
        if not header_dict:
            return meta
        for k, v in header_dict.items():
            nk = self._norm_key(k)
            if nk:
                meta[nk] = str(v).strip()
        return meta

    def meta_get_raw(self, meta, keys):
        for k in keys:
            if k in meta:
                return meta[k], k
        for mk, mv in meta.items():
            for k in keys:
                if k in mk:
                    return mv, mk
        return None, None

    def value_with_unit_to_si(self, raw, target):
        val = self._extract_float(raw)
        if val is None:
            return None
        s = str(raw).lower() if raw is not None else ""

        if target == "distance_m":
            if "mm" in s:
                return val / 1000.0
            if "cm" in s:
                return val / 100.0
            if "um" in s or "micron" in s:
                return val / 1_000_000.0
            if "nm" in s:
                return val / 1_000_000_000.0
            if " m" in f" {s}" or s.endswith("m"):
                return val
            if val > 20:
                return val / 1000.0
            return val

        if target == "pixel_m":
            if "um" in s or "micron" in s:
                return val / 1_000_000.0
            if "mm" in s:
                return val / 1000.0
            if "nm" in s:
                return val / 1_000_000_000.0
            if " m" in f" {s}" or s.endswith("m"):
                return val
            if val > 10:
                return val / 1_000_000.0
            if val > 0.01:
                return val / 1000.0
            return val

        if target == "wavelength_a":
            if "nm" in s:
                return val * 10.0
            if "pm" in s:
                return val / 100.0
            if "m" in s and "mm" not in s and "um" not in s and "nm" not in s:
                return val * 1e10
            return val

        if target == "energy_kev":
            if "mev" in s:
                return val * 1000.0
            if "ev" in s and "kev" not in s:
                return val / 1000.0
            return val

        return val

    def extract_instrument_signature(self, filepath, header_dict=None, shape=None):
        meta = self.normalize_header_dict(header_dict)
        if not meta:
            try:
                img = fabio.open(filepath)
                meta = self.normalize_header_dict(getattr(img, "header", {}))
                if shape is None:
                    shape = tuple(img.data.shape)
            except Exception:
                pass

        wl_raw, _ = self.meta_get_raw(meta, ["wavelength", "lambda", "wave"])
        en_raw, _ = self.meta_get_raw(meta, ["energykev", "energy", "xrayenergy", "beamenergy"])
        dist_raw, _ = self.meta_get_raw(meta, ["detdistance", "distance", "sampledetdist", "camlength"])
        px1_raw, _ = self.meta_get_raw(meta, ["pixel1", "pixelsizey", "pixely", "ypixelsize"])
        px2_raw, _ = self.meta_get_raw(meta, ["pixel2", "pixelsizex", "pixelx", "xpixelsize"])
        det_raw, _ = self.meta_get_raw(meta, ["detector", "detectorname", "detector_model"])

        wl_a = self.value_with_unit_to_si(wl_raw, "wavelength_a")
        en_kev = self.value_with_unit_to_si(en_raw, "energy_kev")
        dist_m = self.value_with_unit_to_si(dist_raw, "distance_m")
        px1_m = self.value_with_unit_to_si(px1_raw, "pixel_m")
        px2_m = self.value_with_unit_to_si(px2_raw, "pixel_m")

        if wl_a is None and en_kev and en_kev > 0:
            wl_a = HC_KEV_A / en_kev
        if en_kev is None and wl_a and wl_a > 0:
            en_kev = HC_KEV_A / wl_a

        return {
            "distance_m": dist_m,
            "pixel1_m": px1_m,
            "pixel2_m": px2_m,
        }

    def relative_diff(self, a, b):
        if a is None or b is None:
            return None
        if not (np.isfinite(a) and np.isfinite(b)):
            return None
        den = max(abs(a), 1e-12)
        return abs(a - b) / den

    def normalize_azimuth_deg(self, angle_deg):
        a = float(angle_deg)
        if not np.isfinite(a):
            raise ValueError(f"è§’åº¦éæ³•: {angle_deg}")
        return ((a + 180.0) % 360.0) - 180.0

    def resolve_sector_range(self, sec_min, sec_max):
        s1 = self.normalize_azimuth_deg(sec_min)
        s2 = self.normalize_azimuth_deg(sec_max)
        span = (s2 - s1 + 360.0) % 360.0
        if np.isclose(span, 0.0, atol=1e-9):
            raise ValueError("æ‰‡åŒºè§’åº¦èŒƒå›´æ— æ•ˆï¼šsec_min ä¸ sec_max ä¸èƒ½ç›¸åŒï¼ˆæ¨¡360ï¼‰ã€‚")

        wrap = s1 > s2
        if wrap:
            segments = [(s1, 180.0), (-180.0, s2)]
        else:
            segments = [(s1, s2)]
        return s1, s2, wrap, segments

    def build_sector_mask(self, chi_deg, sec_min, sec_max):
        s1, s2, wrap, _ = self.resolve_sector_range(sec_min, sec_max)
        chi = np.asarray(chi_deg, dtype=np.float64)
        if wrap:
            mask = (chi >= s1) | (chi <= s2)
        else:
            mask = (chi >= s1) & (chi <= s2)
        return mask, s1, s2, wrap

    def _sector_value_token(self, value):
        s = f"{float(value):.3f}".rstrip("0").rstrip(".")
        if s in {"", "-0"}:
            s = "0"
        s = s.replace("-", "m").replace("+", "p").replace(".", "p")
        return s

    def sector_folder_name(self, idx, sec_min, sec_max):
        return f"sector_{int(idx):02d}_{self._sector_value_token(sec_min)}_to_{self._sector_value_token(sec_max)}"

    def parse_sector_specs(self, text, fallback_pair=None):
        raw = str(text).strip() if text is not None else ""
        pairs = []

        if raw:
            norm = (
                raw.replace("ï¼Œ", ",")
                .replace("ï¼›", ";")
                .replace("ï¼š", ":")
                .replace("ï½", "~")
                .replace("â†’", "->")
                .replace("è‡³", "to")
            )
            pat = re.compile(
                r"([-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)\s*(?:~|,|:|->|to)\s*([-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)",
                re.IGNORECASE,
            )
            for m in pat.finditer(norm):
                pairs.append((float(m.group(1)), float(m.group(2))))

            if not pairs:
                nums = [float(x) for x in FLOAT_PATTERN.findall(norm)]
                if len(nums) >= 2 and len(nums) % 2 == 0:
                    pairs = list(zip(nums[::2], nums[1::2]))

        if not pairs:
            if raw:
                raise ValueError(
                    "æœªè§£æåˆ°æ‰‡åŒºèŒƒå›´ã€‚å¯ç”¨ç¤ºä¾‹ï¼š-25~25;45~65 æˆ– -25,25 45,65ã€‚"
                )
            if fallback_pair is not None:
                a, b = fallback_pair
                pairs = [(float(a), float(b))]
            else:
                raise ValueError("æœªæä¾›æ‰‡åŒºèŒƒå›´ã€‚")

        specs = []
        seen = set()
        for a, b in pairs:
            s1, s2, wrap, segments = self.resolve_sector_range(a, b)
            sig = (round(float(s1), 6), round(float(s2), 6))
            if sig in seen:
                continue
            seen.add(sig)
            idx = len(specs) + 1
            specs.append({
                "index": idx,
                "input_min": float(a),
                "input_max": float(b),
                "sec_min": float(s1),
                "sec_max": float(s2),
                "wrap": bool(wrap),
                "segments": list(segments),
                "label": f"[{s1:.2f},{s2:.2f}]",
                "key": self.sector_folder_name(idx, s1, s2),
            })

        if not specs:
            raise ValueError("æ‰‡åŒºè§£æåä¸ºç©ºï¼Œè¯·æ£€æŸ¥è¾“å…¥ã€‚")
        return specs

    def get_t2_sector_specs(self):
        txt = self.t2_sector_ranges_text.get().strip() if hasattr(self, "t2_sector_ranges_text") else ""
        fallback = (float(self.t2_sec_min.get()), float(self.t2_sec_max.get()))
        return self.parse_sector_specs(txt, fallback_pair=fallback)

    def merge_integrate1d_results(self, results):
        if not results:
            raise ValueError("æ— å¯åˆå¹¶ç§¯åˆ†ç»“æœã€‚")

        r0 = np.asarray(results[0].radial, dtype=np.float64)
        if r0.size < 2:
            raise ValueError("ç§¯åˆ†ç»“æœç‚¹æ•°ä¸è¶³ã€‚")

        sum_w = np.zeros_like(r0, dtype=np.float64)
        sum_iw = np.zeros_like(r0, dtype=np.float64)
        sum_sw2 = np.zeros_like(r0, dtype=np.float64)
        has_sigma = False

        for res in results:
            rr = np.asarray(res.radial, dtype=np.float64)
            if rr.shape != r0.shape or not np.allclose(rr, r0, rtol=1e-7, atol=1e-12, equal_nan=False):
                raise ValueError("åˆ†æ®µæ‰‡åŒºç§¯åˆ†çš„ q ç½‘æ ¼ä¸ä¸€è‡´ï¼Œæ— æ³•åˆå¹¶ã€‚")

            i = np.asarray(res.intensity, dtype=np.float64)
            w = getattr(res, "count", None)
            if w is None:
                w = np.where(np.isfinite(i), 1.0, 0.0)
            else:
                w = np.asarray(w, dtype=np.float64)
                if w.shape != r0.shape:
                    w = np.where(np.isfinite(i), 1.0, 0.0)
                w = np.nan_to_num(w, nan=0.0, posinf=0.0, neginf=0.0)
                w = np.maximum(w, 0.0)

            i_num = np.nan_to_num(i, nan=0.0, posinf=0.0, neginf=0.0)
            sum_iw += i_num * w
            sum_w += w

            sigma = getattr(res, "sigma", None)
            if sigma is not None:
                s = np.asarray(sigma, dtype=np.float64)
                if s.shape == r0.shape:
                    term = np.nan_to_num(s, nan=0.0, posinf=0.0, neginf=0.0) * w
                    sum_sw2 += term * term
                    has_sigma = True

        i_merge = np.divide(sum_iw, sum_w, out=np.full_like(sum_iw, np.nan), where=sum_w > 0)
        sigma_merge = None
        if has_sigma:
            sigma_merge = np.divide(
                np.sqrt(sum_sw2),
                sum_w,
                out=np.full_like(sum_w, np.nan),
                where=sum_w > 0,
            )

        return SimpleNamespace(
            radial=r0,
            intensity=i_merge,
            sigma=sigma_merge,
            count=sum_w,
        )

    def integrate1d_sector(self, ai, img, npt, sec_min, sec_max, **kwargs):
        s1, s2, wrap, segments = self.resolve_sector_range(sec_min, sec_max)

        if len(segments) == 1:
            res = ai.integrate1d(
                img,
                npt,
                unit="q_A^-1",
                azimuth_range=segments[0],
                **kwargs,
            )
            return res, s1, s2, wrap

        parts = []
        for seg in segments:
            parts.append(
                ai.integrate1d(
                    img,
                    npt,
                    unit="q_A^-1",
                    azimuth_range=seg,
                    **kwargs,
                )
            )
        res = self.merge_integrate1d_results(parts)
        return res, s1, s2, wrap

    def check_instrument_consistency(self, file_paths, poni_path=None, tol_pct=0.5):
        if not file_paths:
            return []
        tol = max(float(tol_pct), 0.01) / 100.0
        sigs = []
        for fp in file_paths:
            try:
                img = fabio.open(fp)
                d = img.data
                sig = self.extract_instrument_signature(fp, header_dict=getattr(img, "header", {}), shape=d.shape)
                sigs.append(sig)
            except Exception as e:
                sigs.append({"path": str(fp), "shape": None, "error": str(e)})

        ref = sigs[0]
        fallback = self.session_geometry_fallback if isinstance(self.session_geometry_fallback, dict) else {}
        if fallback:
            for key in ("wavelength_a", "distance_m", "pixel1_m", "pixel2_m", "energy_kev"):
                if ref.get(key) is None and fallback.get(key) is not None:
                    ref[key] = fallback.get(key)

        issues = []
        for s in sigs[1:]:
            p = Path(s.get("path", "")).name
            if "error" in s:
                issues.append(f"{p}: æ— æ³•è¯»å–æ–‡ä»¶å¤´ ({s['error']})")
                continue

            if ref.get("shape") and s.get("shape") and ref["shape"] != s["shape"]:
                issues.append(f"{p}: å›¾åƒå°ºå¯¸ä¸ä¸€è‡´ {s['shape']} != {ref['shape']}")

            if ref.get("detector") and s.get("detector") and ref["detector"] != s["detector"]:
                issues.append(f"{p}: æ¢æµ‹å™¨å‹å·ä¸ä¸€è‡´ {s['detector']} != {ref['detector']}")

            for key, label in [
                ("energy_kev", "èƒ½é‡(keV)"),
                ("wavelength_a", "æ³¢é•¿(A)"),
                ("distance_m", "æ ·æ¢è·(m)"),
                ("pixel1_m", "pixel1(m)"),
                ("pixel2_m", "pixel2(m)"),
            ]:
                rd = self.relative_diff(s.get(key), ref.get(key))
                if rd is not None and rd > tol:
                    issues.append(
                        f"{p}: {label} åå·® {rd*100:.3f}% è¶…è¿‡é˜ˆå€¼ {tol*100:.3f}%"
                    )

        if poni_path:
            try:
                ai = pyFAI.load(poni_path)
                ai_wl_a = ai.wavelength * 1e10 if getattr(ai, "wavelength", None) else None
                if ai_wl_a and ref.get("wavelength_a"):
                    rd = self.relative_diff(ai_wl_a, ref["wavelength_a"])
                    if rd is not None and rd > tol:
                        issues.append(
                            f"poni æ³¢é•¿ä¸æ ·å“å¤´ä¿¡æ¯ä¸ä¸€è‡´: {ai_wl_a:.6g} A vs {ref['wavelength_a']:.6g} A"
                        )
            except Exception as e:
                issues.append(f"æ— æ³•è¯»å– poni åšä¸€è‡´æ€§æ£€æŸ¥: {e}")

        return issues

    def build_output_stem_map(self, files):
        name_count = {}
        for fp in files:
            stem = Path(fp).stem
            name_count[stem] = name_count.get(stem, 0) + 1

        used = set()
        out = {}
        for fp in files:
            p = Path(fp)
            stem = p.stem
            if name_count[stem] == 1:
                candidate = stem
            else:
                candidate = f"{p.parent.name}_{stem}"

            if candidate in used:
                idx = 2
                while f"{candidate}_{idx}" in used:
                    idx += 1
                candidate = f"{candidate}_{idx}"

            used.add(candidate)
            out[fp] = candidate
        return out

    def mode_output_path(self, save_dirs, mode, out_stem):
        ext = ".chi" if mode == "radial_chi" else ".dat"
        return save_dirs[mode] / f"{out_stem}{ext}"

    def build_sample_output_targets(self, context, out_stem):
        targets = []
        for mode in context["selected_modes"]:
            if mode != "1d_sector":
                targets.append((mode, self.mode_output_path(context["save_dirs"], mode, out_stem)))
                continue

            if context.get("sector_save_each", True):
                for spec in context.get("sector_specs", []):
                    d = context.get("sector_save_dirs", {}).get(spec["key"])
                    if d is None:
                        continue
                    targets.append((f"1d_sector{spec['label']}", d / f"{out_stem}.dat"))

            if context.get("sector_save_combined", False):
                d = context.get("sector_combined_dir", None)
                if d is not None:
                    targets.append(("1d_sector_sum", d / f"{out_stem}.dat"))
        return targets

    def save_profile_table(self, out_path, x, i_abs, i_err, x_label):
        # Origin-friendly text table: first row is column names, tab-separated.
        df = pd.DataFrame({
            x_label: np.asarray(x, dtype=np.float64),
            "I_abs_cm^-1": np.asarray(i_abs, dtype=np.float64),
            "Error_cm^-1": np.asarray(i_err, dtype=np.float64),
        })
        df.replace([np.inf, -np.inf], np.nan, inplace=True)
        df.to_csv(
            out_path,
            sep="\t",
            index=False,
            encoding="utf-8-sig",
            na_rep="",
            float_format="%.10g",
        )

    def load_optional_array(self, path, name):
        if not path:
            return None
        p = Path(path)
        if p.suffix.lower() == ".npy":
            arr = np.load(path)
        else:
            arr = fabio.open(path).data
        if arr is None:
            raise ValueError(f"{name} æ–‡ä»¶æ— æ³•è¯»å–: {path}")
        return np.asarray(arr)

    def profile_health_issue(self, i_abs):
        arr = np.asarray(i_abs, dtype=np.float64)
        arr = arr[np.isfinite(arr)]
        if arr.size < 50:
            return None
        non_pos_frac = float(np.mean(arr <= 0))
        if non_pos_frac >= 0.98:
            return (
                f"ç§¯åˆ†ç»“æœå¼‚å¸¸ï¼šéæ­£å€¼æ¯”ä¾‹ {non_pos_frac*100:.1f}% "
                "(ç–‘ä¼¼è¿‡æ‰£èƒŒæ™¯æˆ–å½’ä¸€åŒ–è®¾ç½®é”™è¯¯)"
            )
        return None

    def build_reference_library(self, paths):
        refs = []
        for p in list(dict.fromkeys(paths or [])):
            try:
                img = fabio.open(p)
                data = np.asarray(img.data)
                exp, mon, trans = self.parse_header(p, header_dict=getattr(img, "header", {}))
                refs.append({
                    "path": str(p),
                    "shape": tuple(data.shape),
                    "exp": exp,
                    "mon": mon,
                    "trans": trans,
                    "mtime": Path(p).stat().st_mtime if Path(p).exists() else None,
                })
            except Exception:
                continue
        return refs

    def reference_score(self, sample_meta, ref_meta, kind="bg"):
        score = 0.0
        used = 0.0

        se, re = sample_meta.get("exp"), ref_meta.get("exp")
        sm, rm = sample_meta.get("mon"), ref_meta.get("mon")
        st, rt = sample_meta.get("trans"), ref_meta.get("trans")
        stime, rtime = sample_meta.get("mtime"), ref_meta.get("mtime")

        if se and re and se > 0 and re > 0:
            score += self.relative_diff(se, re) * 1.0
            used += 1.0
        if sm and rm and sm > 0 and rm > 0:
            score += self.relative_diff(sm, rm) * 0.8
            used += 0.8
        if kind == "bg" and st and rt and st > 0 and rt > 0:
            score += abs(st - rt) * 1.5
            used += 1.5
        if stime and rtime:
            dt_h = abs(stime - rtime) / 3600.0
            score += min(dt_h / 24.0, 3.0) * 0.5
            used += 0.5

        if used == 0:
            return 1e9
        return score / used

    def select_best_reference(self, sample_meta, refs, kind="bg"):
        if not refs:
            return None, None
        same_shape = [r for r in refs if r.get("shape") == sample_meta.get("shape")]
        pool = same_shape if same_shape else refs
        scored = []
        for r in pool:
            scored.append((self.reference_score(sample_meta, r, kind=kind), r))
        scored.sort(key=lambda x: x[0])
        return scored[0][1], scored[0][0]

    # =========================================================================
    # TAB 1: K-Factor Calibration
    # =========================================================================
    def init_tab1_k_calc(self):
        p = self.tab1
        left_panel = ttk.Frame(p, width=400)
        left_panel.pack(side="left", fill="y", padx=5, pady=5)

        # æµç¨‹æç¤º
        f_guide = ttk.LabelFrame(left_panel, text="å¿«é€Ÿæµç¨‹ï¼ˆæ–°æ‰‹ï¼‰", style="Group.TLabelframe")
        f_guide.pack(fill="x", pady=5)
        guide_text = (
            "â‘  é€‰æ‹©æ ‡å‡†æ ·/æœ¬åº•/æš—åœº/å‡ ä½•æ–‡ä»¶\n"
            "â‘¡ æ ¸å¯¹è‡ªåŠ¨è¯»å–çš„ Timeã€I0ã€T\n"
            "â‘¢ å¡«å†™æ ‡å‡†æ ·åšåº¦(mm)\n"
            "â‘£ ç‚¹å‡»è¿è¡Œæ ‡å®šï¼Œå¾—åˆ° K å› å­\n"
            "â‘¤ æŸ¥çœ‹æŠ¥å‘Šä¸­çš„ Std Dev ä¸ç‚¹æ•°"
        )
        lbl_guide = ttk.Label(f_guide, text=guide_text, justify="left", style="Hint.TLabel")
        lbl_guide.pack(fill="x", padx=4, pady=3)
        self.add_tooltip(lbl_guide, "æŒ‰ 1~5 æ­¥æ‰§è¡Œï¼ŒåŸºæœ¬ä¸ä¼šæ¼å…³é”®å‚æ•°ã€‚")

        # 1. æ–‡ä»¶åŒº
        f_files = ttk.LabelFrame(left_panel, text="1. æ ‡å®šæ–‡ä»¶ï¼ˆå¿…é¡»ï¼‰", style="Group.TLabelframe")
        f_files.pack(fill="x", pady=5)
        self.add_hint(
            f_files,
            "æ ‡å‡†æ ·å»ºè®®ç”¨ç»ç’ƒç¢³ï¼ˆGCï¼‰ï¼›èƒŒæ™¯/æš—åœº/poni åº”ä¸æ ·å“ä¿æŒåŒä¸€å®éªŒå‡ ä½•ä¸èƒ½é‡ã€‚",
        )
        
        self.t1_files = {
            "std": tk.StringVar(), "bg": self.global_vars["bg_path"],
            "dark": self.global_vars["dark_path"], "poni": self.global_vars["poni_path"]
        }

        row_std = self.add_file_row(f_files, "æ ‡å‡†æ · (GC):", self.t1_files["std"], "*.tif", self.on_load_std_t1)
        self.add_tooltip(row_std["entry"], "ç”¨äºç»å¯¹å¼ºåº¦æ ‡å®šçš„æ ‡å‡†æ ·äºŒç»´å›¾åƒï¼ˆæ¨è GCï¼‰ã€‚")
        self.add_tooltip(row_std["button"], "ç‚¹å‡»é€‰æ‹©æ ‡å‡†æ ·æ–‡ä»¶ã€‚")

        row_bg = self.add_file_row(f_files, "èƒŒæ™¯å›¾åƒ:", self.t1_files["bg"], "*.tif", self.on_load_bg_t1)
        self.add_tooltip(row_bg["entry"], "ç©ºæ ·å“/ç©ºæ°”æˆ–æœ¬åº•æ•£å°„å›¾åƒï¼Œç”¨äº 2D æœ¬åº•æ‰£é™¤ã€‚")
        self.add_tooltip(row_bg["button"], "ç‚¹å‡»é€‰æ‹©èƒŒæ™¯å›¾åƒã€‚")

        row_dark = self.add_file_row(f_files, "æš—åœºå›¾åƒ:", self.t1_files["dark"], "*.tif")
        self.add_tooltip(row_dark["entry"], "æ¢æµ‹å™¨æš—ç”µæµ/æœ¬åº•å™ªå£°å›¾åƒã€‚")
        self.add_tooltip(row_dark["button"], "ç‚¹å‡»é€‰æ‹©æš—åœºå›¾åƒã€‚")

        row_poni = self.add_file_row(f_files, "å‡ ä½•æ–‡ä»¶ (.poni):", self.t1_files["poni"], "*.poni")
        self.add_tooltip(row_poni["entry"], "pyFAI å‡ ä½•æ ‡å®šæ–‡ä»¶ï¼Œå†³å®š q è½¬æ¢ç²¾åº¦ã€‚")
        self.add_tooltip(row_poni["button"], "ç‚¹å‡»é€‰æ‹© .poni æ–‡ä»¶ã€‚")

        # 2. ç‰©ç†å‚æ•°
        f_phys = ttk.LabelFrame(left_panel, text="2. ç‰©ç†å‚æ•°ï¼ˆæ ¸å¿ƒè¾“å…¥ï¼‰", style="Group.TLabelframe")
        f_phys.pack(fill="x", pady=5)
        self.add_hint(
            f_phys,
            "Time(s)=æ›å…‰æ—¶é—´ï¼›I0=å…¥å°„å¼ºåº¦ç›‘æµ‹å€¼ï¼›T=é€è¿‡ç‡(0~1)ã€‚å½’ä¸€åŒ–æŒ‰ä¸‹æ–¹ I0 è¯­ä¹‰é€‰æ‹©å…¬å¼ã€‚",
        )
        f_phys_grid = ttk.Frame(f_phys)
        f_phys_grid.pack(fill="x")
        
        self.t1_params = {
            "std_exp": tk.DoubleVar(value=1.0), "std_i0": tk.DoubleVar(value=1.0),
            "std_t": tk.DoubleVar(value=1.0), "std_thk": tk.DoubleVar(value=1.0),
            "bg_exp": self.global_vars["bg_exp"], "bg_i0": self.global_vars["bg_i0"], "bg_t": self.global_vars["bg_t"]
        }
        
        headers = ["Time(s)", "I0(Mon)", "Trans(T)", "Thk(mm)"]
        for i, h in enumerate(headers):
            ttk.Label(f_phys_grid, text=h, font=("Arial", 8)).grid(row=0, column=i+1)
        
        ttk.Label(f_phys_grid, text="Std:", style="Bold.TLabel").grid(row=1, column=0, pady=2)
        e_std_exp = self.add_grid_entry(f_phys_grid, self.t1_params["std_exp"], 1, 1)
        e_std_i0 = self.add_grid_entry(f_phys_grid, self.t1_params["std_i0"], 1, 2)
        e_std_t = self.add_grid_entry(f_phys_grid, self.t1_params["std_t"], 1, 3)
        e_std_thk = self.add_grid_entry(f_phys_grid, self.t1_params["std_thk"], 1, 4)
        
        ttk.Label(f_phys_grid, text="BG:", style="Bold.TLabel").grid(row=2, column=0, pady=2)
        e_bg_exp = self.add_grid_entry(f_phys_grid, self.t1_params["bg_exp"], 2, 1)
        e_bg_i0 = self.add_grid_entry(f_phys_grid, self.t1_params["bg_i0"], 2, 2)
        e_bg_t = self.add_grid_entry(f_phys_grid, self.t1_params["bg_t"], 2, 3)
        ttk.Label(f_phys_grid, text="-").grid(row=2, column=4)

        norm_row = ttk.Frame(f_phys)
        norm_row.pack(fill="x", pady=(3, 0))
        ttk.Label(norm_row, text="I0 è¯­ä¹‰:").pack(side="left")
        cb_norm_t1 = ttk.Combobox(
            norm_row,
            textvariable=self.global_vars["monitor_mode"],
            width=11,
            state="readonly",
            values=MONITOR_NORM_MODES,
        )
        cb_norm_t1.pack(side="left", padx=(4, 6))
        lbl_norm_hint_t1 = ttk.Label(
            norm_row,
            text="rate: exp*I0*T | integrated: I0*T",
            style="Hint.TLabel",
        )
        lbl_norm_hint_t1.pack(side="left")
        cb_solid_t1 = ttk.Checkbutton(
            norm_row,
            text="SolidAngleä¿®æ­£",
            variable=self.global_vars["apply_solid_angle"],
        )
        cb_solid_t1.pack(side="left", padx=(8, 0))

        self.add_tooltip(e_std_exp, "æ ‡å‡†æ ·æ›å…‰æ—¶é—´ï¼ˆç§’ï¼‰ã€‚")
        self.add_tooltip(e_std_i0, "æ ‡å‡†æ · I0ï¼ˆç›‘æµ‹å™¨è¯»æ•°ï¼‰ã€‚")
        self.add_tooltip(e_std_t, "æ ‡å‡†æ ·é€è¿‡ç‡ï¼Œå»ºè®®åœ¨ 0~1 ä¹‹é—´ã€‚")
        self.add_tooltip(e_std_thk, "æ ‡å‡†æ ·åšåº¦ï¼ˆmmï¼‰ï¼Œç”¨äºä½“ç§¯å½’ä¸€åŒ–ã€‚")
        self.add_tooltip(e_bg_exp, "èƒŒæ™¯å›¾æ›å…‰æ—¶é—´ï¼ˆç§’ï¼‰ã€‚")
        self.add_tooltip(e_bg_i0, "èƒŒæ™¯å›¾ I0ï¼ˆç›‘æµ‹å™¨è¯»æ•°ï¼‰ã€‚")
        self.add_tooltip(e_bg_t, "èƒŒæ™¯å›¾é€è¿‡ç‡ã€‚")
        self.add_tooltip(cb_norm_t1, "rate: I0 æ˜¯æ¯ç§’è®¡æ•°ç‡ï¼›integrated: I0 æ˜¯æ›å…‰ç§¯åˆ†è®¡æ•°ã€‚")
        self.add_tooltip(lbl_norm_hint_t1, "è¯·æŒ‰çº¿ç«™å®é™…è¾“å‡ºé€‰æ‹©ã€‚é€‰é”™ä¼šå¼•å…¥æ›å…‰æ—¶é—´ç›¸å…³ç³»ç»Ÿè¯¯å·®ã€‚")
        self.add_tooltip(cb_solid_t1, "Tab1æ ‡å®šä¸Tab2æ‰¹å¤„ç†å…±ç”¨æ­¤è®¾ç½®ã€‚ä¸¤è€…å¿…é¡»ä¸€è‡´ï¼Œå¦åˆ™ K å› å­æ— æ•ˆã€‚")

        # 3. æ“ä½œæŒ‰é’®
        btn_row = ttk.Frame(left_panel)
        btn_row.pack(fill="x", pady=10)
        btn_cal = ttk.Button(btn_row, text=">>> è¿è¡Œ K å› å­æ ‡å®šï¼ˆç¨³å¥æ¨¡å¼ï¼‰ <<<", command=self.run_calibration)
        btn_cal.pack(side="left", fill="x", expand=True, ipady=5)
        btn_hist = ttk.Button(btn_row, text="K å†å²", command=self.open_k_history)
        btn_hist.pack(side="left", padx=(6, 0))
        self.add_tooltip(btn_cal, "æ‰§è¡Œ 2D æ‰£èƒŒæ™¯ + 1D ç§¯åˆ† + NIST åŒ¹é…ï¼Œè‡ªåŠ¨å†™å…¥ K å› å­ã€‚")
        self.add_tooltip(btn_hist, "æŸ¥çœ‹å†å² K å› å­è¶‹åŠ¿ï¼Œç›‘æ§ä»ªå™¨æ¼‚ç§»ã€‚")

        # 4. æŠ¥å‘Š
        f_rep = ttk.LabelFrame(left_panel, text="åˆ†ææŠ¥å‘Šï¼ˆå»ºè®®é‡ç‚¹çœ‹ Std Devï¼‰", style="Group.TLabelframe")
        f_rep.pack(fill="both", expand=True, pady=5)
        self.txt_report = tk.Text(f_rep, font=("Consolas", 9), height=15, width=40)
        self.txt_report.pack(fill="both", expand=True)
        self.add_tooltip(
            self.txt_report,
            "ä¼šæ˜¾ç¤ºæ ‡å®šå…³é”®æŒ‡æ ‡ï¼šKã€æœ‰æ•ˆç‚¹æ•°ã€Q é‡å åŒºé—´å’Œç¦»æ•£åº¦ã€‚"
        )

        # --- å³ä¾§å›¾å½¢ ---
        right_panel = ttk.Frame(p)
        right_panel.pack(side="right", fill="both", expand=True, padx=5, pady=5)
        lbl_plot_tip = ttk.Label(
            right_panel,
            text="å›¾ç¤ºè¯´æ˜ï¼šé»‘è™šçº¿=å‡€ä¿¡å·ï¼›è“çº¿=K æ ¡æ­£åï¼›çº¢åœˆ=NIST å‚è€ƒç‚¹",
            style="Hint.TLabel",
        )
        lbl_plot_tip.pack(anchor="w", pady=(0, 2))
        self.fig1 = Figure(figsize=(6, 5), dpi=100)
        self.ax1 = self.fig1.add_subplot(111)
        self.canvas1 = FigureCanvasTkAgg(self.fig1, master=right_panel)
        self.canvas1.get_tk_widget().pack(fill="both", expand=True)
        self.toolbar1 = NavigationToolbar2Tk(self.canvas1, right_panel)
        self.toolbar1.update()
        self.add_tooltip(lbl_plot_tip, "è‹¥è“çº¿ä¸çº¢ç‚¹è¶‹åŠ¿ä¸€è‡´ï¼Œé€šå¸¸è¯´æ˜ K æ ‡å®šè´¨é‡è¾ƒå¥½ã€‚")

    # =========================================================================
    # TAB 2: Batch Processing
    # =========================================================================
    def init_tab2_batch(self):
        p = self.tab2
        
        self.t2_files = []
        self.t2_mu = tk.DoubleVar(value=20.2)
        self.t2_calc_mode = tk.StringVar(value="auto") 
        self.t2_fixed_thk = tk.DoubleVar(value=1.0)
        self.t2_ref_mode = tk.StringVar(value="fixed")
        self.t2_error_model = tk.StringVar(value="azimuthal")
        self.t2_apply_solid_angle = self.global_vars["apply_solid_angle"]
        self.t2_polarization = tk.DoubleVar(value=0.0)
        self.t2_output_root = tk.StringVar(value="")
        self.t2_mask_path = tk.StringVar()
        self.t2_flat_path = tk.StringVar()
        self.t2_resume_enabled = tk.BooleanVar(value=True)
        self.t2_overwrite = tk.BooleanVar(value=False)
        self.t2_workers = tk.IntVar(value=1)
        self.t2_strict_instrument = tk.BooleanVar(value=True)
        self.t2_instr_tol_pct = tk.DoubleVar(value=0.5)
        self.t2_bg_candidates = []
        self.t2_dark_candidates = []
        self.t2_bg_lib_info = tk.StringVar(value="BGåº“: 0")
        self.t2_dark_lib_info = tk.StringVar(value="Darkåº“: 0")
        
        self.t2_mode_full = tk.BooleanVar(value=True)
        self.t2_mode_sector = tk.BooleanVar(value=False)
        self.t2_mode_chi = tk.BooleanVar(value=False)
        self.t2_sec_min = tk.DoubleVar(value=-20)
        self.t2_sec_max = tk.DoubleVar(value=20)
        self.t2_sector_ranges_text = tk.StringVar(value="")
        self.t2_sector_save_each = tk.BooleanVar(value=True)
        self.t2_sector_save_combined = tk.BooleanVar(value=False)
        self.t2_rad_qmin = tk.DoubleVar(value=0.5)
        self.t2_rad_qmax = tk.DoubleVar(value=2.5)

        # æµç¨‹æç¤º
        f_guide = ttk.LabelFrame(p, text="æ‰¹å¤„ç†å·¥ä½œæµï¼ˆæ¨èé¡ºåºï¼‰", style="Group.TLabelframe")
        f_guide.pack(fill="x", padx=10, pady=(8, 3))
        guide = (
            "â‘  å…ˆç¡®è®¤ K å› å­å’Œ BG/æš—åœº/poni å·²å°±ç»ª\n"
            "â‘¡ é€‰æ‹©åšåº¦é€»è¾‘ï¼ˆè‡ªåŠ¨/å›ºå®šï¼‰\n"
            "â‘¢ é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªç§¯åˆ†æ¨¡å¼ï¼ˆå¯åŒæ—¶å‹¾é€‰ï¼‰\n"
            "â‘£ æ·»åŠ æ ·å“æ–‡ä»¶å¹¶ç‚¹å‡»é¢„æ£€æŸ¥\n"
            "â‘¤ å¯åŠ¨æ‰¹å¤„ç†å¹¶æŸ¥çœ‹ batch_report.csv"
        )
        lbl_guide = ttk.Label(f_guide, text=guide, justify="left", style="Hint.TLabel")
        lbl_guide.pack(fill="x", padx=4, pady=3)
        self.add_tooltip(lbl_guide, "å…ˆé¢„æ£€æŸ¥å†æ­£å¼è·‘æ‰¹ï¼Œå¯æ˜¾è‘—å‡å°‘ä¸­é€”å¤±è´¥ã€‚")

        # --- Settings ---
        top_frame = ttk.Frame(p)
        top_frame.pack(fill="x", padx=10, pady=5)
        
        # 1. Global
        c1 = ttk.LabelFrame(top_frame, text="1. å…¨å±€é…ç½®", style="Group.TLabelframe")
        c1.pack(side="left", fill="y", padx=5)
        self.add_hint(c1, "K å› å­æ¥è‡ª Tab1 æ ‡å®šç»“æœã€‚I0 è¯­ä¹‰å†³å®šå½’ä¸€åŒ–å…¬å¼ï¼›BG è·¯å¾„ä»…ç”¨äºå¿«é€Ÿç¡®è®¤ã€‚", wraplength=300)
        c1_grid = ttk.Frame(c1)
        c1_grid.pack(fill="x")
        ttk.Label(c1_grid, text="K å› å­:").grid(row=0, column=0, sticky="e")
        e_k = ttk.Entry(c1_grid, textvariable=self.global_vars["k_factor"], width=10)
        e_k.grid(row=0, column=1, padx=5)
        ttk.Label(c1_grid, text="èƒŒæ™¯æ–‡ä»¶:").grid(row=1, column=0, sticky="e")
        lbl_bg = ttk.Label(c1_grid, textvariable=self.global_vars["bg_path"], width=20, foreground="gray")
        lbl_bg.grid(row=1, column=1, padx=5)
        ttk.Label(c1_grid, text="I0 è¯­ä¹‰:").grid(row=2, column=0, sticky="e")
        cb_norm_t2 = ttk.Combobox(
            c1_grid,
            textvariable=self.global_vars["monitor_mode"],
            width=11,
            state="readonly",
            values=MONITOR_NORM_MODES,
        )
        cb_norm_t2.grid(row=2, column=1, padx=5, pady=(2, 0), sticky="w")
        lbl_norm_hint_t2 = ttk.Label(c1_grid, text="rate: exp*I0*T / integrated: I0*T", style="Hint.TLabel")
        lbl_norm_hint_t2.grid(row=3, column=0, columnspan=2, sticky="w", padx=2)
        self.add_tooltip(e_k, "ç»å¯¹å¼ºåº¦æ¯”ä¾‹å› å­ã€‚å¿…é¡»å¤§äº 0ã€‚")
        self.add_tooltip(lbl_bg, "å½“å‰å¯ç”¨çš„èƒŒæ™¯å›¾è·¯å¾„ï¼ˆç”± Tab1 å…±äº«ï¼‰ã€‚")
        self.add_tooltip(cb_norm_t2, "å…¨å±€ç”Ÿæ•ˆï¼šrate è¡¨ç¤º I0 ä¸ºè®¡æ•°ç‡ï¼›integrated è¡¨ç¤º I0 ä¸ºç§¯åˆ†è®¡æ•°ã€‚")
        self.add_tooltip(lbl_norm_hint_t2, "è¯¥è®¾ç½®ä¼šå½±å“æ ‡å®šä¸æ‰¹å¤„ç†çš„æ‰€æœ‰å½’ä¸€åŒ–å› å­ã€‚")

        # 2. Thickness
        c2 = ttk.LabelFrame(top_frame, text="2. åšåº¦ç­–ç•¥", style="Group.TLabelframe")
        c2.pack(side="left", fill="y", padx=5)
        self.add_hint(c2, "è‡ªåŠ¨æ¨¡å¼: d=-ln(T)/muï¼›å›ºå®šæ¨¡å¼: æ‰€æœ‰æ ·å“ä½¿ç”¨åŒä¸€åšåº¦(mm)ã€‚", wraplength=320)
        
        r1 = ttk.Frame(c2); r1.pack(anchor="w")
        rb_auto = ttk.Radiobutton(r1, text="è‡ªåŠ¨åšåº¦ (d = -ln(T)/Î¼)", variable=self.t2_calc_mode, value="auto")
        rb_auto.pack(side="left")
        lbl_mu = ttk.Label(r1, text=" Î¼(cmâ»Â¹):")
        lbl_mu.pack(side="left")
        e_mu = ttk.Entry(r1, textvariable=self.t2_mu, width=6)
        e_mu.pack(side="left")
        btn_est = ttk.Button(r1, text="Î¼ä¼°ç®—", command=self.open_mu_tool, width=8)
        btn_est.pack(side="left", padx=2)
        
        r2 = ttk.Frame(c2); r2.pack(anchor="w")
        rb_fix = ttk.Radiobutton(r2, text="å›ºå®šåšåº¦ (mm):", variable=self.t2_calc_mode, value="fixed")
        rb_fix.pack(side="left")
        e_fix = ttk.Entry(r2, textvariable=self.t2_fixed_thk, width=6)
        e_fix.pack(side="left")

        self.add_tooltip(rb_auto, "é€‚åˆæ¯ä¸ªæ ·å“éƒ½å…·æœ‰å¯é é€è¿‡ç‡ T çš„æƒ…å†µã€‚")
        self.add_tooltip(e_mu, "çº¿æ€§è¡°å‡ç³»æ•° muï¼Œå•ä½ cm^-1ï¼Œå¿…é¡»å¤§äº 0ã€‚")
        self.add_tooltip(btn_est, "æŒ‰åˆé‡‘æˆåˆ†ä¼°ç®— muï¼ˆ30 keV ç»éªŒï¼‰ã€‚")
        self.add_tooltip(rb_fix, "é€è¿‡ç‡ä¸ç¨³å®šæˆ–ç¼ºå¤±æ—¶ï¼Œå»ºè®®æ”¹ä¸ºå›ºå®šåšåº¦ã€‚")
        self.add_tooltip(e_fix, "æ‰€æœ‰æ ·å“ç»Ÿä¸€åšåº¦å€¼ï¼Œå•ä½ mmã€‚")
        self.add_tooltip(lbl_mu, "mu è¶Šå¤§ï¼ŒæŒ‰åŒæ · T ç®—å‡ºçš„åšåº¦è¶Šå°ã€‚")
        
        # 3. Integration
        c3 = ttk.LabelFrame(top_frame, text="3. ç§¯åˆ†æ¨¡å¼ï¼ˆ2D æ‰£èƒŒæ™¯åï¼‰", style="Group.TLabelframe")
        c3.pack(side="left", fill="y", padx=5)
        self.add_hint(c3, "å¯å¤šé€‰å¹¶ä¸€æ¬¡æ€§è¾“å‡ºåˆ°ä¸åŒæ–‡ä»¶å¤¹ï¼šå…¨ç¯/æ‰‡åŒº/ç»‡æ„å¯åŒæ—¶è¿è¡Œã€‚", wraplength=320)
        c3_grid = ttk.Frame(c3)
        c3_grid.pack(fill="x")

        cb_full = ttk.Checkbutton(c3_grid, text="I-Q å…¨ç¯", variable=self.t2_mode_full)
        cb_full.grid(row=0, column=0, sticky="w")
        f_sec = ttk.Frame(c3_grid); f_sec.grid(row=1, column=0, sticky="w")
        cb_sec = ttk.Checkbutton(f_sec, text="I-Q æ‰‡åŒº", variable=self.t2_mode_sector)
        cb_sec.pack(side="left")
        ttk.Label(f_sec, text=" [").pack(side="left")
        e_sec_min = ttk.Entry(f_sec, textvariable=self.t2_sec_min, width=4)
        e_sec_min.pack(side="left")
        ttk.Label(f_sec, text=",").pack(side="left")
        e_sec_max = ttk.Entry(f_sec, textvariable=self.t2_sec_max, width=4)
        e_sec_max.pack(side="left")
        ttk.Label(f_sec, text="] deg").pack(side="left")
        btn_sec_preview = ttk.Button(f_sec, text="é¢„è§ˆI-Q", width=8, command=self.preview_iq_window_t2)
        btn_sec_preview.pack(side="left", padx=(4, 0))

        f_sec_multi = ttk.Frame(c3_grid); f_sec_multi.grid(row=2, column=0, sticky="w")
        ttk.Label(f_sec_multi, text=" å¤šæ‰‡åŒº:").pack(side="left")
        e_sec_multi = ttk.Entry(f_sec_multi, textvariable=self.t2_sector_ranges_text, width=26)
        e_sec_multi.pack(side="left")
        ttk.Label(f_sec_multi, text=" ä¾‹:-25~25;45~65").pack(side="left")
        cb_sec_each = ttk.Checkbutton(f_sec_multi, text="åˆ†æ‰‡åŒºåˆ†åˆ«ä¿å­˜", variable=self.t2_sector_save_each)
        cb_sec_each.pack(side="left", padx=(6, 0))
        cb_sec_sum = ttk.Checkbutton(f_sec_multi, text="æ‰‡åŒºåˆå¹¶ä¿å­˜", variable=self.t2_sector_save_combined)
        cb_sec_sum.pack(side="left", padx=(4, 0))

        f_tex = ttk.Frame(c3_grid); f_tex.grid(row=3, column=0, sticky="w")
        cb_tex = ttk.Checkbutton(f_tex, text="I-chi ç»‡æ„", variable=self.t2_mode_chi)
        cb_tex.pack(side="left")
        ttk.Label(f_tex, text=" Q[").pack(side="left")
        e_qmin = ttk.Entry(f_tex, textvariable=self.t2_rad_qmin, width=4)
        e_qmin.pack(side="left")
        ttk.Label(f_tex, text=",").pack(side="left")
        e_qmax = ttk.Entry(f_tex, textvariable=self.t2_rad_qmax, width=4)
        e_qmax.pack(side="left")
        ttk.Label(f_tex, text="] Aâ»Â¹").pack(side="left")
        btn_chi_preview = ttk.Button(f_tex, text="é¢„è§ˆI-chi", width=10, command=self.preview_ichi_window_t2)
        btn_chi_preview.pack(side="left", padx=(4, 0))

        self.add_tooltip(cb_full, "å¯¹å„å‘åŒæ€§æ ·å“ä¼˜å…ˆæ¨èã€‚å¯ä¸å…¶ä»–æ¨¡å¼åŒæ—¶å‹¾é€‰ã€‚")
        self.add_tooltip(cb_sec, "ä»…å¯¹æŒ‡å®šæ–¹ä½è§’æ‰‡åŒºç§¯åˆ†ï¼Œçªå‡ºæ–¹å‘æ€§ç»“æ„ã€‚å¯å¤šé€‰å¹¶è¡Œè¾“å‡ºã€‚")
        self.add_tooltip(e_sec_min, "æ‰‡åŒºèµ·å§‹è§’ï¼ˆåº¦ï¼‰ã€‚æ”¯æŒè·¨ Â±180Â°ï¼ˆä¾‹å¦‚ 170 åˆ° -170ï¼‰ã€‚")
        self.add_tooltip(e_sec_max, "æ‰‡åŒºç»“æŸè§’ï¼ˆåº¦ï¼‰ã€‚ä¸èµ·å§‹è§’ç›¸åŒï¼ˆæ¨¡360ï¼‰æ— æ•ˆã€‚")
        self.add_tooltip(btn_sec_preview, "å¼¹å‡º2Dçª—å£é¢„è§ˆ I-Q ç§¯åˆ†åŒºåŸŸï¼ˆæ‰‡åŒºæˆ–å…¨ç¯ï¼‰ï¼Œç”¨äºç¡®è®¤é€‰åŒºã€‚")
        self.add_tooltip(e_sec_multi, "å¤šæ‰‡åŒºåˆ—è¡¨ã€‚æ”¯æŒ `-25~25;45~65`ã€`-25,25 45,65` ç­‰æ ¼å¼ï¼›ç•™ç©ºæ—¶ä½¿ç”¨ä¸Šæ–¹å•æ‰‡åŒºã€‚")
        self.add_tooltip(cb_sec_each, "æ¯ä¸ªæ‰‡åŒºè¾“å‡ºåˆ°ç‹¬ç«‹å­æ–‡ä»¶å¤¹ï¼ˆsector_XX_*ï¼‰ã€‚")
        self.add_tooltip(cb_sec_sum, "å°†æ‰€æœ‰æ‰‡åŒºæŒ‰åƒç´ æƒé‡åˆå¹¶æˆä¸€æ¡ I-Qï¼Œå¹¶å•ç‹¬è¾“å‡ºã€‚")
        self.add_tooltip(cb_tex, "åœ¨ç»™å®š q èŒƒå›´å†…è¾“å‡º I éšæ–¹ä½è§’ chi çš„åˆ†å¸ƒã€‚å¯ä¸ I-Q åŒæ—¶è¾“å‡ºã€‚")
        self.add_tooltip(e_qmin, "ç»‡æ„åˆ†æ q æœ€å°å€¼ï¼ˆA^-1ï¼‰ã€‚")
        self.add_tooltip(e_qmax, "ç»‡æ„åˆ†æ q æœ€å¤§å€¼ï¼ˆA^-1ï¼‰ï¼Œéœ€å¤§äº q_minã€‚")
        self.add_tooltip(btn_chi_preview, "å¼¹å‡º2Dçª—å£é¢„è§ˆ I-chi ä½¿ç”¨çš„ q ç¯å¸¦èŒƒå›´ã€‚")

        # 4. ä¿®æ­£ä¸æ‰§è¡Œç­–ç•¥
        adv_frame = ttk.Frame(p)
        adv_frame.pack(fill="x", padx=10, pady=(2, 4))

        c4 = ttk.LabelFrame(adv_frame, text="4. ä¿®æ­£å‚æ•°", style="Group.TLabelframe")
        c4.pack(side="left", fill="x", expand=True, padx=5)
        self.add_hint(c4, "å»ºè®®å¼€å¯ solid angleã€‚å¯é€‰ mask/flat/polarization ä¸è¯¯å·®æ¨¡å‹ã€‚", wraplength=480)

        c4_row1 = ttk.Frame(c4); c4_row1.pack(fill="x", pady=2)
        cb_solid = ttk.Checkbutton(c4_row1, text="åº”ç”¨ Solid Angle ä¿®æ­£", variable=self.t2_apply_solid_angle)
        cb_solid.pack(side="left")
        ttk.Label(c4_row1, text="è¯¯å·®æ¨¡å‹:").pack(side="left", padx=(8, 2))
        cb_err = ttk.Combobox(c4_row1, textvariable=self.t2_error_model, width=10, state="readonly")
        cb_err["values"] = ("azimuthal", "poisson", "none")
        cb_err.pack(side="left")
        ttk.Label(c4_row1, text="Polarization(-1~1):").pack(side="left", padx=(8, 2))
        e_pol = ttk.Entry(c4_row1, textvariable=self.t2_polarization, width=6)
        e_pol.pack(side="left")

        row_mask = self.add_file_row(c4, "Mask æ–‡ä»¶:", self.t2_mask_path, "*.tif *.tiff *.edf *.npy")
        row_flat = self.add_file_row(c4, "Flat æ–‡ä»¶:", self.t2_flat_path, "*.tif *.tiff *.edf *.npy")

        self.add_tooltip(cb_solid, "å¿…é¡»ä¸ Tab1 æ ‡å®šæ—¶ä¿æŒä¸€è‡´ã€‚è‹¥ä¸ä¸€è‡´ç¨‹åºä¼šé˜»æ–­æ‰¹å¤„ç†ã€‚")
        self.add_tooltip(cb_err, "azimuthal: æ–¹ä½ç¦»æ•£ï¼›poisson: è®¡æ•°ç»Ÿè®¡ï¼›none: ä¸è®¡ç®—è¯¯å·®ã€‚")
        self.add_tooltip(e_pol, "åæŒ¯å› å­ï¼Œé€šå¸¸åœ¨ -1 åˆ° 1ã€‚0 è¡¨ç¤ºä¸åæŒ¯ã€‚")
        self.add_tooltip(row_mask["entry"], "æ©è†œå›¾ï¼šéé›¶åƒç´ è§†ä¸ºæ— æ•ˆåŒºåŸŸã€‚")
        self.add_tooltip(row_flat["entry"], "å¹³åœºæ ¡æ­£å›¾ï¼ˆå¯é€‰ï¼‰ã€‚")

        c5 = ttk.LabelFrame(adv_frame, text="5. å‚è€ƒåŒ¹é…ä¸æ‰§è¡Œ", style="Group.TLabelframe")
        c5.pack(side="left", fill="x", expand=True, padx=5)
        self.add_hint(c5, "å¯å›ºå®š BG/Darkï¼Œæˆ–æŒ‰å…ƒæ•°æ®è‡ªåŠ¨åŒ¹é…æœ€æ¥è¿‘çš„ BG/Darkã€‚", wraplength=480)

        row_ref = ttk.Frame(c5); row_ref.pack(fill="x")
        rb_ref_fixed = ttk.Radiobutton(row_ref, text="å›ºå®š BG/Dark", variable=self.t2_ref_mode, value="fixed")
        rb_ref_fixed.pack(side="left")
        rb_ref_auto = ttk.Radiobutton(row_ref, text="è‡ªåŠ¨åŒ¹é… BG/Dark", variable=self.t2_ref_mode, value="auto")
        rb_ref_auto.pack(side="left", padx=(8, 0))

        row_lib = ttk.Frame(c5); row_lib.pack(fill="x", pady=2)
        btn_bg_lib = ttk.Button(row_lib, text="é€‰æ‹© BG åº“", command=self.add_bg_library_files)
        btn_bg_lib.pack(side="left")
        btn_dark_lib = ttk.Button(row_lib, text="é€‰æ‹© Dark åº“", command=self.add_dark_library_files)
        btn_dark_lib.pack(side="left", padx=(5, 0))
        btn_clear_lib = ttk.Button(row_lib, text="æ¸…ç©ºåº“", command=self.clear_reference_libraries)
        btn_clear_lib.pack(side="left", padx=(5, 0))

        row_lib_info = ttk.Frame(c5); row_lib_info.pack(fill="x")
        ttk.Label(row_lib_info, textvariable=self.t2_bg_lib_info, style="Hint.TLabel").pack(side="left")
        ttk.Label(row_lib_info, textvariable=self.t2_dark_lib_info, style="Hint.TLabel").pack(side="left", padx=(10, 0))

        row_exec = ttk.Frame(c5); row_exec.pack(fill="x", pady=2)
        ttk.Label(row_exec, text="å¹¶è¡Œçº¿ç¨‹:").pack(side="left")
        e_workers = ttk.Entry(row_exec, textvariable=self.t2_workers, width=4)
        e_workers.pack(side="left")
        cb_resume = ttk.Checkbutton(row_exec, text="æ–­ç‚¹ç»­è·‘(è·³è¿‡å·²å­˜åœ¨è¾“å‡º)", variable=self.t2_resume_enabled)
        cb_resume.pack(side="left", padx=(8, 0))
        cb_overwrite = ttk.Checkbutton(row_exec, text="å¼ºåˆ¶è¦†ç›–è¾“å‡º", variable=self.t2_overwrite)
        cb_overwrite.pack(side="left", padx=(8, 0))

        row_strict = ttk.Frame(c5); row_strict.pack(fill="x")
        cb_strict = ttk.Checkbutton(row_strict, text="ä¸¥æ ¼ä»ªå™¨ä¸€è‡´æ€§æ ¡éªŒ", variable=self.t2_strict_instrument)
        cb_strict.pack(side="left")
        ttk.Label(row_strict, text="é˜ˆå€¼(%):").pack(side="left", padx=(8, 2))
        e_tol = ttk.Entry(row_strict, textvariable=self.t2_instr_tol_pct, width=5)
        e_tol.pack(side="left")

        self.add_tooltip(rb_ref_fixed, "å…¨æ‰¹æ¬¡ç»Ÿä¸€ä½¿ç”¨ Tab1 æŒ‡å®šçš„ BG/Darkã€‚")
        self.add_tooltip(rb_ref_auto, "æŒ‰æ›å…‰/I0/T/æ—¶é—´ä¸æ ·å“æœ€æ¥è¿‘åŸåˆ™è‡ªåŠ¨é€‰ BG å’Œ Darkã€‚")
        self.add_tooltip(btn_bg_lib, "é€‰æ‹©å¯ä¾›è‡ªåŠ¨åŒ¹é…çš„èƒŒæ™¯æ–‡ä»¶é›†åˆã€‚")
        self.add_tooltip(btn_dark_lib, "é€‰æ‹©å¯ä¾›è‡ªåŠ¨åŒ¹é…çš„æš—åœºæ–‡ä»¶é›†åˆã€‚")
        self.add_tooltip(btn_clear_lib, "æ¸…ç©º BG/Dark åº“ã€‚")
        self.add_tooltip(e_workers, "å¹¶è¡Œçº¿ç¨‹æ•°ï¼Œ1 è¡¨ç¤ºä¸²è¡Œã€‚å»ºè®® 1~8ã€‚")
        self.add_tooltip(cb_resume, "å·²å­˜åœ¨è¾“å‡ºæ–‡ä»¶æ—¶è‡ªåŠ¨è·³è¿‡ï¼Œæ”¯æŒä¸­æ–­åç»­è·‘ã€‚")
        self.add_tooltip(cb_overwrite, "å¿½ç•¥å·²å­˜åœ¨è¾“å‡ºå¹¶é‡æ–°è®¡ç®—ã€‚")
        self.add_tooltip(cb_strict, "æ£€æŸ¥èƒ½é‡/æ³¢é•¿/è·ç¦»/åƒç´ /å°ºå¯¸ä¸€è‡´æ€§ï¼Œä¸ä¸€è‡´åˆ™åœæ­¢ã€‚")
        self.add_tooltip(e_tol, "ä¸€è‡´æ€§é˜ˆå€¼ç™¾åˆ†æ¯”ï¼Œä¾‹å¦‚ 0.5 è¡¨ç¤º 0.5%ã€‚")

        # --- List ---
        mid_frame = ttk.LabelFrame(p, text="æ ·å“é˜Ÿåˆ—", style="Group.TLabelframe")
        mid_frame.pack(fill="both", expand=True, padx=10, pady=5)
        self.add_hint(mid_frame, "å¯ä¸€æ¬¡æ·»åŠ å¤šä¸ªæ–‡ä»¶ã€‚å»ºè®®å…ˆç‚¹â€œé¢„æ£€æŸ¥â€ï¼Œç¡®è®¤å¤´ä¿¡æ¯ä¸åšåº¦è®¡ç®—æ˜¯å¦æ­£å¸¸ã€‚")
        
        tb = ttk.Frame(mid_frame); tb.pack(fill="x")
        btn_add = ttk.Button(tb, text="æ·»åŠ æ–‡ä»¶", command=self.add_batch_files)
        btn_add.pack(side="left")
        btn_clear = ttk.Button(tb, text="æ¸…ç©ºé˜Ÿåˆ—", command=self.clear_batch_files)
        btn_clear.pack(side="left")
        btn_check = ttk.Button(tb, text="é¢„æ£€æŸ¥", command=self.dry_run, style="Accent.TButton")
        btn_check.pack(side="right", padx=10)
        self.add_tooltip(btn_add, "æ”¯æŒå¤šé€‰ TIFF æ–‡ä»¶ã€‚")
        self.add_tooltip(btn_clear, "æ¸…ç©ºé˜Ÿåˆ—ï¼Œä¸ä¼šåˆ é™¤ç£ç›˜æ–‡ä»¶ã€‚")
        self.add_tooltip(btn_check, "æ‰¹é‡æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶çš„ exp/mon/T å’Œåšåº¦å¯ç”¨æ€§ã€‚")

        self.t2_queue_info = tk.StringVar(value="é˜Ÿåˆ—æ–‡ä»¶: 0")
        lbl_queue = ttk.Label(mid_frame, textvariable=self.t2_queue_info, style="Hint.TLabel")
        lbl_queue.pack(anchor="w", padx=5, pady=(2, 0))

        self.lb_batch = tk.Listbox(mid_frame, height=8)
        self.lb_batch.pack(fill="both", expand=True, padx=5, pady=5)
        self.add_tooltip(self.lb_batch, "æ˜¾ç¤ºå½“å‰å¾…å¤„ç†æ ·å“åˆ—è¡¨ã€‚")

        # --- Action ---
        bot_frame = ttk.Frame(p)
        bot_frame.pack(fill="x", padx=10, pady=10)
        btn_run = ttk.Button(bot_frame, text=">>> å¼€å§‹ç¨³å¥æ‰¹å¤„ç†ï¼ˆ2D æ‰£èƒŒæ™¯ + è¯¯å·®æ£’ï¼‰ <<<", command=self.run_batch)
        btn_run.pack(fill="x", ipady=5)
        self.prog_bar = ttk.Progressbar(bot_frame, mode="determinate")
        self.prog_bar.pack(fill="x", pady=5)
        row_out_dir = self.add_dir_row(bot_frame, "è¾“å‡ºæ ¹ç›®å½•:", self.t2_output_root)
        self.add_tooltip(btn_run, "æ‰§è¡Œæ‰¹å¤„ç†ã€‚å•æ–‡ä»¶å¤±è´¥ä¸ä¼šä¸­æ–­æ•´æ‰¹ã€‚")
        self.add_tooltip(self.prog_bar, "æ˜¾ç¤ºæ‰¹å¤„ç†è¿›åº¦ã€‚")
        self.add_tooltip(row_out_dir["entry"], "å¯é€‰ã€‚ä¸å¡«æ—¶é»˜è®¤è¾“å‡ºåˆ°æ ·å“æ‰€åœ¨ç›®å½•ã€‚")

        self.t2_out_hint_var = tk.StringVar(value="è¾“å‡ºç›®å½•å°†è‡ªåŠ¨åˆ›å»º: processed_robust_1d_full")
        lbl_out = ttk.Label(bot_frame, textvariable=self.t2_out_hint_var, style="Hint.TLabel")
        lbl_out.pack(anchor="w")
        self.add_tooltip(lbl_out, "è¾“å‡ºæ–‡ä»¶ä¸ batch_report.csv ä¼šå†™å…¥è¯¥ç›®å½•ã€‚")

        self.t2_mode_full.trace_add("write", lambda *_: self.refresh_queue_status())
        self.t2_mode_sector.trace_add("write", lambda *_: self.refresh_queue_status())
        self.t2_mode_chi.trace_add("write", lambda *_: self.refresh_queue_status())
        self.t2_sector_ranges_text.trace_add("write", lambda *_: self.refresh_queue_status())
        self.t2_sector_save_each.trace_add("write", lambda *_: self.refresh_queue_status())
        self.t2_sector_save_combined.trace_add("write", lambda *_: self.refresh_queue_status())
        self.t2_output_root.trace_add("write", lambda *_: self.refresh_queue_status())
        self.refresh_queue_status()

    # =========================================================================
    # TAB 3: External 1D -> Absolute Intensity
    # =========================================================================
    def init_tab3_external_1d(self):
        p = self.tab3

        self.t3_files = []
        self.t3_pipeline_mode = tk.StringVar(value="scaled")
        self.t3_corr_mode = tk.StringVar(value="k_over_d")
        self.t3_fixed_thk = tk.DoubleVar(value=1.0)
        self.t3_x_mode = tk.StringVar(value="auto")
        self.t3_meta_csv_path = tk.StringVar()
        self.t3_bg1d_path = tk.StringVar()
        self.t3_dark1d_path = tk.StringVar()
        self.t3_output_root = tk.StringVar(value="")
        self.t3_use_meta_thk = tk.BooleanVar(value=True)
        self.t3_sample_exp = tk.DoubleVar(value=1.0)
        self.t3_sample_i0 = tk.DoubleVar(value=1.0)
        self.t3_sample_t = tk.DoubleVar(value=1.0)
        self.t3_bg_exp = tk.DoubleVar(value=1.0)
        self.t3_bg_i0 = tk.DoubleVar(value=1.0)
        self.t3_bg_t = tk.DoubleVar(value=1.0)
        self.t3_sync_bg_from_global = tk.BooleanVar(value=True)
        self.t3_bg_exp.set(self.global_vars["bg_exp"].get())
        self.t3_bg_i0.set(self.global_vars["bg_i0"].get())
        self.t3_bg_t.set(self.global_vars["bg_t"].get())
        self.t3_resume_enabled = tk.BooleanVar(value=True)
        self.t3_overwrite = tk.BooleanVar(value=False)
        self.t3_queue_info = tk.StringVar(value="é˜Ÿåˆ—æ–‡ä»¶: 0")
        self.t3_out_hint = tk.StringVar(value="è¾“å‡ºç›®å½•å°†è‡ªåŠ¨åˆ›å»º: processed_external_1d_abs")

        f_guide = ttk.LabelFrame(p, text="å¤–éƒ¨ 1D ç»å¯¹å¼ºåº¦æ ¡æ­£æµç¨‹", style="Group.TLabelframe")
        f_guide.pack(fill="x", padx=10, pady=(8, 3))
        guide = (
            "â‘  å…ˆåœ¨ Tab1 å¾—åˆ°å¯ä¿¡ K å› å­\n"
            "â‘¡ é€‰æ‹©æµç¨‹ï¼šä»…æ¯”ä¾‹ç¼©æ”¾ / åŸå§‹1Då®Œæ•´æ ¡æ­£\n"
            "â‘¢ å¯¼å…¥å¤–éƒ¨1Dæ–‡ä»¶ï¼ˆåŸå§‹æ¨¡å¼è¿˜éœ€ BG1D/Dark1D ä¸å‚æ•°ï¼‰\n"
            "â‘£ é€‰æ‹©æ ¡æ­£å…¬å¼ï¼ˆK/d æˆ– Kï¼‰ä¸ X è½´ç±»å‹\n"
            "â‘¤ å…ˆé¢„æ£€æŸ¥ï¼Œå†æ‰¹é‡è¾“å‡ºç»å¯¹å¼ºåº¦è¡¨æ ¼"
        )
        lbl_guide = ttk.Label(f_guide, text=guide, justify="left", style="Hint.TLabel")
        lbl_guide.pack(fill="x", padx=4, pady=3)
        self.add_tooltip(lbl_guide, "é€‚åˆä½ åœ¨ pyFAI/å…¶ä»–è½¯ä»¶å®Œæˆç§¯åˆ†åï¼Œä»…åœ¨æœ¬ç¨‹åºåšç»å¯¹æ ‡å®šã€‚")

        top = ttk.Frame(p)
        top.pack(fill="x", padx=10, pady=5)

        c1 = ttk.LabelFrame(top, text="1. å…¨å±€ä¸å…¬å¼", style="Group.TLabelframe")
        c1.pack(side="left", fill="y", padx=5)
        self.add_hint(c1, "K æ¥è‡ª Tab1ã€‚å…ˆé€‰æµç¨‹ï¼Œå†é€‰å…¬å¼ã€‚åŸå§‹1Dæµç¨‹ä¼šç”¨åˆ° exp/I0/T ä¸ BG1D/Dark1Dã€‚", wraplength=380)

        c1_grid = ttk.Frame(c1)
        c1_grid.pack(fill="x")
        ttk.Label(c1_grid, text="K å› å­:").grid(row=0, column=0, sticky="e")
        e_k = ttk.Entry(c1_grid, textvariable=self.global_vars["k_factor"], width=10)
        e_k.grid(row=0, column=1, padx=5, pady=1, sticky="w")
        ttk.Label(c1_grid, text="æµç¨‹:").grid(row=1, column=0, sticky="e")
        rb_scaled = ttk.Radiobutton(
            c1_grid, text="ä»…æ¯”ä¾‹ç¼©æ”¾", variable=self.t3_pipeline_mode, value="scaled"
        )
        rb_scaled.grid(row=1, column=1, sticky="w")
        rb_raw = ttk.Radiobutton(
            c1_grid, text="åŸå§‹1Då®Œæ•´æ ¡æ­£", variable=self.t3_pipeline_mode, value="raw"
        )
        rb_raw.grid(row=2, column=1, sticky="w")

        rb_kd = ttk.Radiobutton(
            c1_grid,
            text="å¤–éƒ¨1Dæœªé™¤åšåº¦: I_abs = I_rel * K / d",
            variable=self.t3_corr_mode,
            value="k_over_d",
        )
        rb_kd.grid(row=3, column=0, columnspan=2, sticky="w", pady=(4, 1))
        ttk.Label(c1_grid, text="å›ºå®šåšåº¦(mm):").grid(row=4, column=0, sticky="e")
        e_thk = ttk.Entry(c1_grid, textvariable=self.t3_fixed_thk, width=8)
        e_thk.grid(row=4, column=1, padx=5, pady=1, sticky="w")

        rb_k = ttk.Radiobutton(
            c1_grid,
            text="å¤–éƒ¨1Då·²é™¤åšåº¦: I_abs = I_rel * K",
            variable=self.t3_corr_mode,
            value="k_only",
        )
        rb_k.grid(row=5, column=0, columnspan=2, sticky="w", pady=(4, 1))

        ttk.Label(c1_grid, text="Xè½´ç±»å‹:").grid(row=6, column=0, sticky="e")
        cb_x = ttk.Combobox(c1_grid, textvariable=self.t3_x_mode, width=12, state="readonly")
        cb_x["values"] = ("auto", "q_A^-1", "chi_deg")
        cb_x.grid(row=6, column=1, padx=5, pady=1, sticky="w")
        ttk.Label(c1_grid, text="I0è¯­ä¹‰:", style="Hint.TLabel").grid(row=7, column=0, sticky="e")
        ttk.Label(c1_grid, textvariable=self.global_vars["monitor_mode"], style="Hint.TLabel").grid(row=7, column=1, sticky="w")

        self.add_tooltip(e_k, "å¿…é¡» >0ã€‚ä¼˜å…ˆä½¿ç”¨ Tab1 æœ€æ–°æ ‡å®šå€¼ã€‚")
        self.add_tooltip(rb_scaled, "é€‚åˆå¤–éƒ¨1Då·²åšè¿‡æœ¬åº•/å½’ä¸€åŒ–ï¼Œä»…éœ€ç»å¯¹å¼ºåº¦æ˜ å°„ã€‚")
        self.add_tooltip(rb_raw, "é€‚åˆå¤–éƒ¨1Dæ˜¯åŸå§‹ç§¯åˆ†å¼ºåº¦ï¼Œéœ€è¦åœ¨æœ¬é¡µå®Œæˆ1Dçº§æ‰£æœ¬åº•å’Œå½’ä¸€åŒ–ã€‚")
        self.add_tooltip(rb_kd, "é€‚ç”¨äºå¤–éƒ¨ç§¯åˆ†ç»“æœä»æ˜¯ç›¸å¯¹å¼ºåº¦ï¼ˆå°šæœªé™¤åšåº¦ï¼‰ã€‚")
        self.add_tooltip(e_thk, "ä»…åœ¨ K/d æ¨¡å¼ä¸‹ä½¿ç”¨ã€‚å•ä½ mmã€‚")
        self.add_tooltip(rb_k, "é€‚ç”¨äºå¤–éƒ¨ç§¯åˆ†ç»“æœå·²ç»åšäº†åšåº¦å½’ä¸€åŒ–ã€‚")
        self.add_tooltip(cb_x, "auto ä¼šæ ¹æ®åˆ—å/åç¼€æ¨æ–­ Q_A^-1 æˆ– Chi_degã€‚")

        c2 = ttk.LabelFrame(top, text="2. æ‰§è¡Œç­–ç•¥", style="Group.TLabelframe")
        c2.pack(side="left", fill="y", padx=5)
        self.add_hint(c2, "å»ºè®®å…ˆé¢„æ£€æŸ¥ã€‚å¯æ–­ç‚¹ç»­è·‘ï¼Œé¿å…é‡å¤è¦†ç›–ã€‚", wraplength=320)
        row_exec = ttk.Frame(c2)
        row_exec.pack(fill="x")
        cb_resume = ttk.Checkbutton(c2, text="æ–­ç‚¹ç»­è·‘(è·³è¿‡å·²å­˜åœ¨è¾“å‡º)", variable=self.t3_resume_enabled)
        cb_resume.pack(anchor="w")
        cb_overwrite = ttk.Checkbutton(c2, text="å¼ºåˆ¶è¦†ç›–è¾“å‡º", variable=self.t3_overwrite)
        cb_overwrite.pack(anchor="w")
        ttk.Label(
            row_exec,
            text="æ”¯æŒæ ¼å¼: .dat .txt .chi .csvï¼ˆåˆ—è‡³å°‘åŒ…å« X ä¸ Iï¼›Error å¯é€‰ï¼‰",
            style="Hint.TLabel",
            wraplength=320,
            justify="left",
        ).pack(anchor="w")
        self.add_tooltip(cb_resume, "è¾“å‡ºå­˜åœ¨æ—¶è·³è¿‡ï¼Œé€‚åˆå¤§æ‰¹é‡ä¸­æ–­åç»§ç»­ã€‚")
        self.add_tooltip(cb_overwrite, "å¿½ç•¥å·²å­˜åœ¨ç»“æœå¹¶é‡ç®—ã€‚")

        c3 = ttk.LabelFrame(top, text="3. åŸå§‹1Dæ ¡æ­£å‚æ•°ï¼ˆrawæµç¨‹ï¼‰", style="Group.TLabelframe")
        c3.pack(side="left", fill="y", padx=5)
        self.add_hint(
            c3,
            "ä»…å½“æµç¨‹=åŸå§‹1Då®Œæ•´æ ¡æ­£æ—¶ç”Ÿæ•ˆã€‚å¯ç›´æ¥ä½¿ç”¨ Tab2 çš„ batch_report.csv æˆ– metadata.csvã€‚",
            wraplength=420,
        )

        row_meta = self.add_file_row(c3, "Metadata CSV:", self.t3_meta_csv_path, "*.csv")
        row_bg = self.add_file_row(c3, "BG 1D æ–‡ä»¶:", self.t3_bg1d_path, "*.dat *.txt *.chi *.csv")
        row_dark = self.add_file_row(c3, "Dark 1D æ–‡ä»¶:", self.t3_dark1d_path, "*.dat *.txt *.chi *.csv")

        row_meta_ops = ttk.Frame(c3)
        row_meta_ops.pack(fill="x", pady=(1, 1))
        btn_meta_from_batch = ttk.Button(
            row_meta_ops,
            text="ç”± Tab2 æŠ¥å‘Šç”Ÿæˆ metadata",
            command=self.t3_make_meta_from_batch_report,
        )
        btn_meta_from_batch.pack(side="left", padx=(3, 0))

        self.add_tooltip(row_meta["entry"], "å¯é€‰ã€‚æ”¯æŒ metadata.csvï¼Œæˆ–ç›´æ¥é€‰æ‹© Tab2 çš„ batch_report.csvã€‚")
        self.add_tooltip(row_bg["entry"], "å¿…å¡«ï¼ˆrawæµç¨‹ï¼‰ã€‚ä¸æ ·å“åŒç§¯åˆ†æ–¹å¼å¾—åˆ°çš„ BG 1Dã€‚")
        self.add_tooltip(row_dark["entry"], "å¯é€‰ã€‚æœªæä¾›åˆ™æŒ‰ 0 å¤„ç†ã€‚")
        self.add_tooltip(btn_meta_from_batch, "ä» Tab2 çš„ batch_report.csv ä¸€é”®ç”Ÿæˆ Tab3 å¯ç”¨ metadata.csvï¼Œå¹¶è‡ªåŠ¨å›å¡«è·¯å¾„ã€‚")

        cb_meta_thk = ttk.Checkbutton(c3, text="ä¼˜å…ˆä½¿ç”¨ metadata ä¸­çš„ thk_mm", variable=self.t3_use_meta_thk)
        cb_meta_thk.pack(anchor="w", padx=3, pady=(2, 1))
        self.add_tooltip(cb_meta_thk, "å¼€å¯åï¼Œè‹¥æŸæ ·å“ metadata å« thk_mmï¼Œåˆ™è¦†ç›–å›ºå®šåšåº¦ã€‚")
        cb_sync_bg = ttk.Checkbutton(
            c3,
            text="BGå‚æ•°è·Ÿéš Tab1 å…¨å±€(bg_exp/bg_i0/bg_t)",
            variable=self.t3_sync_bg_from_global,
            command=self.on_t3_sync_bg_toggle,
        )
        cb_sync_bg.pack(anchor="w", padx=3, pady=(0, 1))
        self.add_tooltip(cb_sync_bg, "å¼€å¯å Tab3 çš„ BG å‚æ•°ä¼šéš Tab1/å…¨å±€å˜åŒ–è‡ªåŠ¨æ›´æ–°ï¼Œé¿å…é™ˆæ—§å€¼ã€‚")

        f_sample = ttk.Frame(c3)
        f_sample.pack(fill="x", pady=(2, 1))
        ttk.Label(f_sample, text="æ ·å“å›ºå®šå‚æ•° exp/i0/T:", style="Hint.TLabel").grid(row=0, column=0, columnspan=6, sticky="w")
        ttk.Label(f_sample, text="exp").grid(row=1, column=0, sticky="e")
        ttk.Entry(f_sample, textvariable=self.t3_sample_exp, width=7).grid(row=1, column=1, padx=2)
        ttk.Label(f_sample, text="i0").grid(row=1, column=2, sticky="e")
        ttk.Entry(f_sample, textvariable=self.t3_sample_i0, width=7).grid(row=1, column=3, padx=2)
        ttk.Label(f_sample, text="T").grid(row=1, column=4, sticky="e")
        ttk.Entry(f_sample, textvariable=self.t3_sample_t, width=7).grid(row=1, column=5, padx=2)

        f_bg = ttk.Frame(c3)
        f_bg.pack(fill="x", pady=(2, 1))
        ttk.Label(f_bg, text="BGå›ºå®šå‚æ•° exp/i0/T:", style="Hint.TLabel").grid(row=0, column=0, columnspan=6, sticky="w")
        ttk.Label(f_bg, text="exp").grid(row=1, column=0, sticky="e")
        self.t3_bg_entry_exp = ttk.Entry(f_bg, textvariable=self.t3_bg_exp, width=7)
        self.t3_bg_entry_exp.grid(row=1, column=1, padx=2)
        ttk.Label(f_bg, text="i0").grid(row=1, column=2, sticky="e")
        self.t3_bg_entry_i0 = ttk.Entry(f_bg, textvariable=self.t3_bg_i0, width=7)
        self.t3_bg_entry_i0.grid(row=1, column=3, padx=2)
        ttk.Label(f_bg, text="T").grid(row=1, column=4, sticky="e")
        self.t3_bg_entry_t = ttk.Entry(f_bg, textvariable=self.t3_bg_t, width=7)
        self.t3_bg_entry_t.grid(row=1, column=5, padx=2)

        mid = ttk.LabelFrame(p, text="å¤–éƒ¨ 1D æ–‡ä»¶é˜Ÿåˆ—", style="Group.TLabelframe")
        mid.pack(fill="both", expand=True, padx=10, pady=5)
        self.add_hint(mid, "å»ºè®®å…ˆç‚¹â€œé¢„æ£€æŸ¥â€ç¡®è®¤æ¯ä¸ªæ–‡ä»¶çš„åˆ—è§£ææƒ…å†µã€‚")

        tb = ttk.Frame(mid)
        tb.pack(fill="x")
        btn_add = ttk.Button(tb, text="æ·»åŠ 1Dæ–‡ä»¶", command=self.add_external_1d_files)
        btn_add.pack(side="left")
        btn_clear = ttk.Button(tb, text="æ¸…ç©ºé˜Ÿåˆ—", command=self.clear_external_1d_files)
        btn_clear.pack(side="left", padx=(4, 0))
        btn_check = ttk.Button(tb, text="é¢„æ£€æŸ¥", command=self.dry_run_external_1d)
        btn_check.pack(side="right")
        self.add_tooltip(btn_add, "æ”¯æŒå¤šé€‰å¤–éƒ¨ç§¯åˆ†ç»“æœæ–‡ä»¶ã€‚")
        self.add_tooltip(btn_clear, "ä»…æ¸…ç©ºé˜Ÿåˆ—ï¼Œä¸åˆ é™¤ç£ç›˜æ–‡ä»¶ã€‚")
        self.add_tooltip(btn_check, "æ£€æŸ¥åˆ—è¯†åˆ«ã€ç‚¹æ•°å’Œåæ ‡ç±»å‹æ¨æ–­ã€‚")

        ttk.Label(mid, textvariable=self.t3_queue_info, style="Hint.TLabel").pack(anchor="w", padx=5, pady=(2, 0))
        self.lb_ext1d = tk.Listbox(mid, height=9)
        self.lb_ext1d.pack(fill="both", expand=True, padx=5, pady=5)
        self.add_tooltip(self.lb_ext1d, "å½“å‰å¾…è½¬æ¢çš„å¤–éƒ¨1Dæ–‡ä»¶åˆ—è¡¨ã€‚")

        bot = ttk.Frame(p)
        bot.pack(fill="x", padx=10, pady=10)
        btn_run = ttk.Button(bot, text=">>> å¼€å§‹å¤–éƒ¨1Dç»å¯¹å¼ºåº¦æ ¡æ­£ <<<", command=self.run_external_1d_batch)
        btn_run.pack(fill="x", ipady=5)
        self.t3_prog_bar = ttk.Progressbar(bot, mode="determinate")
        self.t3_prog_bar.pack(fill="x", pady=5)
        row_out_dir = self.add_dir_row(bot, "è¾“å‡ºæ ¹ç›®å½•:", self.t3_output_root)
        ttk.Label(bot, textvariable=self.t3_out_hint, style="Hint.TLabel").pack(anchor="w")
        self.add_tooltip(btn_run, "å°†å¤–éƒ¨1Dç›¸å¯¹å¼ºåº¦æŒ‰é€‰å®šå…¬å¼æ‰¹é‡è½¬æ¢ä¸ºç»å¯¹å¼ºåº¦ã€‚")
        self.add_tooltip(self.t3_prog_bar, "æ˜¾ç¤ºå¤–éƒ¨1Dæ‰¹å¤„ç†è¿›åº¦ã€‚")
        self.add_tooltip(row_out_dir["entry"], "å¯é€‰ã€‚ä¸å¡«æ—¶é»˜è®¤è¾“å‡ºåˆ°é¦–ä¸ªè¾“å…¥æ–‡ä»¶æ‰€åœ¨ç›®å½•ã€‚")

        self.global_vars["bg_exp"].trace_add("write", self.on_global_bg_changed_for_t3)
        self.global_vars["bg_i0"].trace_add("write", self.on_global_bg_changed_for_t3)
        self.global_vars["bg_t"].trace_add("write", self.on_global_bg_changed_for_t3)
        self.t3_output_root.trace_add("write", lambda *_: self.refresh_external_1d_status())
        self.on_t3_sync_bg_toggle()
        self.refresh_external_1d_status()

    def add_external_1d_files(self):
        fs = filedialog.askopenfilenames(
            filetypes=[("1D Files", "*.dat *.txt *.chi *.csv"), ("All Files", "*.*")]
        )
        for f in fs:
            if f not in self.t3_files:
                self.t3_files.append(f)
                self.lb_ext1d.insert(tk.END, Path(f).name)
        self.refresh_external_1d_status()

    def clear_external_1d_files(self):
        self.t3_files = []
        self.lb_ext1d.delete(0, tk.END)
        self.refresh_external_1d_status()

    def refresh_external_1d_status(self):
        if hasattr(self, "t3_queue_info"):
            total = len(getattr(self, "t3_files", []))
            uniq = len(dict.fromkeys(getattr(self, "t3_files", [])))
            if total == uniq:
                self.t3_queue_info.set(f"é˜Ÿåˆ—æ–‡ä»¶: {uniq}")
            else:
                self.t3_queue_info.set(f"é˜Ÿåˆ—æ–‡ä»¶: {total}ï¼ˆå»é‡å {uniq}ï¼‰")

        if hasattr(self, "t3_out_hint"):
            custom_root = self.t3_output_root.get().strip() if hasattr(self, "t3_output_root") else ""
            if custom_root:
                self.t3_out_hint.set(
                    f"è¾“å‡ºç›®å½•å°†å†™å…¥: {custom_root}\\processed_external_1d_abs "
                    f"(æŠ¥å‘Š: {custom_root}\\processed_external_1d_reports)"
                )
            else:
                self.t3_out_hint.set("è¾“å‡ºç›®å½•å°†è‡ªåŠ¨åˆ›å»º: processed_external_1d_absï¼ˆé»˜è®¤ä½äºé¦–ä¸ªæ ·å“ç›®å½•ï¼‰")

    def sync_t3_bg_params_from_global(self):
        if not hasattr(self, "global_vars"):
            return
        try:
            self.t3_bg_exp.set(float(self.global_vars["bg_exp"].get()))
            self.t3_bg_i0.set(float(self.global_vars["bg_i0"].get()))
            self.t3_bg_t.set(float(self.global_vars["bg_t"].get()))
        except Exception:
            pass

    def on_global_bg_changed_for_t3(self, *_):
        if hasattr(self, "t3_sync_bg_from_global") and bool(self.t3_sync_bg_from_global.get()):
            self.sync_t3_bg_params_from_global()

    def on_t3_sync_bg_toggle(self):
        follow = bool(self.t3_sync_bg_from_global.get()) if hasattr(self, "t3_sync_bg_from_global") else False
        if follow:
            self.sync_t3_bg_params_from_global()
        state = "disabled" if follow else "normal"
        for w in [
            getattr(self, "t3_bg_entry_exp", None),
            getattr(self, "t3_bg_entry_i0", None),
            getattr(self, "t3_bg_entry_t", None),
        ]:
            if w is not None:
                try:
                    w.configure(state=state)
                except Exception:
                    pass

    def read_external_1d_profile(self, path):
        dfs = []
        errs = []
        read_trials = [
            {"sep": None, "engine": "python", "comment": "#"},
            {"sep": r"[,\s;]+", "engine": "python", "comment": "#"},
            {"sep": r"[,\s;]+", "engine": "python", "comment": "#", "header": None},
        ]

        for kw in read_trials:
            try:
                df = pd.read_csv(path, **kw)
                if df is not None and not df.empty and df.shape[1] >= 2:
                    dfs.append(df)
            except Exception as e:
                errs.append(str(e))

        if not dfs:
            raise ValueError(f"æ— æ³•è§£ææ–‡ä»¶: {Path(path).name} ({'; '.join(errs[:2])})")

        best = None
        best_pts = -1

        for df in dfs:
            numeric_cols = {}
            for col in df.columns:
                s = pd.to_numeric(df[col], errors="coerce")
                arr = s.to_numpy(dtype=np.float64, na_value=np.nan)
                cnt = int(np.isfinite(arr).sum())
                if cnt >= 3:
                    numeric_cols[col] = s

            if len(numeric_cols) < 2:
                continue

            cols = list(numeric_cols.keys())

            def pick(tokens, used):
                for c in cols:
                    if c in used:
                        continue
                    name = str(c).strip().lower().replace("_", "").replace(" ", "")
                    if any(t in name for t in tokens):
                        return c
                return None

            x_col = pick(["q", "chi", "radial", "2theta", "x"], set()) or cols[0]
            i_col = pick(["intensity", "irel", "iabs", "signal", "count", "i"], {x_col})
            if i_col is None:
                i_col = next((c for c in cols if c != x_col), None)
            if i_col is None:
                continue

            err_col = pick(["error", "sigma", "std", "unc"], {x_col, i_col})
            if err_col is None and len(cols) >= 3:
                err_col = next((c for c in cols if c not in {x_col, i_col}), None)

            x = pd.to_numeric(df[x_col], errors="coerce").to_numpy(dtype=np.float64, na_value=np.nan)
            i_rel = pd.to_numeric(df[i_col], errors="coerce").to_numpy(dtype=np.float64, na_value=np.nan)
            mask = np.isfinite(x) & np.isfinite(i_rel)
            if int(mask.sum()) < 3:
                continue

            x = x[mask]
            i_rel = i_rel[mask]
            if err_col is not None:
                err = pd.to_numeric(df[err_col], errors="coerce").to_numpy(dtype=np.float64, na_value=np.nan)[mask]
                err = np.where(np.isfinite(err), err, np.nan)
            else:
                err = np.full_like(i_rel, np.nan, dtype=np.float64)

            order = np.argsort(x)
            x = x[order]
            i_rel = i_rel[order]
            err = err[order]

            pts = int(x.size)
            if pts > best_pts:
                best_pts = pts
                best = {
                    "x": x,
                    "i_rel": i_rel,
                    "err_rel": err,
                    "x_col": str(x_col),
                    "i_col": str(i_col),
                    "err_col": str(err_col) if err_col is not None else "",
                }

        if best is None:
            raise ValueError(f"æ— æ³•ä» {Path(path).name} è¯†åˆ«æœ‰æ•ˆæ•°å€¼åˆ—ï¼ˆè‡³å°‘éœ€è¦ X å’Œ I ä¸¤åˆ—ï¼‰")
        return best

    def _regularize_xy_triplet(self, x, y, e=None, min_points=3, name="profile"):
        x = np.asarray(x, dtype=np.float64)
        y = np.asarray(y, dtype=np.float64)
        if e is None:
            e = np.full_like(y, np.nan, dtype=np.float64)
        else:
            e = np.asarray(e, dtype=np.float64)

        if x.shape != y.shape:
            raise ValueError(f"{name}: x/y å½¢çŠ¶ä¸ä¸€è‡´ã€‚")
        if e.shape != x.shape:
            e = np.full_like(y, np.nan, dtype=np.float64)

        mask = np.isfinite(x) & np.isfinite(y)
        x = x[mask]
        y = y[mask]
        e = e[mask]
        if x.size < min_points:
            raise ValueError(f"{name}: æœ‰æ•ˆç‚¹æ•°ä¸è¶³ï¼ˆ<{min_points}ï¼‰ã€‚")

        order = np.argsort(x)
        x = x[order]
        y = y[order]
        e = e[order]

        # Collapse duplicate x values by averaging to build a stable monotonic grid.
        ux, inv = np.unique(x, return_inverse=True)
        if ux.size != x.size:
            y_sum = np.zeros_like(ux, dtype=np.float64)
            cnt = np.zeros_like(ux, dtype=np.float64)
            e_sum = np.zeros_like(ux, dtype=np.float64)
            e_cnt = np.zeros_like(ux, dtype=np.float64)
            for i, g in enumerate(inv):
                y_sum[g] += y[i]
                cnt[g] += 1.0
                if np.isfinite(e[i]):
                    e_sum[g] += e[i]
                    e_cnt[g] += 1.0
            y = y_sum / np.clip(cnt, 1.0, None)
            e = np.where(e_cnt > 0, e_sum / np.clip(e_cnt, 1.0, None), np.nan)
            x = ux

        if x.size < min_points:
            raise ValueError(f"{name}: å»é‡åæœ‰æ•ˆç‚¹æ•°ä¸è¶³ï¼ˆ<{min_points}ï¼‰ã€‚")
        return x, y, e

    def infer_external_x_label(self, path, profile):
        mode = self.t3_x_mode.get().strip().lower()
        if mode == "q_a^-1":
            return "Q_A^-1"
        if mode == "chi_deg":
            return "Chi_deg"

        name = f"{profile.get('x_col', '')}".lower()
        fname = Path(path).name.lower()
        if ("chi" in name) or fname.endswith(".chi"):
            return "Chi_deg"
        return "Q_A^-1"

    def parse_mode_outputs(self, outputs_raw):
        if outputs_raw is None:
            return []
        if isinstance(outputs_raw, (int, float, np.number)) and not np.isfinite(outputs_raw):
            return []

        s = str(outputs_raw).strip()
        if not s or s.lower() in {"nan", "none", "null"}:
            return []

        out = []
        for part in s.split("|"):
            item = str(part).strip()
            if not item:
                continue
            m = re.match(
                r"^(1d_full|1d_sector(?:\[[^\]]+\])?|1d_sector_sum|radial_chi)\s*:\s*(.+)$",
                item,
                flags=re.IGNORECASE,
            )
            if m:
                item = m.group(2).strip()
            item = re.sub(r"\(existing\)\s*$", "", item, flags=re.IGNORECASE).strip()
            if item:
                out.append(item)
        return out

    def collect_external_meta_rows(self, df):
        if df is None or df.empty:
            return [], {}

        col_map = {}
        for c in df.columns:
            col_map[self._norm_key(c)] = c

        def pick(names):
            for n in names:
                if n in col_map:
                    return col_map[n]
            return None

        file_col = pick(["file", "filename", "name", "path", "sample", "samplename"])
        outputs_col = pick(["outputs", "output", "result", "results"])
        if file_col is None and outputs_col is None:
            raise ValueError("metadata CSV ç¼ºå°‘æ–‡ä»¶åˆ—ï¼ˆfile/filename/name/pathï¼‰æˆ–è¾“å‡ºåˆ—ï¼ˆoutputsï¼‰ã€‚")

        exp_col = pick(["exp", "exposure", "exposuretime", "exposures", "counttime", "time", "exposures"])
        mon_col = pick(["i0", "mon", "monitor", "beammonitor", "flux"])
        trans_col = pick(["trans", "transmission", "sampletransmission", "abs"])
        thk_mm_col = pick(["thkmm", "thicknessmm", "thickness", "dmm", "calcthkmm", "fixedthicknessmm"])
        thk_cm_col = pick(["thkcm", "thicknesscm", "dcm"])

        out_map = {}
        rows = []
        for _, row in df.iterrows():
            names = []

            if file_col is not None:
                raw_file = str(row.get(file_col, "")).strip()
                if raw_file:
                    names.append(raw_file)
            if outputs_col is not None:
                names.extend(self.parse_mode_outputs(row.get(outputs_col)))

            uniq_names = []
            seen = set()
            for nm in names:
                nm_s = str(nm).strip()
                if not nm_s:
                    continue
                nk = nm_s.lower()
                if nk in seen:
                    continue
                seen.add(nk)
                uniq_names.append(nm_s)

            if not uniq_names:
                continue

            raw_exp = row.get(exp_col) if exp_col is not None else None
            raw_mon = row.get(mon_col) if mon_col is not None else None
            raw_trans = row.get(trans_col) if trans_col is not None else None
            raw_thk_mm = row.get(thk_mm_col) if thk_mm_col is not None else None
            raw_thk_cm = row.get(thk_cm_col) if thk_cm_col is not None else None

            exp = self._extract_float(raw_exp)
            mon = self._extract_float(raw_mon)
            trans = self._extract_float(raw_trans)
            if trans is not None:
                trans = self._normalize_transmission(trans, raw=raw_trans, key=trans_col)

            thk_mm = self._extract_float(raw_thk_mm)
            if thk_mm is None:
                thk_cm = self._extract_float(raw_thk_cm)
                if thk_cm is not None:
                    thk_mm = thk_cm * 10.0

            meta = {"exp": exp, "mon": mon, "trans": trans, "thk_mm": thk_mm}
            for nm in uniq_names:
                p = Path(nm)
                aliases = {str(nm).lower(), p.name.lower(), p.stem.lower()}
                for a in aliases:
                    if a:
                        out_map[a] = meta
                rows.append({
                    "file": str(nm).strip(),
                    "exp": exp if exp is not None else np.nan,
                    "i0": mon if mon is not None else np.nan,
                    "trans": trans if trans is not None else np.nan,
                    "thk_mm": thk_mm if thk_mm is not None else np.nan,
                })

        if rows:
            df_rows = pd.DataFrame(rows)
            if "file" in df_rows.columns:
                df_rows["file"] = df_rows["file"].astype(str).str.strip()
                df_rows = df_rows[df_rows["file"] != ""]
                df_rows["_k"] = df_rows["file"].str.lower()
                df_rows = df_rows.drop_duplicates(subset=["_k"], keep="last").drop(columns=["_k"])
            rows = df_rows.to_dict("records")

        return rows, out_map

    def export_tab3_metadata_from_report(self, report_csv_path, stamp=None):
        report_path = Path(report_csv_path)
        if not report_path.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ°æŠ¥å‘Šæ–‡ä»¶: {report_path}")

        try:
            df = pd.read_csv(report_path, sep=None, engine="python")
        except Exception:
            df = pd.read_csv(report_path)

        rows, _ = self.collect_external_meta_rows(df)
        if not rows:
            raise ValueError("æœªä»æŠ¥å‘Šä¸­æå–åˆ°å¯ç”¨ metadata è¡Œã€‚")

        out_df = pd.DataFrame(rows)
        for c in ["file", "exp", "i0", "trans", "thk_mm"]:
            if c not in out_df.columns:
                out_df[c] = np.nan
        out_df = out_df[["file", "exp", "i0", "trans", "thk_mm"]]

        out_df["file"] = out_df["file"].astype(str).str.strip()
        out_df = out_df[out_df["file"] != ""]
        if out_df.empty:
            raise ValueError("metadata è¡Œä¸ºç©ºï¼šæœªè¯†åˆ«åˆ°æ–‡ä»¶åã€‚")

        out_df["_k"] = out_df["file"].str.lower()
        out_df = out_df.drop_duplicates(subset=["_k"], keep="last").drop(columns=["_k"])
        out_df = out_df.sort_values("file").reset_index(drop=True)

        if not stamp:
            stamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")

        out_dir = report_path.parent
        out_stamp = out_dir / f"metadata_for_tab3_{stamp}.csv"
        out_latest = out_dir / "metadata.csv"
        out_df.to_csv(out_stamp, index=False, encoding="utf-8-sig")
        out_df.to_csv(out_latest, index=False, encoding="utf-8-sig")
        return out_stamp, out_latest, int(len(out_df))

    def t3_make_meta_from_batch_report(self):
        try:
            report_path = filedialog.askopenfilename(
                filetypes=[("Batch Report", "batch_report_*.csv"), ("CSV", "*.csv"), ("All Files", "*.*")]
            )
            if not report_path:
                return
            out_stamp, out_latest, n_rows = self.export_tab3_metadata_from_report(report_path)
            self.t3_meta_csv_path.set(str(out_latest))
            messagebox.showinfo(
                "metadata å·²ç”Ÿæˆ",
                (
                    f"å·²ä»æŠ¥å‘Šç”Ÿæˆ metadataã€‚\n"
                    f"è¡Œæ•°: {n_rows}\n"
                    f"æ—¶é—´æˆ³æ–‡ä»¶: {out_stamp.name}\n"
                    f"é»˜è®¤æ–‡ä»¶: {out_latest.name}\n"
                    f"Tab3 å°†ä½¿ç”¨: {out_latest}"
                ),
            )
        except Exception as e:
            messagebox.showerror("ç”Ÿæˆ metadata å¤±è´¥", f"{e}\n{traceback.format_exc()}")

    def load_external_meta_map(self, csv_path):
        if not csv_path:
            return {}

        try:
            df = pd.read_csv(csv_path, sep=None, engine="python")
        except Exception:
            df = pd.read_csv(csv_path)

        if df is None or df.empty:
            return {}
        _, out_map = self.collect_external_meta_rows(df)
        return out_map

    def get_external_meta_for_file(self, meta_map, file_path):
        if not meta_map:
            return None
        p = Path(file_path)

        def norm_path(s):
            return str(s).strip().replace("\\", "/").lower()

        full_key = norm_path(file_path)
        if full_key in meta_map:
            return meta_map[full_key]

        # å…¼å®¹ metadata ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ˆä¾‹å¦‚ sector_01/sample.datï¼‰ï¼Œè€Œå®é™…æ–‡ä»¶æ˜¯ç»å¯¹è·¯å¾„ã€‚
        suffix_hits = []
        for k in meta_map.keys():
            ks = norm_path(k)
            if "/" not in ks:
                continue
            if full_key.endswith("/" + ks) or full_key.endswith(ks):
                suffix_hits.append((len(ks), k))
        if suffix_hits:
            suffix_hits.sort(reverse=True)
            return meta_map[suffix_hits[0][1]]

        candidates = [p.name.lower(), p.stem.lower()]
        for c in candidates:
            if c in meta_map:
                return meta_map[c]
        return None

    def parse_external_1d_header_meta(self, file_path):
        meta = {}
        try:
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                for _ in range(200):
                    line = f.readline()
                    if not line:
                        break
                    s = line.strip()
                    if not s:
                        continue
                    if not s.startswith(("#", ";", "//")):
                        break
                    s = s.lstrip("#;/ ").strip()
                    if not s:
                        continue
                    if "=" in s:
                        k, v = s.split("=", 1)
                    elif ":" in s:
                        k, v = s.split(":", 1)
                    else:
                        parts = s.split(None, 1)
                        if len(parts) != 2:
                            continue
                        k, v = parts
                    nk = self._norm_key(k)
                    if nk:
                        meta[nk] = v.strip()
        except Exception:
            return {"exp": None, "mon": None, "trans": None, "thk_mm": None}

        exp_raw, exp_key = self.meta_get_raw(meta, ["exposuretime", "counttime", "acqtime", "exposure", "time", "exp"])
        mon_raw, _ = self.meta_get_raw(meta, ["monitor", "beammonitor", "ionchamber", "mon", "i0", "flux"])
        trans_raw, trans_key = self.meta_get_raw(meta, ["sampletransmission", "transmission", "trans", "abs"])
        thk_raw, _ = self.meta_get_raw(meta, ["thkmm", "thicknessmm", "thickness", "dmm"])

        exp = self._extract_float(exp_raw)
        if exp is not None:
            tag = f"{exp_key or ''} {exp_raw or ''}".lower()
            if "ms" in tag:
                exp /= 1000.0
            elif "us" in tag:
                exp /= 1_000_000.0
        mon = self._extract_float(mon_raw)
        trans = self._extract_float(trans_raw)
        if trans is not None:
            trans = self._normalize_transmission(trans, raw=trans_raw, key=trans_key)
        thk_mm = self._extract_float(thk_raw)

        return {"exp": exp, "mon": mon, "trans": trans, "thk_mm": thk_mm}

    def align_profile_to_x(self, x_target, ref_profile, name):
        x = np.asarray(x_target, dtype=np.float64)
        if not np.all(np.isfinite(x)):
            raise ValueError(f"{name} ç›®æ ‡ x ç½‘æ ¼åŒ…å«éæœ‰é™å€¼ã€‚")

        xr, yr, er = self._regularize_xy_triplet(
            ref_profile["x"],
            ref_profile["i_rel"],
            ref_profile.get("err_rel"),
            min_points=2,
            name=name,
        )

        if xr.size == x.size and np.allclose(xr, x, rtol=1e-7, atol=1e-9, equal_nan=False):
            y = yr
            e = er
        else:
            y = np.interp(x, xr, yr, left=np.nan, right=np.nan)
            finite_err = np.isfinite(er)
            if np.sum(finite_err) >= 2:
                e = np.interp(x, xr[finite_err], er[finite_err], left=np.nan, right=np.nan)
            else:
                e = np.full_like(y, np.nan)

        outside = int(np.sum(~np.isfinite(y)))
        return y, e, outside

    def resolve_external_sample_params(self, file_path, meta_map, monitor_mode):
        meta = self.get_external_meta_for_file(meta_map, file_path)
        hmeta = self.parse_external_1d_header_meta(file_path)

        exp = None
        mon = None
        trans = None
        thk_mm_meta = None
        source = "fixed"

        if meta is not None:
            if meta.get("exp") is not None:
                exp = meta["exp"]
            if meta.get("mon") is not None:
                mon = meta["mon"]
            if meta.get("trans") is not None:
                trans = meta["trans"]
            thk_mm_meta = meta.get("thk_mm")
            source = "meta"

        if hmeta is not None:
            if exp is None and hmeta.get("exp") is not None:
                exp = hmeta["exp"]
                if source != "meta":
                    source = "header"
            if mon is None and hmeta.get("mon") is not None:
                mon = hmeta["mon"]
                if source != "meta":
                    source = "header"
            if trans is None and hmeta.get("trans") is not None:
                trans = hmeta["trans"]
                if source != "meta":
                    source = "header"
            if thk_mm_meta is None and hmeta.get("thk_mm") is not None:
                thk_mm_meta = hmeta["thk_mm"]
                if source == "fixed":
                    source = "header"

        if exp is None:
            exp = self.t3_sample_exp.get()
        if mon is None:
            mon = self.t3_sample_i0.get()
        if trans is None:
            trans = self.t3_sample_t.get()

        norm = self.compute_norm_factor(exp, mon, trans, monitor_mode)
        return {
            "exp": exp,
            "mon": mon,
            "trans": trans,
            "norm": norm,
            "thk_mm_meta": thk_mm_meta,
            "source": source,
        }

    def dry_run_external_1d(self):
        if not self.t3_files:
            messagebox.showinfo("é¢„æ£€æŸ¥", "é˜Ÿåˆ—ä¸ºç©ºï¼Œè¯·å…ˆæ·»åŠ å¤–éƒ¨1Dæ–‡ä»¶ã€‚")
            return

        rows = []
        files = list(dict.fromkeys(self.t3_files))
        pipeline_mode = self.t3_pipeline_mode.get().strip().lower()
        mode = self.t3_corr_mode.get()
        k = float(self.global_vars["k_factor"].get())
        thk_mm = float(self.t3_fixed_thk.get())
        monitor_mode = self.get_monitor_mode()
        warnings = []

        if k <= 0:
            warnings.append("K å› å­ <= 0ã€‚")
        if mode == "k_over_d" and thk_mm <= 0:
            warnings.append("K/d æ¨¡å¼ä¸‹å›ºå®šåšåº¦å¿…é¡» > 0 mmã€‚")

        meta_map = {}
        bg_prof = None
        dark_prof = None
        bg_norm = np.nan
        if pipeline_mode == "raw":
            meta_path = self.t3_meta_csv_path.get().strip()
            if meta_path:
                try:
                    meta_map = self.load_external_meta_map(meta_path)
                except Exception as e:
                    warnings.append(f"metadata CSV è¯»å–å¤±è´¥: {e}")
            else:
                warnings.append("rawæµç¨‹æœªæä¾› metadata CSVï¼Œå°†å…¨éƒ¨ä½¿ç”¨å›ºå®šæ ·å“å‚æ•°ã€‚")

            bg_path = self.t3_bg1d_path.get().strip()
            if not bg_path:
                warnings.append("rawæµç¨‹ç¼ºå°‘ BG 1D æ–‡ä»¶ã€‚")
            else:
                try:
                    bg_prof = self.read_external_1d_profile(bg_path)
                except Exception as e:
                    warnings.append(f"BG 1D è¯»å–å¤±è´¥: {e}")

            dark_path = self.t3_dark1d_path.get().strip()
            if dark_path:
                try:
                    dark_prof = self.read_external_1d_profile(dark_path)
                except Exception as e:
                    warnings.append(f"Dark 1D è¯»å–å¤±è´¥: {e}")

            bg_norm = self.compute_norm_factor(
                self.t3_bg_exp.get(), self.t3_bg_i0.get(), self.t3_bg_t.get(), monitor_mode
            )
            if (not np.isfinite(bg_norm) or bg_norm <= 0) and bg_path:
                bg_h = self.parse_external_1d_header_meta(bg_path)
                bg_norm = self.compute_norm_factor(bg_h.get("exp"), bg_h.get("mon"), bg_h.get("trans"), monitor_mode)
            if not np.isfinite(bg_norm) or bg_norm <= 0:
                warnings.append("BG å½’ä¸€åŒ–å› å­ <=0ï¼Œè¯·æ£€æŸ¥ BG exp/i0/Tã€‚")

        for fp in files:
            try:
                prof = self.read_external_1d_profile(fp)
                x_label = self.infer_external_x_label(fp, prof)
                status = "æ­£å¸¸"
                reason = ""
                norm_s = np.nan
                thk_used = np.nan
                meta_src = "-"
                outside_bg = 0
                outside_dark = 0

                if pipeline_mode == "raw":
                    sp = self.resolve_external_sample_params(fp, meta_map, monitor_mode)
                    norm_s = sp["norm"]
                    meta_src = sp["source"]
                    if not np.isfinite(norm_s) or norm_s <= 0:
                        status = "å¤±è´¥"
                        reason = "æ ·å“å½’ä¸€åŒ–å› å­æ— æ•ˆï¼ˆexp/i0/Tï¼‰"
                    else:
                        if mode == "k_over_d":
                            thk_use_mm = thk_mm
                            if self.t3_use_meta_thk.get() and sp["thk_mm_meta"] is not None:
                                thk_use_mm = float(sp["thk_mm_meta"])
                            thk_used = thk_use_mm / 10.0 if np.isfinite(thk_use_mm) else np.nan
                            if not np.isfinite(thk_used) or thk_used <= 0:
                                status = "å¤±è´¥"
                                reason = "åšåº¦æ— æ•ˆï¼ˆå›ºå®šåšåº¦æˆ–metadata thk_mmï¼‰"
                        else:
                            thk_used = np.nan

                        if status == "æ­£å¸¸" and bg_prof is not None:
                            _, _, outside_bg = self.align_profile_to_x(prof["x"], bg_prof, "BG")
                        if status == "æ­£å¸¸" and dark_prof is not None:
                            _, _, outside_dark = self.align_profile_to_x(prof["x"], dark_prof, "Dark")

                rows.append({
                    "File": Path(fp).name,
                    "Points": len(prof["x"]),
                    "XCol": prof.get("x_col", ""),
                    "ICol": prof.get("i_col", ""),
                    "ErrCol": prof.get("err_col", ""),
                    "XLabel": x_label,
                    "Norm_s": norm_s,
                    "Thk_cm": thk_used,
                    "MetaSrc": meta_src,
                    "BG_OutsidePts": outside_bg,
                    "Dark_OutsidePts": outside_dark,
                    "Status": status,
                    "Reason": reason,
                })
            except Exception as e:
                rows.append({
                    "File": Path(fp).name,
                    "Points": 0,
                    "XCol": "",
                    "ICol": "",
                    "ErrCol": "",
                    "XLabel": "",
                    "Norm_s": np.nan,
                    "Thk_cm": np.nan,
                    "MetaSrc": "-",
                    "BG_OutsidePts": 0,
                    "Dark_OutsidePts": 0,
                    "Status": "å¤±è´¥",
                    "Reason": str(e),
                })

        top = tk.Toplevel(self.root)
        top.title("å¤–éƒ¨1Dé¢„æ£€æŸ¥ç»“æœ")
        txt = tk.Text(top, font=("Consolas", 9))
        txt.pack(fill="both", expand=True)
        txt.insert(tk.END, f"K å› å­: {k}\n")
        txt.insert(tk.END, f"æµç¨‹: {pipeline_mode}\n")
        txt.insert(tk.END, f"æ ¡æ­£æ¨¡å¼: {mode}\n")
        txt.insert(tk.END, f"å›ºå®šåšåº¦(mm): {thk_mm}\n")
        txt.insert(tk.END, f"Xè½´æ¨¡å¼: {self.t3_x_mode.get()}\n")
        if pipeline_mode == "raw":
            txt.insert(tk.END, f"I0è¯­ä¹‰: {monitor_mode} (norm={self.monitor_norm_formula(monitor_mode)})\n")
            txt.insert(tk.END, f"BG_Norm: {bg_norm if np.isfinite(bg_norm) else 'NaN'}\n")
        txt.insert(tk.END, "-" * 80 + "\n")
        if warnings:
            txt.insert(tk.END, "[é¢„æ£€æŸ¥è­¦å‘Š]\n")
            for w in warnings:
                txt.insert(tk.END, f"- {w}\n")
            txt.insert(tk.END, "-" * 80 + "\n")
        else:
            txt.insert(tk.END, "[é¢„æ£€æŸ¥é€šè¿‡] å‚æ•°æœªè§æ˜æ˜¾é—®é¢˜ã€‚\n")
            txt.insert(tk.END, "-" * 80 + "\n")
        txt.insert(tk.END, pd.DataFrame(rows).to_string(index=False))

    def run_external_1d_batch(self):
        try:
            if not self.t3_files:
                raise ValueError("é˜Ÿåˆ—ä¸ºç©ºï¼šè¯·å…ˆæ·»åŠ å¤–éƒ¨1Dæ–‡ä»¶ã€‚")

            files = list(dict.fromkeys(self.t3_files))
            if len(files) < len(self.t3_files):
                self.t3_files = files
                self.lb_ext1d.delete(0, tk.END)
                for f in self.t3_files:
                    self.lb_ext1d.insert(tk.END, Path(f).name)
                self.refresh_external_1d_status()

            k = float(self.global_vars["k_factor"].get())
            if not np.isfinite(k) or k <= 0:
                raise ValueError("K å› å­æ— æ•ˆï¼ˆå¿…é¡» > 0ï¼‰ã€‚")

            pipeline_mode = self.t3_pipeline_mode.get().strip().lower()
            if pipeline_mode not in ("scaled", "raw"):
                raise ValueError(f"æœªçŸ¥æµç¨‹æ¨¡å¼: {pipeline_mode}")

            corr_mode = self.t3_corr_mode.get().strip().lower()
            if corr_mode not in ("k_over_d", "k_only"):
                raise ValueError(f"æœªçŸ¥æ ¡æ­£æ¨¡å¼: {corr_mode}")

            fixed_thk_mm = float(self.t3_fixed_thk.get())
            if corr_mode == "k_over_d" and fixed_thk_mm <= 0:
                raise ValueError("K/d æ¨¡å¼ä¸‹å›ºå®šåšåº¦å¿…é¡» > 0 mmã€‚")

            fixed_thk_cm = fixed_thk_mm / 10.0 if corr_mode == "k_over_d" else np.nan
            scale_factor_global = (k / fixed_thk_cm) if corr_mode == "k_over_d" else k
            monitor_mode = self.get_monitor_mode()

            meta_map = {}
            bg_prof = None
            dark_prof = None
            bg_norm = np.nan
            if pipeline_mode == "raw":
                meta_path = self.t3_meta_csv_path.get().strip()
                if meta_path:
                    meta_map = self.load_external_meta_map(meta_path)

                bg_path = self.t3_bg1d_path.get().strip()
                if not bg_path:
                    raise ValueError("rawæµç¨‹å¿…é¡»æä¾› BG 1D æ–‡ä»¶ã€‚")
                bg_prof = self.read_external_1d_profile(bg_path)

                dark_path = self.t3_dark1d_path.get().strip()
                if dark_path:
                    dark_prof = self.read_external_1d_profile(dark_path)

                bg_norm = self.compute_norm_factor(
                    self.t3_bg_exp.get(), self.t3_bg_i0.get(), self.t3_bg_t.get(), monitor_mode
                )
                if (not np.isfinite(bg_norm) or bg_norm <= 0) and bg_path:
                    bg_h = self.parse_external_1d_header_meta(bg_path)
                    bg_norm = self.compute_norm_factor(bg_h.get("exp"), bg_h.get("mon"), bg_h.get("trans"), monitor_mode)
                if not np.isfinite(bg_norm) or bg_norm <= 0:
                    raise ValueError("rawæµç¨‹ä¸‹ BG å½’ä¸€åŒ–å› å­æ— æ•ˆï¼Œè¯·æ£€æŸ¥ BG exp/i0/Tã€‚")

            custom_out_root = self.t3_output_root.get().strip() if hasattr(self, "t3_output_root") else ""
            if custom_out_root:
                out_root = Path(custom_out_root).expanduser()
                out_root.mkdir(parents=True, exist_ok=True)
            else:
                out_root = Path(files[0]).parent
            out_dir = out_root / "processed_external_1d_abs"
            report_dir = out_root / "processed_external_1d_reports"
            out_dir.mkdir(parents=True, exist_ok=True)
            report_dir.mkdir(parents=True, exist_ok=True)

            resume = bool(self.t3_resume_enabled.get())
            overwrite = bool(self.t3_overwrite.get())
            stem_map = self.build_output_stem_map(files)

            self.t3_prog_bar["maximum"] = len(files)
            self.t3_prog_bar["value"] = 0

            rows = []
            ok = 0
            skip = 0
            fail = 0
            processed = 0

            for idx, fp in enumerate(files):
                fname = Path(fp).name
                reason = ""
                outputs = ""
                points = 0
                x_label = ""
                scale_factor = scale_factor_global if pipeline_mode == "scaled" else np.nan
                thk_cm_used = fixed_thk_cm if pipeline_mode == "scaled" else np.nan
                norm_s = np.nan
                meta_source = "-"
                outside_bg = 0
                outside_dark = 0
                try:
                    prof = self.read_external_1d_profile(fp)
                    points = len(prof["x"])
                    x_label = self.infer_external_x_label(fp, prof)
                    ext = ".chi" if x_label == "Chi_deg" else ".dat"
                    out_path = out_dir / f"{stem_map[fp]}{ext}"

                    if resume and (not overwrite) and out_path.exists():
                        status = "å·²è·³è¿‡"
                        reason = "è¾“å‡ºå·²å­˜åœ¨"
                        outputs = out_path.name
                        skip += 1
                    else:
                        if pipeline_mode == "scaled":
                            scale_factor = scale_factor_global
                            thk_cm_used = fixed_thk_cm
                            i_abs = np.asarray(prof["i_rel"], dtype=np.float64) * scale_factor
                            err_abs = np.asarray(prof["err_rel"], dtype=np.float64) * abs(scale_factor)
                        else:
                            sp = self.resolve_external_sample_params(fp, meta_map, monitor_mode)
                            norm_s = sp["norm"]
                            meta_source = sp["source"]
                            if not np.isfinite(norm_s) or norm_s <= 0:
                                raise ValueError("æ ·å“å½’ä¸€åŒ–å› å­æ— æ•ˆï¼ˆexp/i0/Tï¼‰")

                            if corr_mode == "k_over_d":
                                thk_use_mm = fixed_thk_mm
                                if self.t3_use_meta_thk.get() and sp["thk_mm_meta"] is not None:
                                    thk_use_mm = float(sp["thk_mm_meta"])
                                thk_cm_used = float(thk_use_mm) / 10.0
                                if not np.isfinite(thk_cm_used) or thk_cm_used <= 0:
                                    raise ValueError("åšåº¦æ— æ•ˆï¼ˆå›ºå®šåšåº¦æˆ–metadata thk_mmï¼‰")
                                scale_factor = k / thk_cm_used
                            else:
                                thk_cm_used = np.nan
                                scale_factor = k

                            s_i = np.asarray(prof["i_rel"], dtype=np.float64)
                            s_e = np.asarray(prof["err_rel"], dtype=np.float64)
                            x = np.asarray(prof["x"], dtype=np.float64)

                            bg_i, bg_e, outside_bg = self.align_profile_to_x(x, bg_prof, "BG")
                            if dark_prof is not None:
                                d_i, d_e, outside_dark = self.align_profile_to_x(x, dark_prof, "Dark")
                            else:
                                d_i = np.zeros_like(s_i)
                                d_e = np.full_like(s_i, np.nan)

                            net = (s_i - d_i) / norm_s - (bg_i - d_i) / bg_norm

                            if np.all(~np.isfinite(net)):
                                raise ValueError("å‡€ä¿¡å·å…¨éƒ¨ä¸ºæ— æ•ˆå€¼ï¼Œæ— æ³•è¾“å‡ºã€‚")

                            if np.any(np.isfinite(s_e)) or np.any(np.isfinite(bg_e)) or np.any(np.isfinite(d_e)):
                                s_term = (np.nan_to_num(s_e, nan=0.0) / norm_s) ** 2
                                bg_term = (np.nan_to_num(bg_e, nan=0.0) / bg_norm) ** 2
                                d_term = (np.nan_to_num(d_e, nan=0.0) * (1.0 / norm_s + 1.0 / bg_norm)) ** 2
                                net_err = np.sqrt(s_term + bg_term + d_term)
                                net_err[~np.isfinite(net)] = np.nan
                            else:
                                net_err = np.full_like(net, np.nan)

                            i_abs = net * scale_factor
                            err_abs = net_err * abs(scale_factor)

                            issue = self.profile_health_issue(i_abs)
                            if issue:
                                raise ValueError(issue)

                        self.save_profile_table(out_path, prof["x"], i_abs, err_abs, x_label)
                        status = "æˆåŠŸ"
                        outputs = out_path.name
                        ok += 1

                except Exception as e:
                    status = "å¤±è´¥"
                    reason = str(e)
                    fail += 1

                rows.append({
                    "Index": idx,
                    "File": fname,
                    "Status": status,
                    "Reason": reason,
                    "Points": points,
                    "XLabel": x_label,
                    "PipelineMode": pipeline_mode,
                    "CorrMode": corr_mode,
                    "K": k,
                    "Thickness_cm": thk_cm_used if np.isfinite(thk_cm_used) else np.nan,
                    "Norm_s": norm_s if np.isfinite(norm_s) else np.nan,
                    "BG_Norm": bg_norm if np.isfinite(bg_norm) else np.nan,
                    "MetaSource": meta_source,
                    "BG_OutsidePts": outside_bg,
                    "Dark_OutsidePts": outside_dark,
                    "ScaleFactor": scale_factor,
                    "Output": outputs,
                })

                processed += 1
                self.t3_prog_bar["value"] = processed
                self.root.update_idletasks()

            rows.sort(key=lambda x: x.get("Index", 0))
            for r in rows:
                r.pop("Index", None)

            stamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")
            report_path = report_dir / f"external1d_report_{stamp}.csv"
            pd.DataFrame(rows).to_csv(report_path, index=False, encoding="utf-8-sig")

            meta = {
                "timestamp": stamp,
                "files_total": len(files),
                "k_factor": k,
                "pipeline_mode": pipeline_mode,
                "corr_mode": corr_mode,
                "scale_factor_global": scale_factor_global,
                "fixed_thickness_mm": fixed_thk_mm if corr_mode == "k_over_d" else None,
                "x_mode": self.t3_x_mode.get(),
                "monitor_mode": monitor_mode,
                "monitor_norm_formula": self.monitor_norm_formula(monitor_mode),
                "meta_csv": self.t3_meta_csv_path.get().strip(),
                "bg_1d_path": self.t3_bg1d_path.get().strip(),
                "dark_1d_path": self.t3_dark1d_path.get().strip(),
                "bg_norm": float(bg_norm) if np.isfinite(bg_norm) else None,
                "resume_enabled": resume,
                "overwrite": overwrite,
                "output_root": str(out_root),
                "output_root_custom": bool(custom_out_root),
                "output_dir": str(out_dir),
                "report_csv": str(report_path),
                "summary": {"success": ok, "skipped": skip, "failed": fail},
            }
            meta_path = report_dir / f"external1d_meta_{stamp}.json"
            with open(meta_path, "w", encoding="utf-8") as f:
                json.dump(meta, f, indent=2, ensure_ascii=False)

            messagebox.showinfo(
                "å¤–éƒ¨1Dæ ¡æ­£å®Œæˆ",
                (
                    "å¤–éƒ¨1Dç»å¯¹å¼ºåº¦æ ¡æ­£å®Œæˆã€‚\n"
                    f"æˆåŠŸ: {ok}\n"
                    f"è·³è¿‡: {skip}\n"
                    f"å¤±è´¥: {fail}\n"
                    f"è¾“å‡ºç›®å½•: {out_dir}\n"
                    f"æŠ¥å‘Š: {report_path.name}\n"
                    f"å…ƒæ•°æ®: {meta_path.name}"
                ),
            )

        except Exception as e:
            messagebox.showerror("å¤–éƒ¨1Dæ ¡æ­£é”™è¯¯", f"{e}\n{traceback.format_exc()}")

    def init_tab_help(self):
        p = self.tab_help

        head = ttk.LabelFrame(p, text="ç¨‹åºå¸®åŠ©ï¼ˆæ–°æ‰‹ç‰ˆï¼‰", style="Group.TLabelframe")
        head.pack(fill="x", padx=10, pady=(8, 4))
        ttk.Label(
            head,
            text=(
                "ç›®æ ‡ï¼šå…ˆåœ¨ Tab1 å¾—åˆ°å¯é  K å› å­ï¼Œå†åœ¨ Tab2 åšç¨³å¥æ‰¹å¤„ç†ã€‚\n"
                "å»ºè®®ï¼šç¬¬ä¸€æ¬¡ä½¿ç”¨å…ˆå®Œæ•´çœ‹ä¸€éâ€œå¿«é€Ÿä¸Šæ‰‹â€å’Œâ€œå¸¸è§é”™è¯¯â€ã€‚"
            ),
            justify="left",
            style="Hint.TLabel",
        ).pack(fill="x", padx=5, pady=4)

        bar = ttk.Frame(p)
        bar.pack(fill="x", padx=10, pady=(0, 4))
        ttk.Label(bar, text="å¸®åŠ©æ–‡æœ¬ï¼ˆå¯æ»šåŠ¨ï¼‰ï¼š", style="Bold.TLabel").pack(side="left")

        text_wrap = ttk.Frame(p)
        text_wrap.pack(fill="both", expand=True, padx=10, pady=(0, 10))
        y_scroll = ttk.Scrollbar(text_wrap, orient="vertical")
        y_scroll.pack(side="right", fill="y")
        txt = tk.Text(
            text_wrap,
            font=("Consolas", 10),
            wrap="word",
            yscrollcommand=y_scroll.set,
            padx=8,
            pady=8,
        )
        txt.pack(side="left", fill="both", expand=True)
        y_scroll.config(command=txt.yview)

        help_text = """
==============================
BL19B2 SAXS Workstation ä½¿ç”¨å¸®åŠ©
==============================

[ä¸€] ç¨‹åºåšä»€ä¹ˆ
1. Tab1ï¼šç”¨æ ‡å‡†æ ·ï¼ˆæ¨è GCï¼‰åš K å› å­æ ‡å®šã€‚
2. Tab2ï¼šæŠŠ 2D å›¾åƒæ‰¹å¤„ç†æˆç»å¯¹å¼ºåº¦ 1D ç»“æœï¼ˆå«è¯¯å·®åˆ—ï¼‰ã€‚
3. Tab3ï¼šæŠŠå¤–éƒ¨è½¯ä»¶ç§¯åˆ†åçš„ 1D ç›¸å¯¹å¼ºåº¦æ‰¹é‡è½¬æ¢ä¸ºç»å¯¹å¼ºåº¦ã€‚
4. è¾“å‡ºåŒ…å«æŠ¥å‘Šæ–‡ä»¶ï¼Œä¾¿äºå¤ç°å®éªŒæµç¨‹ã€‚

----------------------------------------
[äºŒ] ç¬¬ä¸€æ¬¡ä½¿ç”¨çš„æœ€çŸ­è·¯å¾„ï¼ˆå»ºè®®æŒ‰é¡ºåºï¼‰
----------------------------------------
Step 1. å…ˆåš Tab1 æ ‡å®šï¼ˆåªéœ€ä¸€ç»„ Std/BG/Dark/poniï¼‰
1) é€‰æ‹©æ–‡ä»¶ï¼šæ ‡å‡†æ ·ã€èƒŒæ™¯ã€æš—åœºã€poniã€‚
2) æ£€æŸ¥ Time/I0/T æ˜¯å¦è‡ªåŠ¨å¸¦å…¥æ­£ç¡®ï¼ˆå¿…è¦æ—¶æ‰‹å·¥æ”¹ï¼‰ã€‚
3) é€‰æ‹© I0 è¯­ä¹‰ï¼š
   - rateï¼šI0 æ˜¯æ¯ç§’è®¡æ•°ç‡ï¼Œå½’ä¸€åŒ–ç”¨ exp * I0 * T
   - integratedï¼šI0 æ˜¯ç§¯åˆ†è®¡æ•°ï¼Œå½’ä¸€åŒ–ç”¨ I0 * T
4) å¡«æ ‡å‡†æ ·åšåº¦(mm)ï¼Œç‚¹å‡»â€œè¿è¡Œ K å› å­æ ‡å®šâ€ã€‚
5) é‡ç‚¹çœ‹æŠ¥å‘Šä¸­çš„ï¼š
   - Points Usedï¼ˆè¶Šå¤šè¶Šç¨³ï¼‰
   - Std Devï¼ˆè¶Šå°è¶Šç¨³ï¼‰
   - Q overlapï¼ˆè¦æœ‰è¶³å¤Ÿé‡å åŒºé—´ï¼‰
6) æ ‡å®šæˆåŠŸåï¼ŒK ä¼šè‡ªåŠ¨å†™å…¥å…¨å±€å¹¶ä¿å­˜å†å²ã€‚

Step 2. å†åš Tab2 æ‰¹å¤„ç†
1) ç¡®è®¤ K å› å­ > 0ï¼›BG/Dark/poni è·¯å¾„æ­£ç¡®ã€‚
2) é€‰æ‹©åšåº¦ç­–ç•¥ï¼š
   - è‡ªåŠ¨åšåº¦ï¼šd = -ln(T)/mu
   - å›ºå®šåšåº¦ï¼šæ‰€æœ‰æ ·å“åŒä¸€åšåº¦
3) é€‰æ‹©ç§¯åˆ†æ¨¡å¼ï¼ˆå¯å¤šé€‰ï¼‰ï¼š
   - I-Q å…¨ç¯
   - I-Q æ‰‡åŒºï¼ˆæ”¯æŒå¤šæ‰‡åŒºï¼šå¦‚ -25~25;45~65ï¼‰
   - I-chi ç»‡æ„ï¼ˆq åŒºé—´ï¼‰
4) é€‰æ‹©ä¿®æ­£é¡¹ï¼ˆæ¨èï¼‰ï¼š
   - å¼€å¯ Solid Angle
   - è¯¯å·®æ¨¡å‹é€‰ azimuthalï¼ˆå¸¸ç”¨ï¼‰
   - æœ‰æ©è†œå°±åŠ è½½ Mask
   - æ³¨æ„ï¼šTab2 çš„ Solid Angle å¿…é¡»ä¸ Tab1 æ ‡å®šæ—¶ä¸€è‡´ï¼Œå¦åˆ™ K å› å­ä¸å¯ç›´æ¥ä½¿ç”¨
5) å‚è€ƒæ¨¡å¼ï¼š
   - å›ºå®š BG/Darkï¼ˆæ–°æ‰‹æ¨èï¼Œæœ€ç¨³å®šï¼‰
   - è‡ªåŠ¨åŒ¹é… BG/Darkï¼ˆé«˜çº§ç”¨æ³•ï¼‰
6) å…ˆç‚¹â€œé¢„æ£€æŸ¥â€ï¼Œç¡®è®¤æ²¡æœ‰å…³é”®è­¦å‘Šã€‚
7) å¦‚éœ€é›†ä¸­ç®¡ç†ç»“æœï¼Œå¯åœ¨åº•éƒ¨â€œè¾“å‡ºæ ¹ç›®å½•â€æŒ‡å®šè‡ªå®šä¹‰è·¯å¾„ã€‚
8) ç‚¹å‡»â€œå¼€å§‹ç¨³å¥æ‰¹å¤„ç†â€ã€‚

Step 3. å¦‚æœä½ å·²åœ¨å¤–éƒ¨è½¯ä»¶å®Œæˆç§¯åˆ†ï¼ˆå¯é€‰ï¼‰
1) è¿›å…¥ Tab3ï¼Œå¯¼å…¥å¤–éƒ¨ 1D æ–‡ä»¶ï¼ˆ.dat/.txt/.chi/.csvï¼‰ã€‚
2) é€‰æ‹©æµç¨‹ï¼š
   - ä»…æ¯”ä¾‹ç¼©æ”¾ï¼šå¤–éƒ¨1Då·²å®Œæˆæœ¬åº•/å½’ä¸€åŒ–
   - åŸå§‹1Då®Œæ•´æ ¡æ­£ï¼šå¤–éƒ¨1Dæ˜¯åŸå§‹ç§¯åˆ†ç»“æœï¼Œéœ€è¦æä¾› BG1D/Dark1D å’Œ exp/I0/T
   - metadata æ¥æºä¼˜å…ˆçº§ï¼šmetadata.csv > æ–‡ä»¶æ³¨é‡Šå¤´ > Tab3 å›ºå®šå‚æ•°
   - BGå›ºå®šå‚æ•°é»˜è®¤è·Ÿéš Tab1 å…¨å±€ï¼›å¯å–æ¶ˆâ€œBGå‚æ•°è·Ÿéšâ€åæ‰‹åŠ¨è¦†ç›–
   - metadata.csv å¯ä»¥ç›´æ¥ç”¨ Tab2 çš„ batch_report.csvï¼Œæˆ–ç‚¹â€œç”± Tab2 æŠ¥å‘Šç”Ÿæˆ metadataâ€
3) é€‰æ‹©å…¬å¼ï¼š
   - K/dï¼šå¤–éƒ¨ 1D è¿˜æœªé™¤åšåº¦
   - Kï¼šå¤–éƒ¨ 1D å·²é™¤åšåº¦
4) å…ˆé¢„æ£€æŸ¥ï¼Œå†æ‰¹é‡è¿è¡Œã€‚
5) å¦‚éœ€é›†ä¸­ç®¡ç†ç»“æœï¼Œå¯åœ¨åº•éƒ¨â€œè¾“å‡ºæ ¹ç›®å½•â€æŒ‡å®šè‡ªå®šä¹‰è·¯å¾„ã€‚

----------------------------------------
[ä¸‰] æ ¸å¿ƒå‚æ•°è§£é‡Šï¼ˆæ–°æ‰‹å¿…çœ‹ï¼‰
----------------------------------------
1) Time(s)
   æ›å…‰æ—¶é—´ã€‚è‹¥ I0 è¯­ä¹‰æ˜¯ rateï¼ŒTime ä¼šå‚ä¸å½’ä¸€åŒ–ï¼›è‹¥æ˜¯ integratedï¼Œä¸å‚ä¸ã€‚

2) I0(Mon)
   å…¥å°„å¼ºåº¦ç›‘æµ‹å€¼ã€‚è¯·ç¡®è®¤æ˜¯â€œè®¡æ•°ç‡â€è¿˜æ˜¯â€œç§¯åˆ†è®¡æ•°â€ï¼Œå¹¶ä¸ I0 è¯­ä¹‰ä¸€è‡´ã€‚

3) Trans(T)
   é€è¿‡ç‡ï¼Œæ¨èèŒƒå›´ (0, 1]ã€‚
   ç¨‹åºä¼šå¯¹ 1~2 çš„å€¼åšä¿æŠ¤å¤„ç†ï¼ˆè§†ä¸ºæ¼‚ç§»å¹¶å¤¹åˆ° 1.0ï¼‰ï¼Œ
   ä»…å¯¹æ˜ç¡®ç™¾åˆ†å·æˆ–æ˜æ˜¾ç™¾åˆ†æ•°å­—é¢é‡ï¼ˆ>2ï¼‰æ‰æŒ‰ç™¾åˆ†æ•°æ¢ç®—ã€‚

4) muï¼ˆè‡ªåŠ¨åšåº¦æ¨¡å¼ï¼‰
   å•ä½ cm^-1ã€‚mu é”™ä¼šå¯¼è‡´åšåº¦å’Œç»å¯¹å¼ºåº¦æ•´ä½“åå·®ã€‚

5) Polarization
   èŒƒå›´ [-1, 1]ã€‚ä¸ç¡®å®šæ—¶å…ˆç”¨ 0ã€‚

6) æ‰‡åŒºè§’åº¦ï¼ˆTab2 azimuth_rangeï¼‰
   ç¨‹åºä½¿ç”¨ pyFAI chi å®šä¹‰ï¼š
   - 0Â° å‘å³
   - +90Â° å‘ä¸‹
   - -90Â° å‘ä¸Š
   - Â±180Â° å‘å·¦
   æ”¯æŒè·¨ Â±180Â° æ‰‡åŒºï¼Œä¾‹å¦‚ sec_min=170, sec_max=-170ã€‚
   å¤šæ‰‡åŒºå¯åœ¨â€œå¤šæ‰‡åŒºâ€ä¸­å†™ä¸º `-25~25;45~65`ï¼ˆç•™ç©ºåˆ™ä½¿ç”¨å•æ‰‡åŒºè¾“å…¥æ¡†ï¼‰ã€‚
   å¯ç‚¹å‡»â€œé¢„è§ˆI-Qâ€åœ¨2Då›¾ä¸Šç¡®è®¤å…¨ç¯/å¤šæ‰‡åŒºç§¯åˆ†åŒºåŸŸã€‚

----------------------------------------
[å››] ç¨‹åºå†…ç½®çš„é˜²é”™æœºåˆ¶ï¼ˆä½ ä¼šçœ‹åˆ°çš„å‘Šè­¦ï¼‰
----------------------------------------
1) BG_Norm ä¸æ ·å“ Norm_s é‡çº§å¼‚å¸¸
   è‹¥å·®å¼‚è¿‡å¤§ï¼Œå›ºå®š BG æ¨¡å¼ä¼šç›´æ¥é˜»æ–­ï¼Œé¿å…â€œè¿‡æ‰£èƒŒæ™¯å¯¼è‡´å…¨è´Ÿå€¼â€ã€‚

2) ç§¯åˆ†ç»“æœå¥åº·æ£€æŸ¥
   è‹¥æŸæ¡è¾“å‡ºå‡ ä¹å…¨ä¸ºéæ­£å€¼ï¼Œæ¨¡å¼ä¼šè¢«åˆ¤å¤±è´¥å¹¶æç¤ºæ£€æŸ¥å½’ä¸€åŒ–/BGã€‚

3) ä»ªå™¨ä¸€è‡´æ€§æ£€æŸ¥
   å¯æ£€æŸ¥èƒ½é‡ã€æ³¢é•¿ã€è·ç¦»ã€åƒç´ ã€å°ºå¯¸æ˜¯å¦ä¸€è‡´ã€‚

----------------------------------------
[äº”] å¸¸è§é—®é¢˜ä¸å¤„ç†
----------------------------------------
Q1ï¼šæ•´æ¡æ›²çº¿å‡ ä¹å…¨è´Ÿï¼Ÿ
A1ï¼š
  - å…ˆçœ‹ batch_report é‡Œçš„ Norm_s å’Œ BG_Norm æ˜¯å¦åŒé‡çº§ã€‚
  - æ£€æŸ¥ BG çš„ Time/I0/T æ˜¯å¦å¡«å†™æ­£ç¡®ã€‚
  - æ£€æŸ¥ I0 è¯­ä¹‰ï¼ˆrate/integratedï¼‰æ˜¯å¦é€‰é”™ã€‚
  - ç”¨â€œå›ºå®š BG/Dark + é¢„æ£€æŸ¥â€å…ˆè·‘é€šã€‚

Q2ï¼šä¸ºä»€ä¹ˆç¨‹åºæç¤ºç¼ºå°‘ exp/mon/transï¼Ÿ
A2ï¼š
  - å¤´å­—æ®µæ²¡è¯»åˆ°æˆ–å‘½åä¸æ ‡å‡†ã€‚
  - å¯æ‰‹å·¥åœ¨ç•Œé¢å¡«å…¥å‚æ•°ï¼ˆå°¤å…¶æ˜¯ Tab1ï¼‰ã€‚
  - å»ºè®®å…ˆç”¨å°‘é‡æ ·å“ dry_run éªŒè¯ã€‚

Q3ï¼šI-chi ç»“æœçœ‹èµ·æ¥ä¸å¯¹ï¼Ÿ
A3ï¼š
  - æ£€æŸ¥ qmin/qmax æ˜¯å¦åˆç†ã€‚
  - ç¨‹åºå·²å¯¹ radial q å•ä½åšå…¼å®¹å¤„ç†ï¼Œä½†ä»éœ€ç¡®è®¤ q åŒºé—´ä¸ç‰©ç†é¢„æœŸä¸€è‡´ã€‚
  - å¯ç‚¹å‡»â€œé¢„è§ˆI-chiâ€åœ¨2Då›¾ä¸Šæ ¸å¯¹ q ç¯å¸¦èŒƒå›´ã€‚

Q4ï¼šOrigin å¯¼å…¥ä¸æ–¹ä¾¿ï¼Ÿ
A4ï¼š
  - å½“å‰è¾“å‡ºæ˜¯è¡¨å¤´+åˆ¶è¡¨ç¬¦æ ¼å¼ï¼ˆTSVé£æ ¼ï¼‰ï¼Œåˆ—ååŒ…å«åæ ‡ã€I_absã€Errorï¼Œç›´æ¥æŒ‰åˆ—å¯¼å…¥ã€‚

Q5ï¼špyFAI å¯¼å‡ºçš„ 1D æ–‡ä»¶èƒ½ç›´æ¥è¯»å‡º exp/I0/T å—ï¼Ÿ
A5ï¼š
  - å¤šæ•°æƒ…å†µä¸‹åªèƒ½ç¨³å®šè¯»å‡º X/I/(å¯é€‰Error) åˆ—ã€‚
  - exp/I0/T æ˜¯å¦å¯è¯»ï¼Œå–å†³äºæ–‡ä»¶æ³¨é‡Šå¤´æ˜¯å¦å†™å…¥äº†è¿™äº›å­—æ®µã€‚
  - ç¨‹åºä¼šå°è¯•ä»æ³¨é‡Šå¤´è¯»å–ï¼›è‹¥è¯»ä¸åˆ°ï¼Œè¯·æä¾› metadata CSV æˆ–å›ºå®šå‚æ•°ã€‚

Q6ï¼šmetadata.csv ä»å“ªæ¥ï¼Ÿ
A6ï¼š
  - æ¨èç›´æ¥ä½¿ç”¨ Tab2 è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤æ ·å“ç›®å½•ï¼Œæˆ–ä½ è®¾ç½®çš„è‡ªå®šä¹‰è¾“å‡ºæ ¹ç›®å½•ï¼‰`processed_robust_reports` ä¸­è‡ªåŠ¨ç”Ÿæˆçš„ï¼š
    `metadata_for_tab3_*.csv` æˆ– `metadata.csv`ã€‚
  - ä¹Ÿå¯åœ¨ Tab3 ç‚¹â€œç”± Tab2 æŠ¥å‘Šç”Ÿæˆ metadataâ€ï¼Œä» `batch_report_*.csv` ä¸€é”®ç”Ÿæˆã€‚

Q7ï¼šTab2 æ‰‡åŒºè§’åº¦ä¸ç¡®å®šæ€ä¹ˆåŠï¼Ÿ
A7ï¼š
  - åœ¨ Tab2 æ‰‡åŒºè¾“å…¥æ¡†æ—ç‚¹å‡»â€œé¢„è§ˆI-Qâ€ã€‚
  - å¼¹çª—ä¼šå åŠ å•æ‰‡åŒº/å¤šæ‰‡åŒºæ©è†œä¸è¾¹ç•Œçº¿ï¼Œå¹¶æ˜¾ç¤ºè§’åº¦å®šä¹‰ï¼ˆ0Â°å³ã€+90Â°ä¸‹ï¼‰ã€‚

----------------------------------------
[å…­] è¾“å‡ºæ–‡ä»¶è¯´æ˜
----------------------------------------
1) Tab1 è¾“å‡º
   - calibration_check.csvï¼šæ ‡å®šåçš„å‚è€ƒæ›²çº¿ï¼ˆå«è¯¯å·®åˆ—ï¼‰
   - k_factor_history.csvï¼šK å†å²ä¸å…³é”®å‚æ•°

2) Tab2 è¾“å‡º
   ï¼ˆæ ¹ç›®å½•é»˜è®¤åœ¨æ ·å“ç›®å½•ï¼Œä¹Ÿå¯åœ¨ Tab2 åº•éƒ¨è‡ªå®šä¹‰ï¼‰
   - processed_robust_1d_full/*.dat
   - processed_robust_1d_sector/*.datï¼ˆå•æ‰‡åŒºï¼‰
   - processed_robust_1d_sector/sector_*/*.datï¼ˆå¤šæ‰‡åŒºåˆ†åˆ«ä¿å­˜ï¼‰
   - processed_robust_1d_sector_combined/*.datï¼ˆæ‰‡åŒºåˆå¹¶ä¿å­˜ï¼Œè‹¥å‹¾é€‰ï¼‰
   - processed_robust_radial_chi/*.chi
   æ¯ä¸ªæ–‡ä»¶å‡ä¸ºï¼šåæ ‡åˆ— + I_abs_cm^-1 + Error_cm^-1
   - processed_robust_reports/batch_report_*.csv
   - processed_robust_reports/metadata_for_tab3_*.csv
   - processed_robust_reports/metadata.csv
   - processed_robust_reports/run_meta_*.json

3) Tab3 è¾“å‡º
   ï¼ˆæ ¹ç›®å½•é»˜è®¤åœ¨é¦–ä¸ªè¾“å…¥æ–‡ä»¶ç›®å½•ï¼Œä¹Ÿå¯åœ¨ Tab3 åº•éƒ¨è‡ªå®šä¹‰ï¼‰
   - processed_external_1d_abs/*.dat æˆ– *.chi
   - processed_external_1d_reports/external1d_report_*.csv
   - processed_external_1d_reports/external1d_meta_*.json

----------------------------------------
[ä¸ƒ] æ–°æ‰‹æ‰§è¡Œæ£€æŸ¥æ¸…å•ï¼ˆæ¯æ¬¡å¼€è·‘å‰ï¼‰
----------------------------------------
[ ] K å› å­æ¥è‡ªæœ€è¿‘ä¸€æ¬¡å¯ä¿¡æ ‡å®šï¼ˆTab1ï¼‰
[ ] I0 è¯­ä¹‰ç¡®è®¤æ— è¯¯ï¼ˆrate æˆ– integratedï¼‰
[ ] BG/Dark/poni æ¥è‡ªåŒä¸€å®éªŒæ¡ä»¶
[ ] å…ˆåšé¢„æ£€æŸ¥ï¼ˆdry_runï¼‰å†æ­£å¼æ‰¹å¤„ç†
[ ] çœ‹ batch_reportï¼šæˆåŠŸ/å¤±è´¥åŸå› æ˜¯å¦åˆç†

----------------------------------------
[å…«] æ¨èå·¥ä½œä¹ æƒ¯ï¼ˆå‡å°‘è¿”å·¥ï¼‰
----------------------------------------
1) å…ˆç”¨ 3~5 ä¸ªæ ·å“è¯•è·‘ï¼Œç¡®è®¤æµç¨‹æ­£ç¡®å†å…¨é‡è·‘ã€‚
2) æ‰¹å¤„ç†æ—¶ä¼˜å…ˆå¼€å¯æ–­ç‚¹ç»­è·‘ï¼Œé¿å…ä¸­æ–­åé‡ç®—å…¨éƒ¨ã€‚
3) æ¯æ‰¹æ¬¡ä¿ç•™ run_meta ä¸ batch_reportï¼Œæ–¹ä¾¿è¿½æº¯ä¸å®¡ç¨¿è¯´æ˜ã€‚

ï¼ˆå¸®åŠ©é¡µç‰ˆæœ¬ï¼šv2ï¼Œé€‚é… Tab2->Tab3 ç›´è¿ metadata æµç¨‹ï¼‰
"""

        txt.insert(tk.END, help_text.strip() + "\n")
        txt.config(state="disabled")

        def copy_help():
            self.root.clipboard_clear()
            self.root.clipboard_append(help_text.strip() + "\n")
            self.root.update()
            messagebox.showinfo("Help", "å¸®åŠ©æ–‡æœ¬å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ã€‚")

        btn_copy = ttk.Button(bar, text="å¤åˆ¶å¸®åŠ©æ–‡æœ¬", command=copy_help)
        btn_copy.pack(side="right")
        self.add_tooltip(btn_copy, "å¤åˆ¶å®Œæ•´å¸®åŠ©å†…å®¹ï¼Œæ–¹ä¾¿å‘ç»™åŒäº‹æˆ–å­˜æ¡£ã€‚")

    # =========================================================================
    # Logic: K-Calibration (ROBUST + Error)
    # =========================================================================
    def run_calibration(self):
        try:
            files = {k: v.get() for k, v in self.t1_files.items()}
            if not all(files.values()): raise ValueError("æ–‡ä»¶ä¸å®Œæ•´ï¼šè¯·å…ˆé€‰æ‹©æ ‡å‡†æ ·ã€èƒŒæ™¯ã€æš—åœºå’Œ poniã€‚")
            p = {k: v.get() for k, v in self.t1_params.items()}
            if p["std_thk"] <= 0: raise ValueError("æ ‡å‡†æ ·åšåº¦å¿…é¡» > 0 mmã€‚")
            monitor_mode = self.get_monitor_mode()
            apply_solid_angle = bool(self.global_vars["apply_solid_angle"].get())

            self.report("å¼€å§‹æ ‡å®šï¼ˆç¨³å¥æ¨¡å¼ï¼‰...")
            self.report(f"I0 å½’ä¸€åŒ–æ¨¡å¼: {monitor_mode} (norm={self.monitor_norm_formula(monitor_mode)})")
            self.report(f"SolidAngle ä¿®æ­£: {'ON' if apply_solid_angle else 'OFF'}")
            
            ai = pyFAI.load(files["poni"])
            d_std = fabio.open(files["std"]).data.astype(np.float64)
            d_bg = fabio.open(files["bg"]).data.astype(np.float64)
            d_dark = fabio.open(files["dark"]).data.astype(np.float64)
            self._assert_same_shape(d_std, d_bg, "std", "bg")
            self._assert_same_shape(d_std, d_dark, "std", "dark")

            # --- 2D Subtraction (Physics Correct) ---
            norm_std = self.compute_norm_factor(
                p["std_exp"], p["std_i0"], p["std_t"], monitor_mode
            )
            norm_bg = self.compute_norm_factor(
                p["bg_exp"], p["bg_i0"], p["bg_t"], monitor_mode
            )
            
            if norm_std <= 0 or norm_bg <= 0: raise ValueError("å½’ä¸€åŒ–å› å­ <= 0ï¼Œè¯·æ£€æŸ¥ Time/I0/Tã€‚")
            norm_ratio = norm_bg / max(norm_std, 1e-12)
            if norm_ratio < 0.01 or norm_ratio > 100.0:
                self.report(
                    f"[è­¦å‘Š] æ ‡å®šä¸­ BG_Norm ä¸ Std_Norm é‡çº§å·®å¼‚è¿‡å¤§ "
                    f"(BG/Std={norm_ratio:.3g})ï¼Œè¯·å¤æ ¸ BG çš„ Time/I0/T ä¸ I0 è¯­ä¹‰ã€‚"
                )
            
            # Net Signal 2D (Intensity/sec/unit_flux)
            img_net = (d_std - d_dark)/norm_std - (d_bg - d_dark)/norm_bg
            
            # Integrate (Enable Error Propagation via Azimuthal Variance)
            # error_model="azimuthal" computes the sigma (std dev) of pixels in bin
            res = ai.integrate1d(
                img_net,
                1000,
                unit="q_A^-1",
                error_model="azimuthal",
                correctSolidAngle=apply_solid_angle,
            )

            q = np.asarray(res.radial, dtype=np.float64)
            i_1d = np.asarray(res.intensity, dtype=np.float64)
            if q.size < 3:
                raise ValueError("ç§¯åˆ†ç»“æœç‚¹æ•°è¿‡å°‘ï¼Œæ— æ³•å®Œæˆæ ‡å®šã€‚")

            thk_cm = p["std_thk"] / 10.0
            i_net_vol = i_1d / thk_cm

            # Extract Error (Azimuthal StdDev scaled by thickness)
            if getattr(res, "sigma", None) is None:
                sigma_net_vol = np.full_like(i_net_vol, np.nan)
            else:
                sigma_net_vol = np.asarray(res.sigma, dtype=np.float64) / thk_cm
            
            q_nist, i_nist = NIST_SRM3600_DATA[:,0], NIST_SRM3600_DATA[:,1]
            mask = (q_nist >= 0.01) & (q_nist <= 0.2)
            q_ref_all = q_nist[mask]
            i_ref_all = i_nist[mask]
            q_min = max(np.nanmin(q), np.nanmin(q_ref_all))
            q_max = min(np.nanmax(q), np.nanmax(q_ref_all))
            q_mask = (q_ref_all >= q_min) & (q_ref_all <= q_max)
            q_ref = q_ref_all[q_mask]
            i_ref = i_ref_all[q_mask]
            if q_ref.size < 3:
                raise ValueError("ä¸ NIST å‚è€ƒæ›²çº¿çš„ q é‡å åŒºé—´ä¸è¶³ï¼Œæ— æ³•å¯é æ ‡å®šã€‚")

            if estimate_k_factor_robust is not None:
                k_res = estimate_k_factor_robust(
                    q_meas=q,
                    i_meas_per_cm=i_net_vol,
                    q_ref=q_ref,
                    i_ref=i_ref,
                    q_window=(0.01, 0.2),
                    positive_floor=1e-9,
                    min_points=3,
                )
                k_val = float(k_res.k_factor)
                k_std = float(k_res.k_std)
                q_min = float(k_res.q_min_overlap)
                q_max = float(k_res.q_max_overlap)
                ratios_used = np.asarray(k_res.ratios_used, dtype=np.float64)
                points_total = int(k_res.points_total)
            else:
                # Interpolate
                i_meas_interp = np.interp(q_ref, q, i_net_vol)

                # --- æ­£å€¼+æœ‰é™å€¼ç­›é€‰ ---
                valid_idx = np.isfinite(i_meas_interp) & (i_meas_interp > 1e-9)
                if np.sum(valid_idx) < 3:
                    raise ValueError("æ‰£èƒŒæ™¯åä¿¡å·è¿‡å¼±æˆ–ä¸ºè´Ÿï¼Œæ— æ³•æ ‡å®šã€‚")

                ratios = i_ref[valid_idx] / i_meas_interp[valid_idx]
                ratios = ratios[np.isfinite(ratios) & (ratios > 0)]
                if ratios.size < 3:
                    raise ValueError("æœ‰æ•ˆæ¯”å€¼ç‚¹æ•°ä¸è¶³ï¼Œæ— æ³•ç¨³å¥ä¼°è®¡ Kã€‚")

                # åŸºäº MAD çš„ç¨³å¥ç¦»ç¾¤ç‚¹è¿‡æ»¤
                r_med = np.nanmedian(ratios)
                r_mad = np.nanmedian(np.abs(ratios - r_med))
                ratios_used = ratios
                if np.isfinite(r_mad) and r_mad > 0:
                    robust_sigma = 1.4826 * r_mad
                    inlier = np.abs(ratios - r_med) <= 3.0 * robust_sigma
                    if np.sum(inlier) >= 3:
                        ratios_used = ratios[inlier]

                k_val = np.nanmedian(ratios_used)
                k_std = np.nanstd(ratios_used)
                points_total = len(q_ref)

            if k_val <= 0: raise ValueError(f"è®¡ç®—å¾—åˆ°çš„ K <= 0 ({k_val})ï¼Œè¯·æ£€æŸ¥æœ¬åº•ç¼©æ”¾å’Œå‚æ•°ã€‚")

            self.global_vars["k_factor"].set(k_val)
            self.global_vars["k_solid_angle"].set("on" if apply_solid_angle else "off")
            
            # Report
            self.report("-" * 30)
            self.report("æ ‡å®šæˆåŠŸï¼ˆç¨³å¥ä¼°è®¡ï¼‰")
            self.report(f"K-Factor: {k_val:.4f}")
            self.report(f"Q overlap : {q_min:.4f} to {q_max:.4f} A^-1")
            self.report(f"Points Used: {len(ratios_used)}/{points_total}")
            rel_std = (k_std / k_val * 100) if k_val != 0 else np.nan
            self.report(f"Std Dev : {k_std:.4f} ({rel_std:.1f}%)")
            self.report("-" * 30)
            
            # Plot
            self.ax1.clear()
            self.ax1.loglog(q, i_net_vol, 'k--', alpha=0.4, label="Measured Net")
            self.ax1.loglog(q, i_net_vol * k_val, 'b-', label="Corrected")
            self.ax1.loglog(q_ref, i_ref, 'ro', mfc='none', label="NIST SRM3600")
            self.ax1.set_xlabel("q ($A^{-1}$)")
            self.ax1.set_ylabel("Absolute Intensity ($cm^{-1}$)")
            self.ax1.set_title(f"K={k_val:.2f}")
            self.ax1.legend()
            self.canvas1.draw()
            
            # Save Check File with Error
            save_path = Path(files["std"]).parent / "calibration_check.csv"
            # We save the full profile with error bars
            df = pd.DataFrame({
                "Q": q,
                "I_Abs": i_net_vol * k_val,
                "Error": sigma_net_vol * k_val
            })
            df.to_csv(save_path, index=False)
            self.report(f"Saved profile: {save_path.name}")

            self.append_k_history(
                files=files,
                params=p,
                monitor_mode=monitor_mode,
                apply_solid_angle=apply_solid_angle,
                k_val=k_val,
                k_std=k_std,
                points_used=len(ratios_used),
                q_min=q_min,
                q_max=q_max,
            )
            self.report("K history updated.")
            
        except Exception as e:
            messagebox.showerror("æ ‡å®šé”™è¯¯", str(e))
            self.report(f"[ERROR] {str(e)}")

    def append_k_history(self, files, params, monitor_mode, apply_solid_angle, k_val, k_std, points_used, q_min, q_max):
        hist_path = Path(__file__).resolve().parent / "k_factor_history.csv"
        std_norm = self.compute_norm_factor(
            params.get("std_exp", np.nan),
            params.get("std_i0", np.nan),
            params.get("std_t", np.nan),
            monitor_mode,
        )
        bg_norm = self.compute_norm_factor(
            params.get("bg_exp", np.nan),
            params.get("bg_i0", np.nan),
            params.get("bg_t", np.nan),
            monitor_mode,
        )
        row = {
            "Timestamp": datetime.datetime.now().isoformat(timespec="seconds"),
            "Norm_Mode": monitor_mode,
            "Norm_Formula": self.monitor_norm_formula(monitor_mode),
            "SolidAngle_On": bool(apply_solid_angle),
            "K_Factor": float(k_val),
            "K_Std": float(k_std),
            "RelStd_pct": float((k_std / k_val * 100) if k_val else np.nan),
            "PointsUsed": int(points_used),
            "Q_Min": float(q_min),
            "Q_Max": float(q_max),
            "Std_File": files.get("std", ""),
            "BG_File": files.get("bg", ""),
            "Dark_File": files.get("dark", ""),
            "Poni_File": files.get("poni", ""),
            "Std_Thk_mm": float(params.get("std_thk", np.nan)),
            "Std_Norm": float(std_norm) if np.isfinite(std_norm) else np.nan,
            "BG_Norm": float(bg_norm) if np.isfinite(bg_norm) else np.nan,
        }
        df_row = pd.DataFrame([row])
        if hist_path.exists():
            try:
                old = pd.read_csv(hist_path)
                out = pd.concat([old, df_row], ignore_index=True)
            except Exception:
                out = df_row
        else:
            out = df_row
        out.to_csv(hist_path, index=False, encoding="utf-8-sig")

    def open_k_history(self):
        hist_path = Path(__file__).resolve().parent / "k_factor_history.csv"
        if not hist_path.exists():
            messagebox.showinfo("K å†å²", "å°šæ—  K å†å²è®°å½•ï¼Œè¯·å…ˆè¿è¡Œä¸€æ¬¡æ ‡å®šã€‚")
            return

        try:
            df = pd.read_csv(hist_path)
            if df.empty:
                messagebox.showinfo("K å†å²", "å†å²æ–‡ä»¶ä¸ºç©ºã€‚")
                return
        except Exception as e:
            messagebox.showerror("K å†å²", f"è¯»å–å†å²å¤±è´¥: {e}")
            return

        top = tk.Toplevel(self.root)
        top.title("K å› å­å†å²è¶‹åŠ¿")
        top.geometry("980x640")

        upper = ttk.Frame(top)
        upper.pack(fill="both", expand=True)
        lower = ttk.Frame(top)
        lower.pack(fill="both", expand=True)

        fig = Figure(figsize=(7.2, 3.4), dpi=100)
        ax = fig.add_subplot(111)
        x = np.arange(len(df))
        y = pd.to_numeric(df["K_Factor"], errors="coerce").to_numpy(dtype=np.float64)
        e = pd.to_numeric(df.get("K_Std", np.nan), errors="coerce").to_numpy(dtype=np.float64)

        if np.any(np.isfinite(e)):
            ax.errorbar(x, y, yerr=e, fmt="o-", capsize=3, label="K Â± Std")
        else:
            ax.plot(x, y, "o-", label="K")
        ax.set_xlabel("Run Index")
        ax.set_ylabel("K Factor")
        ax.set_title("K Drift Monitor")
        ax.grid(alpha=0.3)
        ax.legend()

        canvas = FigureCanvasTkAgg(fig, master=upper)
        canvas.get_tk_widget().pack(fill="both", expand=True)
        canvas.draw()

        txt = tk.Text(lower, font=("Consolas", 9))
        txt.pack(fill="both", expand=True)
        show_cols = [c for c in ["Timestamp", "Norm_Mode", "SolidAngle_On", "K_Factor", "K_Std", "RelStd_pct", "PointsUsed", "Q_Min", "Q_Max"] if c in df.columns]
        txt.insert(tk.END, df[show_cols].to_string(index=False))

    def report(self, msg):
        if hasattr(self, "txt_report"):
            self.txt_report.insert(tk.END, msg + "\n")
            self.txt_report.see(tk.END)

    def log(self, msg):
        print(msg)
        self.report(msg)

    def get_selected_modes(self):
        modes = []
        if hasattr(self, "t2_mode_full") and self.t2_mode_full.get():
            modes.append("1d_full")
        if hasattr(self, "t2_mode_sector") and self.t2_mode_sector.get():
            modes.append("1d_sector")
        if hasattr(self, "t2_mode_chi") and self.t2_mode_chi.get():
            modes.append("radial_chi")
        return modes

    def add_bg_library_files(self):
        fs = filedialog.askopenfilenames(filetypes=[("Image", "*.tif *.tiff *.edf *.cbf")])
        for f in fs:
            if f not in self.t2_bg_candidates:
                self.t2_bg_candidates.append(f)
        self.t2_bg_lib_info.set(f"BGåº“: {len(self.t2_bg_candidates)}")

    def add_dark_library_files(self):
        fs = filedialog.askopenfilenames(filetypes=[("Image", "*.tif *.tiff *.edf *.cbf")])
        for f in fs:
            if f not in self.t2_dark_candidates:
                self.t2_dark_candidates.append(f)
        self.t2_dark_lib_info.set(f"Darkåº“: {len(self.t2_dark_candidates)}")

    def clear_reference_libraries(self):
        self.t2_bg_candidates = []
        self.t2_dark_candidates = []
        self.t2_bg_lib_info.set("BGåº“: 0")
        self.t2_dark_lib_info.set("Darkåº“: 0")

    def process_sample_task(self, idx, fpath, out_stem, context):
        logs = []
        mode_stats = {m: {"ok": 0, "fail": 0, "skip": 0} for m in context["selected_modes"]}

        def log_line(msg):
            logs.append(msg)

        def load_data(path):
            if context["parallel"]:
                return fabio.open(path).data.astype(np.float64)
            with context["cache_lock"]:
                if path in context["image_cache"]:
                    return context["image_cache"][path]
            d = fabio.open(path).data.astype(np.float64)
            with context["cache_lock"]:
                context["image_cache"][path] = d
            return d

        fname = Path(fpath).name
        exp = np.nan
        mon = np.nan
        trans = np.nan
        thk_cm = np.nan
        norm_s = np.nan
        bg_norm_used = np.nan
        bg_path_used = ""
        dark_path_used = ""
        bg_score = np.nan
        dark_score = np.nan
        outputs = []
        mode_errors = []
        status = "å¤±è´¥"
        reason = ""

        try:
            if context["resume"] and (not context["overwrite"]):
                expected_targets = self.build_sample_output_targets(context, out_stem)
                if expected_targets and all(p.exists() for _, p in expected_targets):
                    for mode_tag, p in expected_targets:
                        mode_key = "1d_sector" if mode_tag.startswith("1d_sector") else mode_tag
                        mode_stats[mode_key]["skip"] += 1
                        outputs.append(f"{mode_tag}:{p.name}(existing)")
                    status = "å·²è·³è¿‡"
                    reason = "æ‰€æœ‰æ¨¡å¼è¾“å‡ºå·²å­˜åœ¨"
                    log_line(f"[è·³è¿‡] {fname}: æ‰€æœ‰è¾“å‡ºå·²å­˜åœ¨")
                    row = {
                        "Index": idx,
                        "File": fname,
                        "Status": status,
                        "Reason": reason,
                        "Norm_Mode": context["monitor_mode"],
                        "Exposure_s": exp,
                        "Monitor": mon,
                        "Trans": trans,
                        "Thk_cm": thk_cm,
                        "Norm_s": norm_s,
                        "BG_Norm": bg_norm_used,
                        "BG_Used": bg_path_used,
                        "Dark_Used": dark_path_used,
                        "BG_Score": bg_score,
                        "Dark_Score": dark_score,
                        "ModesSelected": ",".join(context["selected_modes"]),
                        "Outputs": " | ".join(outputs),
                    }
                    return {"row": row, "logs": logs, "mode_stats": mode_stats}

            ai = context["ai_shared"] if not context["parallel"] else pyFAI.load(context["poni_path"])
            sample = fabio.open(fpath)
            d_s = sample.data.astype(np.float64)
            sample_header = getattr(sample, "header", {})

            exp, mon, trans = self.parse_header(fpath, header_dict=sample_header)
            monitor_mode = context["monitor_mode"]
            missing = []
            if mon is None:
                missing.append("mon")
            if trans is None:
                missing.append("trans")
            if monitor_mode == "rate" and exp is None:
                missing.append("exp")
            if missing:
                raise ValueError(f"æ–‡ä»¶å¤´ç¼ºå°‘å…³é”®å­—æ®µ: {', '.join(missing)}")

            exp = float(exp) if exp is not None else np.nan
            mon = float(mon)
            trans = float(trans)
            if not (np.isfinite(mon) and np.isfinite(trans) and (np.isfinite(exp) or monitor_mode == "integrated")):
                raise ValueError("æ–‡ä»¶å¤´å‚æ•°å­˜åœ¨éæ³•å€¼ï¼ˆéæœ‰é™æ•°ï¼‰")
            if monitor_mode == "rate" and exp <= 0:
                raise ValueError(f"æ›å…‰æ—¶é—´éæ³•: exp={exp}")
            if mon <= 0:
                raise ValueError(f"I0 éæ³•: mon={mon}")
            if not (0 < trans <= 1):
                raise ValueError(f"é€è¿‡ç‡è¶…èŒƒå›´ (0,1]: {trans}")

            sample_meta = {
                "exp": exp if np.isfinite(exp) else None,
                "mon": mon,
                "trans": trans,
                "mtime": Path(fpath).stat().st_mtime if Path(fpath).exists() else None,
                "shape": tuple(d_s.shape),
            }

            if context["ref_mode"] == "fixed":
                d_bg = context["fixed_bg_data"]
                d_dark = context["fixed_dark_data"]
                bg_norm = context["fixed_bg_norm"]
                bg_path_used = context["fixed_bg_path"]
                dark_path_used = context["fixed_dark_path"]
            else:
                bg_ref, bg_score = self.select_best_reference(sample_meta, context["bg_library"], kind="bg")
                dark_ref, dark_score = self.select_best_reference(sample_meta, context["dark_library"], kind="dark")
                if bg_ref is None or dark_ref is None:
                    raise ValueError("è‡ªåŠ¨åŒ¹é…å¤±è´¥ï¼šBG/Dark åº“ä¸ºç©ºæˆ–ä¸å…¼å®¹")

                bg_path_used = bg_ref["path"]
                dark_path_used = dark_ref["path"]
                d_bg = load_data(bg_path_used)
                d_dark = load_data(dark_path_used)
                bg_norm = self.compute_norm_factor(
                    bg_ref.get("exp"),
                    bg_ref.get("mon"),
                    bg_ref.get("trans"),
                    monitor_mode,
                )
                if not np.isfinite(bg_norm) or bg_norm <= 0:
                    bg_norm = context["fixed_bg_norm"]
                    log_line(f"[è­¦å‘Š] {fname}: åŒ¹é…åˆ°çš„ BG å¤´å‚æ•°ä¸å®Œæ•´ï¼Œå›é€€å…¨å±€ BG å½’ä¸€åŒ–å› å­")

            self._assert_same_shape(d_s, d_bg, "sample", "bg")
            self._assert_same_shape(d_s, d_dark, "sample", "dark")
            bg_norm_used = bg_norm

            mask_arr = context["mask_arr"]
            flat_arr = context["flat_arr"]
            if mask_arr is not None and tuple(mask_arr.shape) != tuple(d_s.shape):
                raise ValueError(f"Mask å°ºå¯¸ä¸åŒ¹é…: {mask_arr.shape} vs {d_s.shape}")
            if flat_arr is not None and tuple(flat_arr.shape) != tuple(d_s.shape):
                raise ValueError(f"Flat å°ºå¯¸ä¸åŒ¹é…: {flat_arr.shape} vs {d_s.shape}")

            # --- Thickness Logic ---
            if context["calc_mode"] == "auto":
                if trans >= 0.999 or trans <= 0.001:
                    raise ValueError(f"é€è¿‡ç‡ä¸é€‚åˆè‡ªåŠ¨åšåº¦è®¡ç®—: {trans}")
                thk_cm = -math.log(trans) / context["mu"]
            else:
                thk_cm = context["fixed_thk_cm"]
            if not np.isfinite(thk_cm) or thk_cm <= 0:
                raise ValueError(f"åšåº¦è®¡ç®—ç»“æœéæ³•: {thk_cm}")

            norm_s = self.compute_norm_factor(exp if np.isfinite(exp) else None, mon, trans, monitor_mode)
            if not np.isfinite(norm_s) or norm_s <= 0:
                raise ValueError(f"æ ·å“å½’ä¸€åŒ–å› å­éæ³•: {norm_s}")

            img_bg_net = (d_bg - d_dark) / bg_norm
            img_net = (d_s - d_dark) / norm_s - img_bg_net

            integ_kwargs_common = {
                "correctSolidAngle": context["apply_solid_angle"],
            }
            if context["error_model"] != "none":
                integ_kwargs_common["error_model"] = context["error_model"]
            if mask_arr is not None:
                integ_kwargs_common["mask"] = mask_arr
            if flat_arr is not None:
                integ_kwargs_common["flat"] = flat_arr
            if context["polarization"] is not None:
                integ_kwargs_common["polarization_factor"] = context["polarization"]

            mode_success = 0
            mode_skip = 0
            scale_factor = context["k_factor"] / thk_cm
            expected_total = len(self.build_sample_output_targets(context, out_stem))
            if expected_total <= 0:
                expected_total = len(context["selected_modes"])

            for mode in context["selected_modes"]:
                out_path = self.mode_output_path(context["save_dirs"], mode, out_stem)
                try:
                    if mode != "1d_sector" and context["resume"] and (not context["overwrite"]) and out_path.exists():
                        outputs.append(f"{mode}:{out_path.name}(existing)")
                        mode_stats[mode]["skip"] += 1
                        mode_skip += 1
                        continue

                    if mode == "1d_full":
                        res = ai.integrate1d(
                            img_net,
                            1000,
                            unit="q_A^-1",
                            **integ_kwargs_common,
                        )
                        i_abs = np.asarray(res.intensity, dtype=np.float64) * scale_factor
                        if getattr(res, "sigma", None) is None:
                            i_err = np.full_like(i_abs, np.nan)
                        else:
                            i_err = np.asarray(res.sigma, dtype=np.float64) * scale_factor
                        issue = self.profile_health_issue(i_abs)
                        if issue:
                            raise ValueError(issue)
                        self.save_profile_table(out_path, res.radial, i_abs, i_err, "Q_A^-1")
                        outputs.append(f"{mode}:{out_path.name}")
                        mode_stats[mode]["ok"] += 1
                        mode_success += 1

                    elif mode == "1d_sector":
                        sector_specs = context["sector_specs"]
                        save_each = bool(context.get("sector_save_each", True))
                        save_sum = bool(context.get("sector_save_combined", False))
                        sector_results = {}
                        multi_sector = len(sector_specs) > 1

                        sum_out_path = None
                        sum_need_write = False
                        if save_sum:
                            sum_out_path = context["sector_combined_dir"] / f"{out_stem}.dat"
                            if context["resume"] and (not context["overwrite"]) and sum_out_path.exists():
                                outputs.append(f"1d_sector_sum:{sum_out_path.name}(existing)")
                                mode_stats[mode]["skip"] += 1
                                mode_skip += 1
                            else:
                                sum_need_write = True

                        for spec in sector_specs:
                            spec_tag = f"1d_sector{spec['label']}"
                            each_out_path = None
                            need_each_write = False
                            if save_each:
                                each_dir = context["sector_save_dirs"].get(spec["key"])
                                if each_dir is None:
                                    mode_stats[mode]["fail"] += 1
                                    mode_errors.append(f"{spec_tag}: ç¼ºå°‘è¾“å‡ºç›®å½•æ˜ å°„")
                                    continue
                                each_out_path = each_dir / f"{out_stem}.dat"
                                each_disp = (
                                    f"{each_out_path.parent.name}/{each_out_path.name}"
                                    if multi_sector else each_out_path.name
                                )
                                if context["resume"] and (not context["overwrite"]) and each_out_path.exists():
                                    outputs.append(f"{spec_tag}:{each_disp}(existing)")
                                    mode_stats[mode]["skip"] += 1
                                    mode_skip += 1
                                else:
                                    need_each_write = True

                            need_result = need_each_write or sum_need_write
                            if not need_result:
                                continue

                            try:
                                res, sec_min_n, sec_max_n, sec_wrap = self.integrate1d_sector(
                                    ai,
                                    img_net,
                                    1000,
                                    spec["sec_min"],
                                    spec["sec_max"],
                                    **integ_kwargs_common,
                                )
                                sector_results[spec["key"]] = res

                                if need_each_write and each_out_path is not None:
                                    i_abs = np.asarray(res.intensity, dtype=np.float64) * scale_factor
                                    if getattr(res, "sigma", None) is None:
                                        i_err = np.full_like(i_abs, np.nan)
                                    else:
                                        i_err = np.asarray(res.sigma, dtype=np.float64) * scale_factor
                                    issue = self.profile_health_issue(i_abs)
                                    if issue:
                                        raise ValueError(issue)
                                    self.save_profile_table(each_out_path, res.radial, i_abs, i_err, "Q_A^-1")
                                    outputs.append(f"{spec_tag}:{each_disp}")
                                    mode_stats[mode]["ok"] += 1
                                    mode_success += 1

                                if sec_wrap:
                                    log_line(
                                        f"[æç¤º] {fname} {spec['label']}: è·¨Â±180Â°ï¼ŒæŒ‰ [{sec_min_n:.2f},180] ä¸ [-180,{sec_max_n:.2f}] åˆå¹¶ç§¯åˆ†"
                                    )
                            except Exception as sector_err:
                                mode_stats[mode]["fail"] += 1
                                mode_errors.append(f"{spec_tag}: {sector_err}")

                        if sum_need_write and sum_out_path is not None:
                            missing = [s for s in sector_specs if s["key"] not in sector_results]
                            if missing:
                                miss_lbl = ",".join([m["label"] for m in missing[:3]])
                                if len(missing) > 3:
                                    miss_lbl += ",..."
                                mode_stats[mode]["fail"] += 1
                                mode_errors.append(f"1d_sector_sum: æ‰‡åŒºç»“æœä¸å®Œæ•´ï¼Œæ— æ³•åˆå¹¶ ({miss_lbl})")
                            else:
                                try:
                                    merge = self.merge_integrate1d_results(
                                        [sector_results[s["key"]] for s in sector_specs]
                                    )
                                    i_abs = np.asarray(merge.intensity, dtype=np.float64) * scale_factor
                                    if getattr(merge, "sigma", None) is None:
                                        i_err = np.full_like(i_abs, np.nan)
                                    else:
                                        i_err = np.asarray(merge.sigma, dtype=np.float64) * scale_factor
                                    issue = self.profile_health_issue(i_abs)
                                    if issue:
                                        raise ValueError(issue)
                                    self.save_profile_table(sum_out_path, merge.radial, i_abs, i_err, "Q_A^-1")
                                    outputs.append(f"1d_sector_sum:{sum_out_path.name}")
                                    mode_stats[mode]["ok"] += 1
                                    mode_success += 1
                                except Exception as sum_err:
                                    mode_stats[mode]["fail"] += 1
                                    mode_errors.append(f"1d_sector_sum: {sum_err}")

                    elif mode == "radial_chi":
                        qmin = context["qmin"]
                        qmax = context["qmax"]
                        try:
                            res = ai.integrate_radial(
                                img_net,
                                360,
                                unit="chi_deg",
                                radial_unit="q_A^-1",
                                radial_range=(qmin, qmax),
                                **integ_kwargs_common,
                            )
                        except TypeError as radial_err:
                            if "radial_unit" not in str(radial_err):
                                raise
                            # å…¼å®¹æ—§ç‰ˆ pyFAI: é»˜è®¤ radial_range å•ä½æ˜¯ q_nm^-1
                            res = ai.integrate_radial(
                                img_net,
                                360,
                                unit="chi_deg",
                                radial_range=(qmin * 10.0, qmax * 10.0),
                                **integ_kwargs_common,
                            )
                            log_line(f"[è­¦å‘Š] {fname}: pyFAI ä¸æ”¯æŒ radial_unitï¼Œq åŒºé—´å·²æŒ‰ A^-1->nm^-1 è½¬æ¢")
                        i_abs = np.asarray(res.intensity, dtype=np.float64) * scale_factor
                        if getattr(res, "sigma", None) is None:
                            i_err = np.full_like(i_abs, np.nan)
                        else:
                            i_err = np.asarray(res.sigma, dtype=np.float64) * scale_factor
                        issue = self.profile_health_issue(i_abs)
                        if issue:
                            raise ValueError(issue)
                        self.save_profile_table(out_path, res.radial, i_abs, i_err, "Chi_deg")
                        outputs.append(f"{mode}:{out_path.name}")
                        mode_stats[mode]["ok"] += 1
                        mode_success += 1

                    else:
                        raise ValueError(f"ä¸æ”¯æŒçš„ç§¯åˆ†æ¨¡å¼: {mode}")

                except Exception as mode_err:
                    mode_stats[mode]["fail"] += 1
                    mode_errors.append(f"{mode}: {mode_err}")

            if mode_skip == expected_total and mode_success == 0 and not mode_errors:
                status = "å·²è·³è¿‡"
                reason = "æ‰€æœ‰æ¨¡å¼è¾“å‡ºå·²å­˜åœ¨"
                log_line(f"[è·³è¿‡] {fname}: æ‰€æœ‰è¾“å‡ºå·²å­˜åœ¨")
            elif mode_success > 0 and not mode_errors:
                status = "æˆåŠŸ"
                log_line(f"[æˆåŠŸ] {fname} -> {', '.join(outputs)}")
            elif mode_success > 0:
                status = "éƒ¨åˆ†æˆåŠŸ"
                reason = " | ".join(mode_errors)
                log_line(f"[éƒ¨åˆ†æˆåŠŸ] {fname} -> {', '.join(outputs)}")
                log_line(f"[æ¨¡å¼å¤±è´¥] {fname}: {reason}")
            else:
                status = "å¤±è´¥"
                reason = " | ".join(mode_errors) if mode_errors else "æ— è¾“å‡º"
                log_line(f"[å¤±è´¥] {fname}: {reason}")

        except Exception as file_err:
            status = "å¤±è´¥"
            reason = str(file_err)
            log_line(f"[å¤±è´¥] {fname}: {reason}")

        row = {
            "Index": idx,
            "File": fname,
            "Status": status,
            "Reason": reason,
            "Norm_Mode": context["monitor_mode"],
            "Exposure_s": exp,
            "Monitor": mon,
            "Trans": trans,
            "Thk_cm": thk_cm,
            "Norm_s": norm_s,
            "BG_Norm": bg_norm_used,
            "BG_Used": bg_path_used,
            "Dark_Used": dark_path_used,
            "BG_Score": bg_score,
            "Dark_Score": dark_score,
            "ModesSelected": ",".join(context["selected_modes"]),
            "Outputs": " | ".join(outputs),
        }
        return {"row": row, "logs": logs, "mode_stats": mode_stats}

    # =========================================================================
    # Logic: Batch (2D Subtraction Kernel + Error)
    # =========================================================================
    def run_batch(self):
        try:
            if not self.t2_files: raise ValueError("é˜Ÿåˆ—ä¸ºç©ºï¼šè¯·å…ˆæ·»åŠ æ ·å“æ–‡ä»¶ã€‚")
            k = float(self.global_vars["k_factor"].get())
            bg_p = self.global_vars["bg_path"].get()
            dk_p = self.global_vars["dark_path"].get()
            poni = self.global_vars["poni_path"].get()
            
            if k <= 0: raise ValueError("K å› å­æ— æ•ˆï¼ˆå¿…é¡» > 0ï¼‰ã€‚")
            if not all([bg_p, dk_p, poni]): raise ValueError("ç¼ºå°‘èƒŒæ™¯/æš—åœº/poni æ–‡ä»¶ã€‚")
            monitor_mode = self.get_monitor_mode()
            self.log(f"[é…ç½®] I0 å½’ä¸€åŒ–æ¨¡å¼: {monitor_mode} (norm={self.monitor_norm_formula(monitor_mode)})")
            self.log(f"[é…ç½®] SolidAngle ä¿®æ­£: {'ON' if bool(self.t2_apply_solid_angle.get()) else 'OFF'}")

            files = list(dict.fromkeys(self.t2_files))
            if len(files) < len(self.t2_files):
                self.log(f"[æç¤º] é˜Ÿåˆ—å»é‡ï¼šç§»é™¤é‡å¤æ–‡ä»¶ {len(self.t2_files) - len(files)} ä¸ª")
                self.t2_files = files
                self.lb_batch.delete(0, tk.END)
                for f in self.t2_files:
                    self.lb_batch.insert(tk.END, Path(f).name)
                self.refresh_queue_status()

            selected_modes = self.get_selected_modes()
            if not selected_modes:
                raise ValueError("æœªé€‰æ‹©ç§¯åˆ†æ¨¡å¼ï¼šè¯·è‡³å°‘å‹¾é€‰ä¸€ç§ï¼ˆå…¨ç¯/æ‰‡åŒº/ç»‡æ„ï¼‰ã€‚")

            apply_solid_angle = bool(self.t2_apply_solid_angle.get())
            k_solid_state = str(self.global_vars["k_solid_angle"].get()).strip().lower()
            if k_solid_state in ("on", "off"):
                k_solid_bool = (k_solid_state == "on")
                if apply_solid_angle != k_solid_bool:
                    raise ValueError(
                        "SolidAngle è®¾ç½®ä¸ K å› å­æ ‡å®šçŠ¶æ€ä¸ä¸€è‡´ï¼š"
                        f"K ä½¿ç”¨ {'ON' if k_solid_bool else 'OFF'}ï¼Œå½“å‰æ‰¹å¤„ç†ä¸º {'ON' if apply_solid_angle else 'OFF'}ã€‚"
                        "è¯·åˆ‡æ¢ä¸ºä¸€è‡´è®¾ç½®ï¼Œæˆ–é‡æ–°è¿è¡Œ Tab1 æ ‡å®šã€‚"
                    )
            else:
                self.log("[è­¦å‘Š] å½“å‰ K å› å­ç¼ºå°‘ SolidAngle çŠ¶æ€ä¿¡æ¯ï¼Œæ— æ³•è‡ªåŠ¨æ ¡éªŒä¸€è‡´æ€§ã€‚å»ºè®®é‡æ–°æ ‡å®š Kã€‚")

            ai = pyFAI.load(poni)
            if "radial_chi" in selected_modes and not hasattr(ai, "integrate_radial"):
                raise RuntimeError("å½“å‰ pyFAI ä¸æ”¯æŒ integrate_radialï¼Œè¯·å–æ¶ˆç»‡æ„æ¨¡å¼æˆ–å‡çº§ pyFAIã€‚")
            sector_specs = []
            sector_save_each = bool(self.t2_sector_save_each.get())
            sector_save_combined = bool(self.t2_sector_save_combined.get())
            if "1d_sector" in selected_modes:
                sector_specs = self.get_t2_sector_specs()
                if not sector_save_each and not sector_save_combined:
                    raise ValueError("å·²å¯ç”¨æ‰‡åŒºæ¨¡å¼ï¼Œä½†æœªé€‰æ‹©ä»»ä½•æ‰‡åŒºè¾“å‡ºï¼ˆè¯·å‹¾é€‰â€œåˆ†æ‰‡åŒºåˆ†åˆ«ä¿å­˜â€æˆ–â€œæ‰‡åŒºåˆå¹¶ä¿å­˜â€ï¼‰ã€‚")
                sec_brief = "; ".join([f"{s['index']}:{s['label']}" for s in sector_specs[:6]])
                if len(sector_specs) > 6:
                    sec_brief += "; ..."
                self.log(f"[é…ç½®] æ‰‡åŒºåˆ—è¡¨({len(sector_specs)}): {sec_brief}")
            if "radial_chi" in selected_modes and self.t2_rad_qmin.get() >= self.t2_rad_qmax.get():
                raise ValueError("ç»‡æ„ q èŒƒå›´æ— æ•ˆï¼šqmin å¿…é¡» < qmaxã€‚")

            fixed_dark_data = fabio.open(dk_p).data.astype(np.float64)
            fixed_bg_data = fabio.open(bg_p).data.astype(np.float64)
            self._assert_same_shape(fixed_bg_data, fixed_dark_data, "bg", "dark")
            fixed_bg_norm = self.compute_norm_factor(
                self.global_vars["bg_exp"].get(),
                self.global_vars["bg_i0"].get(),
                self.global_vars["bg_t"].get(),
                monitor_mode,
            )
            if not np.isfinite(fixed_bg_norm) or fixed_bg_norm <= 0:
                raise ValueError("èƒŒæ™¯å½’ä¸€åŒ–å› å­ <= 0ï¼Œè¯·æ£€æŸ¥ BG çš„ Time/I0/Tã€‚")

            ref_mode = self.t2_ref_mode.get()
            if ref_mode not in ("fixed", "auto"):
                raise ValueError(f"æœªçŸ¥å‚è€ƒæ¨¡å¼: {ref_mode}")

            # é˜²æ­¢ BG å½’ä¸€åŒ–å› å­é‡çº§å¼‚å¸¸å¯¼è‡´è¿‡æ‰£èƒŒæ™¯ï¼ˆä¾‹å¦‚ T è¢«è¯¯åˆ¤æˆç™¾åˆ†æ•°ï¼‰
            probe_norms = []
            for fp in files[: min(20, len(files))]:
                try:
                    e, m, t = self.parse_header(fp)
                    n = self.compute_norm_factor(e, m, t, monitor_mode)
                    if np.isfinite(n) and n > 0:
                        probe_norms.append(float(n))
                except Exception:
                    continue
            if probe_norms:
                med_sample_norm = float(np.nanmedian(np.asarray(probe_norms, dtype=np.float64)))
                if np.isfinite(med_sample_norm) and med_sample_norm > 0:
                    bg_ratio = fixed_bg_norm / med_sample_norm
                    if bg_ratio < 0.01 or bg_ratio > 100.0:
                        msg = (
                            "BG_Norm ä¸æ ·å“ Norm_s é‡çº§å·®å¼‚è¿‡å¤§ "
                            f"(BG/æ ·å“ä¸­ä½={bg_ratio:.3g}, BG_Norm={fixed_bg_norm:.6g}, "
                            f"SampleMed={med_sample_norm:.6g})ï¼Œè¯·æ£€æŸ¥ BG çš„ Time/I0/Tã€I0 è¯­ä¹‰æˆ–å¤´å­—æ®µæ˜ å°„ã€‚"
                        )
                        if ref_mode == "fixed":
                            raise ValueError(msg)
                        self.log(f"[è­¦å‘Š] {msg}")

            bg_library = self.build_reference_library(self.t2_bg_candidates)
            dark_library = self.build_reference_library(self.t2_dark_candidates)
            if ref_mode == "auto":
                if not bg_library:
                    raise ValueError("è‡ªåŠ¨åŒ¹é…æ¨¡å¼ä¸‹ BG åº“ä¸ºç©ºã€‚")
                if not dark_library:
                    raise ValueError("è‡ªåŠ¨åŒ¹é…æ¨¡å¼ä¸‹ Dark åº“ä¸ºç©ºã€‚")

            if self.t2_strict_instrument.get():
                tol_pct = self.t2_instr_tol_pct.get()
                issues = self.check_instrument_consistency(files, poni_path=poni, tol_pct=tol_pct)
                if issues:
                    preview = "\n".join(issues[:10])
                    tail = "\n..." if len(issues) > 10 else ""
                    raise ValueError(f"ä»ªå™¨ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥ï¼ˆå‰10é¡¹ï¼‰:\n{preview}{tail}")

            mask_arr = self.load_optional_array(self.t2_mask_path.get().strip(), "Mask")
            if mask_arr is not None:
                mask_arr = np.asarray(mask_arr) != 0
            flat_arr = self.load_optional_array(self.t2_flat_path.get().strip(), "Flat")
            if flat_arr is not None:
                flat_arr = np.asarray(flat_arr, dtype=np.float64)

            pol = self.t2_polarization.get()
            if not np.isfinite(pol) or pol < -1.0 or pol > 1.0:
                raise ValueError("Polarization å› å­å¿…é¡»åœ¨ [-1, 1]ã€‚")
            error_model = self.t2_error_model.get().strip().lower()
            if error_model not in ("azimuthal", "poisson", "none"):
                raise ValueError("è¯¯å·®æ¨¡å‹ä»…æ”¯æŒ azimuthal / poisson / noneã€‚")

            custom_out_root = self.t2_output_root.get().strip() if hasattr(self, "t2_output_root") else ""
            if custom_out_root:
                out_root = Path(custom_out_root).expanduser()
                out_root.mkdir(parents=True, exist_ok=True)
                self.log(f"[é…ç½®] è¾“å‡ºæ ¹ç›®å½•(è‡ªå®šä¹‰): {out_root}")
            else:
                out_root = Path(files[0]).parent
                self.log(f"[é…ç½®] è¾“å‡ºæ ¹ç›®å½•(é»˜è®¤æ ·å“ç›®å½•): {out_root}")
            save_dirs = {}
            sector_save_dirs = {}
            sector_combined_dir = None
            for mode in selected_modes:
                if mode == "1d_sector":
                    base = out_root / "processed_robust_1d_sector"
                    base.mkdir(exist_ok=True)
                    save_dirs[mode] = base
                    if sector_save_each:
                        multi = len(sector_specs) > 1
                        for spec in sector_specs:
                            d = base / spec["key"] if multi else base
                            d.mkdir(exist_ok=True)
                            sector_save_dirs[spec["key"]] = d
                    if sector_save_combined:
                        sector_combined_dir = out_root / "processed_robust_1d_sector_combined"
                        sector_combined_dir.mkdir(exist_ok=True)
                else:
                    d = out_root / f"processed_robust_{mode}"
                    d.mkdir(exist_ok=True)
                    save_dirs[mode] = d
            report_dir = out_root / "processed_robust_reports"
            report_dir.mkdir(exist_ok=True)
            stem_map = self.build_output_stem_map(files)

            self.prog_bar["maximum"] = len(files)
            self.prog_bar["value"] = 0
            mu = self.t2_mu.get()
            if self.t2_calc_mode.get() == "auto" and mu <= 0:
                raise ValueError("è‡ªåŠ¨åšåº¦æ¨¡å¼è¦æ±‚ mu > 0ã€‚")
            if self.t2_calc_mode.get() == "fixed" and self.t2_fixed_thk.get() <= 0:
                raise ValueError("å›ºå®šåšåº¦å¿…é¡» > 0 mmã€‚")
            fixed_thk_cm = self.t2_fixed_thk.get() / 10.0

            try:
                workers = max(1, int(self.t2_workers.get()))
            except Exception:
                raise ValueError("å¹¶è¡Œçº¿ç¨‹æ•°å¿…é¡»ä¸ºæ­£æ•´æ•°ã€‚")
            overwrite = bool(self.t2_overwrite.get())
            resume = bool(self.t2_resume_enabled.get())

            context = {
                "selected_modes": selected_modes,
                "save_dirs": save_dirs,
                "poni_path": poni,
                "ai_shared": ai,
                "parallel": workers > 1,
                "cache_lock": threading.Lock(),
                "image_cache": {},
                "k_factor": k,
                "monitor_mode": monitor_mode,
                "calc_mode": self.t2_calc_mode.get(),
                "mu": mu,
                "fixed_thk_cm": fixed_thk_cm,
                "fixed_bg_data": fixed_bg_data,
                "fixed_dark_data": fixed_dark_data,
                "fixed_bg_norm": fixed_bg_norm,
                "fixed_bg_path": bg_p,
                "fixed_dark_path": dk_p,
                "ref_mode": ref_mode,
                "bg_library": bg_library,
                "dark_library": dark_library,
                "mask_arr": mask_arr,
                "flat_arr": flat_arr,
                "error_model": error_model,
                "apply_solid_angle": bool(self.t2_apply_solid_angle.get()),
                "polarization": float(pol),
                "sector_specs": sector_specs,
                "sector_save_each": sector_save_each,
                "sector_save_combined": sector_save_combined,
                "sector_save_dirs": sector_save_dirs,
                "sector_combined_dir": sector_combined_dir,
                "qmin": float(self.t2_rad_qmin.get()),
                "qmax": float(self.t2_rad_qmax.get()),
                "overwrite": overwrite,
                "resume": resume,
            }

            rows = []
            sample_success = 0
            sample_partial = 0
            sample_fail = 0
            sample_skip = 0
            mode_ok_count = {m: 0 for m in selected_modes}
            mode_fail_count = {m: 0 for m in selected_modes}
            mode_skip_count = {m: 0 for m in selected_modes}

            tasks = [(idx, fpath, stem_map[fpath]) for idx, fpath in enumerate(files)]
            processed = 0

            if workers == 1:
                for idx, fpath, out_stem in tasks:
                    result = self.process_sample_task(idx, fpath, out_stem, context)
                    rows.append(result["row"])
                    for line in result["logs"]:
                        self.log(line)

                    for m in selected_modes:
                        mode_ok_count[m] += result["mode_stats"][m]["ok"]
                        mode_fail_count[m] += result["mode_stats"][m]["fail"]
                        mode_skip_count[m] += result["mode_stats"][m]["skip"]

                    st = result["row"]["Status"]
                    if st == "æˆåŠŸ":
                        sample_success += 1
                    elif st == "éƒ¨åˆ†æˆåŠŸ":
                        sample_partial += 1
                    elif st == "å·²è·³è¿‡":
                        sample_skip += 1
                    else:
                        sample_fail += 1

                    processed += 1
                    self.prog_bar["value"] = processed
                    self.root.update_idletasks()
            else:
                with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as ex:
                    futures = {
                        ex.submit(self.process_sample_task, idx, fpath, out_stem, context): (idx, fpath)
                        for idx, fpath, out_stem in tasks
                    }
                    for fut in concurrent.futures.as_completed(futures):
                        result = fut.result()
                        rows.append(result["row"])
                        for line in result["logs"]:
                            self.log(line)

                        for m in selected_modes:
                            mode_ok_count[m] += result["mode_stats"][m]["ok"]
                            mode_fail_count[m] += result["mode_stats"][m]["fail"]
                            mode_skip_count[m] += result["mode_stats"][m]["skip"]

                        st = result["row"]["Status"]
                        if st == "æˆåŠŸ":
                            sample_success += 1
                        elif st == "éƒ¨åˆ†æˆåŠŸ":
                            sample_partial += 1
                        elif st == "å·²è·³è¿‡":
                            sample_skip += 1
                        else:
                            sample_fail += 1

                        processed += 1
                        self.prog_bar["value"] = processed
                        self.root.update_idletasks()

            rows.sort(key=lambda x: x.get("Index", 0))
            for r in rows:
                r.pop("Index", None)

            stamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")
            report_path = report_dir / f"batch_report_{stamp}.csv"
            pd.DataFrame(rows).to_csv(report_path, index=False, encoding="utf-8-sig")

            tab3_meta_stamp = None
            tab3_meta_latest = None
            tab3_meta_rows = 0
            try:
                tab3_meta_stamp, tab3_meta_latest, tab3_meta_rows = self.export_tab3_metadata_from_report(
                    report_path,
                    stamp=stamp,
                )
            except Exception as e:
                self.log(f"[è­¦å‘Š] è‡ªåŠ¨å¯¼å‡º Tab3 metadata å¤±è´¥: {e}")

            meta_path = report_dir / f"run_meta_{stamp}.json"
            output_dirs_meta = {}
            for m in selected_modes:
                if m != "1d_sector":
                    output_dirs_meta[m] = str(save_dirs[m])
                    continue
                output_dirs_meta["1d_sector_base"] = str(save_dirs[m])
                if sector_save_each:
                    output_dirs_meta["1d_sector_each"] = {
                        spec["label"]: str(sector_save_dirs.get(spec["key"], save_dirs[m]))
                        for spec in sector_specs
                    }
                if sector_save_combined and sector_combined_dir is not None:
                    output_dirs_meta["1d_sector_sum"] = str(sector_combined_dir)

            meta = {
                "timestamp": stamp,
                "selected_modes": selected_modes,
                "files_total": len(files),
                "workers": workers,
                "k_factor": k,
                "monitor_mode": monitor_mode,
                "norm_formula": self.monitor_norm_formula(monitor_mode),
                "calc_mode": self.t2_calc_mode.get(),
                "mu_cm^-1": mu,
                "fixed_thickness_mm": self.t2_fixed_thk.get(),
                "reference_mode": ref_mode,
                "fixed_bg_path": bg_p,
                "fixed_dark_path": dk_p,
                "bg_library_count": len(bg_library),
                "dark_library_count": len(dark_library),
                "error_model": error_model,
                "correct_solid_angle": bool(self.t2_apply_solid_angle.get()),
                "k_solid_angle_state": str(self.global_vars["k_solid_angle"].get()),
                "polarization_factor": pol,
                "mask_path": self.t2_mask_path.get().strip(),
                "flat_path": self.t2_flat_path.get().strip(),
                "resume_enabled": resume,
                "overwrite": overwrite,
                "strict_instrument": bool(self.t2_strict_instrument.get()),
                "instrument_tol_pct": float(self.t2_instr_tol_pct.get()),
                "sector_specs": sector_specs,
                "sector_save_each": sector_save_each,
                "sector_save_combined": sector_save_combined,
                "output_root": str(out_root),
                "output_root_custom": bool(custom_out_root),
                "output_dirs": output_dirs_meta,
                "report_csv": str(report_path),
                "tab3_metadata_csv": str(tab3_meta_stamp) if tab3_meta_stamp else None,
                "tab3_metadata_latest": str(tab3_meta_latest) if tab3_meta_latest else None,
                "tab3_metadata_rows": int(tab3_meta_rows),
                "sample_summary": {
                    "success": sample_success,
                    "partial": sample_partial,
                    "skipped": sample_skip,
                    "failed": sample_fail,
                },
                "mode_summary": {
                    m: {"ok": mode_ok_count[m], "skip": mode_skip_count[m], "fail": mode_fail_count[m]}
                    for m in selected_modes
                },
                "versions": {
                    "numpy": np.__version__,
                    "pandas": pd.__version__,
                    "pyFAI": getattr(pyFAI, "__version__", "unknown"),
                    "fabio": getattr(fabio, "__version__", "unknown"),
                },
            }
            with open(meta_path, "w", encoding="utf-8") as f:
                json.dump(meta, f, indent=2, ensure_ascii=False)

            mode_summary = "\n".join(
                [f"{m}: æˆåŠŸ{mode_ok_count[m]} / è·³è¿‡{mode_skip_count[m]} / å¤±è´¥{mode_fail_count[m]}" for m in selected_modes]
            )
            dir_lines = []
            for m in selected_modes:
                if m != "1d_sector":
                    dir_lines.append(f"{m} -> {save_dirs[m]}")
                    continue
                if sector_save_each:
                    if len(sector_specs) > 1:
                        dir_lines.append(f"1d_sector(each) -> {save_dirs[m]}/sector_*")
                    else:
                        dir_lines.append(f"1d_sector(each) -> {save_dirs[m]}")
                if sector_save_combined and sector_combined_dir is not None:
                    dir_lines.append(f"1d_sector_sum -> {sector_combined_dir}")
            dir_summary = "\n".join(dir_lines)

            messagebox.showinfo(
                "æ‰¹å¤„ç†å®Œæˆ",
                (
                    "ç¨³å¥æ‰¹å¤„ç†å®Œæˆã€‚\n"
                    f"æ ·å“æˆåŠŸ: {sample_success}\n"
                    f"æ ·å“éƒ¨åˆ†æˆåŠŸ: {sample_partial}\n"
                    f"æ ·å“å·²è·³è¿‡: {sample_skip}\n"
                    f"æ ·å“å¤±è´¥: {sample_fail}\n"
                    f"æ¨¡å¼ç»Ÿè®¡:\n{mode_summary}\n"
                    f"è¾“å‡ºç›®å½•:\n{dir_summary}\n"
                    f"æŠ¥å‘Š: {report_path.name}\n"
                    f"Tab3 metadata: {tab3_meta_stamp.name if tab3_meta_stamp else 'å¯¼å‡ºå¤±è´¥'}\n"
                    f"å…ƒæ•°æ®: {meta_path.name}"
                ),
            )

        except Exception as e:
            messagebox.showerror("æ‰¹å¤„ç†é”™è¯¯", f"{e}\n{traceback.format_exc()}")

    # --- Helpers ---
    def refresh_queue_status(self):
        if hasattr(self, "t2_queue_info"):
            total = len(getattr(self, "t2_files", []))
            uniq = len(dict.fromkeys(getattr(self, "t2_files", [])))
            if uniq == total:
                self.t2_queue_info.set(f"é˜Ÿåˆ—æ–‡ä»¶: {uniq}")
            else:
                self.t2_queue_info.set(f"é˜Ÿåˆ—æ–‡ä»¶: {total}ï¼ˆå»é‡å {uniq}ï¼‰")

        if hasattr(self, "t2_out_hint_var"):
            modes = self.get_selected_modes()
            if not modes:
                self.t2_out_hint_var.set("è¾“å‡ºç›®å½•: æœªé€‰æ‹©ç§¯åˆ†æ¨¡å¼")
            else:
                dirs = []
                for m in modes:
                    if m != "1d_sector":
                        dirs.append(f"processed_robust_{m}")
                        continue
                    dirs.append("processed_robust_1d_sector")
                    if hasattr(self, "t2_sector_save_combined") and self.t2_sector_save_combined.get():
                        dirs.append("processed_robust_1d_sector_combined")
                sec_note = ""
                if "1d_sector" in modes:
                    try:
                        n_sec = len(self.get_t2_sector_specs())
                        sec_note = f"ï¼ˆæ‰‡åŒºæ•°={n_sec}ï¼‰"
                    except Exception:
                        sec_note = "ï¼ˆæ‰‡åŒºé…ç½®å¾…ç¡®è®¤ï¼‰"
                custom_root = self.t2_output_root.get().strip() if hasattr(self, "t2_output_root") else ""
                if custom_root:
                    self.t2_out_hint_var.set(
                        f"è¾“å‡ºç›®å½•å°†å†™å…¥ {custom_root}: {', '.join(dirs)}{sec_note}"
                    )
                else:
                    self.t2_out_hint_var.set(f"è¾“å‡ºç›®å½•å°†è‡ªåŠ¨åˆ›å»º: {', '.join(dirs)}{sec_note}")

    def dry_run(self):
        if not self.t2_files: return
        files = list(dict.fromkeys(self.t2_files))
        rows = []
        mu = self.t2_mu.get()
        monitor_mode = self.get_monitor_mode()
        mode = self.t2_calc_mode.get()
        selected_modes = self.get_selected_modes()
        warnings = []
        inst_issues = []
        sample_norms = []
        bg_norm = self.compute_norm_factor(
            self.global_vars["bg_exp"].get(),
            self.global_vars["bg_i0"].get(),
            self.global_vars["bg_t"].get(),
            monitor_mode,
        )

        if not selected_modes:
            warnings.append("æœªé€‰æ‹©ç§¯åˆ†æ¨¡å¼ï¼ˆè‡³å°‘å‹¾é€‰ä¸€ç§ï¼‰ã€‚")
        sector_specs = []
        if "1d_sector" in selected_modes:
            try:
                sector_specs = self.get_t2_sector_specs()
                if not self.t2_sector_save_each.get() and not self.t2_sector_save_combined.get():
                    warnings.append("æ‰‡åŒºæ¨¡å¼æœªå‹¾é€‰ä»»ä½•è¾“å‡ºï¼ˆåˆ†åˆ«ä¿å­˜/åˆå¹¶ä¿å­˜ï¼‰ã€‚")
            except Exception as e:
                warnings.append(f"æ‰‡åŒºè§’åº¦èŒƒå›´æ— æ•ˆï¼š{e}")
        if "radial_chi" in selected_modes and self.t2_rad_qmin.get() >= self.t2_rad_qmax.get():
            warnings.append("ç»‡æ„ q èŒƒå›´æ— æ•ˆï¼šqmin å¿…é¡» < qmaxã€‚")
        if mode == "auto" and mu <= 0:
            warnings.append("è‡ªåŠ¨åšåº¦æ¨¡å¼ä¸‹ mu å¿…é¡» > 0ã€‚")
        if self.t2_calc_mode.get() == "fixed" and self.t2_fixed_thk.get() <= 0:
            warnings.append("å›ºå®šåšåº¦å¿…é¡» > 0 mmã€‚")
        if self.t2_ref_mode.get() == "auto":
            if not self.t2_bg_candidates:
                warnings.append("è‡ªåŠ¨åŒ¹é…æ¨¡å¼ä¸‹ BG åº“ä¸ºç©ºã€‚")
            if not self.t2_dark_candidates:
                warnings.append("è‡ªåŠ¨åŒ¹é…æ¨¡å¼ä¸‹ Dark åº“ä¸ºç©ºã€‚")
        if self.t2_strict_instrument.get():
            inst_issues = self.check_instrument_consistency(
                files,
                poni_path=self.global_vars["poni_path"].get(),
                tol_pct=self.t2_instr_tol_pct.get(),
            )
            if inst_issues:
                warnings.append(f"ä»ªå™¨ä¸€è‡´æ€§å‘ç° {len(inst_issues)} é¡¹é—®é¢˜ï¼ˆè§ä¸‹æ–¹è¯¦æƒ…ï¼‰ã€‚")

        bg_library = self.build_reference_library(self.t2_bg_candidates) if self.t2_ref_mode.get() == "auto" else []
        dark_library = self.build_reference_library(self.t2_dark_candidates) if self.t2_ref_mode.get() == "auto" else []

        for fp in files:
            e, m, t = self.parse_header(fp)
            stat = "æ­£å¸¸"
            d_mm = np.nan
            bg_match = "-"
            dark_match = "-"

            missing = []
            if m is None:
                missing.append("MON")
            if t is None:
                missing.append("T")
            if monitor_mode == "rate" and e is None:
                missing.append("EXP")

            if missing:
                stat = f"ç¼ºå°‘æ–‡ä»¶å¤´å­—æ®µ: {','.join(missing)}"
            else:
                if e is not None:
                    e = float(e)
                m = float(m)
                t = float(t)
                n = self.compute_norm_factor(e if e is not None else None, m, t, monitor_mode)
                if np.isfinite(n) and n > 0:
                    sample_norms.append(float(n))
                if monitor_mode == "rate" and e <= 0:
                    stat = "é”™è¯¯: EXP <= 0"
                elif m <= 0:
                    stat = "é”™è¯¯: MON <= 0"
                elif not (0 < t <= 1):
                    stat = "é”™è¯¯: T è¶…å‡º (0,1]"
                elif mode == "auto":
                    if mu <= 0:
                        stat = "é”™è¯¯: MU <= 0"
                    elif t >= 0.999 or t <= 0.001:
                        stat = "é”™è¯¯: T ä¸é€‚åˆè‡ªåŠ¨åšåº¦"
                    else:
                        d_mm = (-math.log(t) / mu) * 10.0
                else:
                    d_mm = self.t2_fixed_thk.get()

            if self.t2_ref_mode.get() == "auto":
                try:
                    img = fabio.open(fp)
                    smeta = {
                        "exp": e if (e is not None and np.isfinite(e)) else None,
                        "mon": m if m is not None else None,
                        "trans": t if t is not None else None,
                        "mtime": Path(fp).stat().st_mtime if Path(fp).exists() else None,
                        "shape": tuple(img.data.shape),
                    }
                    bg_ref, _ = self.select_best_reference(smeta, bg_library, kind="bg")
                    dk_ref, _ = self.select_best_reference(smeta, dark_library, kind="dark")
                    bg_match = Path(bg_ref["path"]).name if bg_ref else "æ— åŒ¹é…"
                    dark_match = Path(dk_ref["path"]).name if dk_ref else "æ— åŒ¹é…"
                except Exception:
                    bg_match = "åŒ¹é…å¤±è´¥"
                    dark_match = "åŒ¹é…å¤±è´¥"

            rows.append({
                "File": Path(fp).name,
                "Exp_s": e if e is not None else np.nan,
                "Mon": m if m is not None else np.nan,
                "Trans": t if t is not None else np.nan,
                "CalcThk_mm": round(d_mm, 4) if np.isfinite(d_mm) else np.nan,
                "BGåŒ¹é…": bg_match,
                "DarkåŒ¹é…": dark_match,
                "Status": stat,
            })

        if np.isfinite(bg_norm) and bg_norm > 0 and sample_norms:
            med_sample_norm = float(np.nanmedian(np.asarray(sample_norms, dtype=np.float64)))
            if np.isfinite(med_sample_norm) and med_sample_norm > 0:
                ratio = bg_norm / med_sample_norm
                if ratio < 0.01 or ratio > 100.0:
                    warnings.append(
                        "BG_Norm ä¸æ ·å“ Norm_s é‡çº§å·®å¼‚è¿‡å¤§ "
                        f"(BG/æ ·å“ä¸­ä½={ratio:.3g}, BG_Norm={bg_norm:.6g}, SampleMed={med_sample_norm:.6g})ã€‚"
                    )
        
        top = tk.Toplevel(self.root)
        top.title("æ‰¹å¤„ç†é¢„æ£€æŸ¥ç»“æœ")
        txt = tk.Text(top, font=("Consolas",9)); txt.pack(fill="both", expand=True)
        txt.insert(tk.END, f"I0 å½’ä¸€åŒ–æ¨¡å¼: {monitor_mode} (norm={self.monitor_norm_formula(monitor_mode)})\n")
        txt.insert(tk.END, f"ç§¯åˆ†æ¨¡å¼: {','.join(selected_modes) if selected_modes else 'æ— '}\n")
        if "1d_sector" in selected_modes:
            txt.insert(
                tk.END,
                f"æ‰‡åŒºè¾“å‡º: each={'ON' if self.t2_sector_save_each.get() else 'OFF'}, "
                f"sum={'ON' if self.t2_sector_save_combined.get() else 'OFF'}\n",
            )
            if sector_specs:
                sec_short = "; ".join([f"{s['index']}:{s['label']}" for s in sector_specs[:8]])
                if len(sector_specs) > 8:
                    sec_short += "; ..."
                txt.insert(tk.END, f"æ‰‡åŒºåˆ—è¡¨: {sec_short}\n")
        txt.insert(tk.END, f"å‚è€ƒæ¨¡å¼: {self.t2_ref_mode.get()}\n")
        txt.insert(tk.END, f"è¯¯å·®æ¨¡å‹: {self.t2_error_model.get()}\n")
        txt.insert(tk.END, f"å¹¶è¡Œçº¿ç¨‹: {self.t2_workers.get()}\n")
        txt.insert(tk.END, "-"*80 + "\n")
        if warnings:
            txt.insert(tk.END, "[é¢„æ£€æŸ¥è­¦å‘Š]\n")
            for w in warnings:
                txt.insert(tk.END, f"- {w}\n")
            if inst_issues:
                for issue in inst_issues[:20]:
                    txt.insert(tk.END, f"  * {issue}\n")
                if len(inst_issues) > 20:
                    txt.insert(tk.END, "  * ...\n")
        else:
            txt.insert(tk.END, "[é¢„æ£€æŸ¥é€šè¿‡] æœªå‘ç°æ˜æ˜¾é…ç½®é—®é¢˜ã€‚\n")
        txt.insert(tk.END, "-"*80 + "\n")
        txt.insert(tk.END, pd.DataFrame(rows).to_string(index=False))

    def get_t2_preview_sample_path(self):
        # ä¼˜å…ˆä½¿ç”¨åˆ—è¡¨å½“å‰é€‰ä¸­é¡¹ï¼›æœªé€‰ä¸­æ—¶ä½¿ç”¨é˜Ÿåˆ—ç¬¬ä¸€ä¸ªï¼›ä»ä¸ºç©ºåˆ™å¼¹æ–‡ä»¶é€‰æ‹©ã€‚
        try:
            sel = self.lb_batch.curselection() if hasattr(self, "lb_batch") else ()
            if sel:
                idx = int(sel[0])
                if 0 <= idx < len(self.t2_files):
                    return self.t2_files[idx]
        except Exception:
            pass

        if getattr(self, "t2_files", None):
            fs = list(dict.fromkeys(self.t2_files))
            if fs:
                return fs[0]

        return filedialog.askopenfilename(
            filetypes=[("Image", "*.tif *.tiff *.edf *.cbf"), ("All Files", "*.*")]
        )

    def _compute_t2_chi_map_deg(self, ai, shape):
        # ä¸ pyFAI azimuth_range å®šä¹‰ä¸€è‡´ï¼š0Â°å³ã€+90Â°ä¸‹ã€-90Â°ä¸Šã€Â±180Â°å·¦
        try:
            chi_rad = np.asarray(ai.center_array(shape, unit="chi_rad"), dtype=np.float64)
        except Exception:
            chi_rad = np.asarray(ai.chiArray(shape), dtype=np.float64)
        chi_deg = np.rad2deg(chi_rad)
        chi_deg = ((chi_deg + 180.0) % 360.0) - 180.0
        return chi_deg

    def _compute_t2_q_map_a_inv(self, ai, shape):
        # ä¼˜å…ˆæ˜¾å¼ A^-1ï¼›æ—§ç‰ˆå…¼å®¹é€€å› qArray(nm^-1) å† /10ã€‚
        try:
            q_map = np.asarray(ai.center_array(shape, unit="q_A^-1"), dtype=np.float64)
            return q_map, "q_A^-1"
        except Exception:
            q_map = np.asarray(ai.qArray(shape), dtype=np.float64) / 10.0
            return q_map, "q_nm^-1/10"

    def _get_t2_preview_context(self):
        sample_path = self.get_t2_preview_sample_path()
        if not sample_path:
            return None

        poni_path = self.global_vars["poni_path"].get().strip()
        if not poni_path:
            raise ValueError("è¯·å…ˆåœ¨ Tab1/Tab2 è®¾ç½® poni æ–‡ä»¶ã€‚")

        ai = pyFAI.load(poni_path)
        data = fabio.open(sample_path).data.astype(np.float64)
        if data.ndim != 2:
            raise ValueError(f"æ ·å“å›¾åƒç»´åº¦é”™è¯¯: {data.shape}")

        valid_mask = np.isfinite(data)
        mask_path = self.t2_mask_path.get().strip() if hasattr(self, "t2_mask_path") else ""
        if mask_path:
            mask_arr = np.asarray(self.load_optional_array(mask_path, "Mask")) != 0
            if mask_arr.shape != data.shape:
                raise ValueError(f"Mask å°ºå¯¸ä¸åŒ¹é…: mask{mask_arr.shape} vs image{data.shape}")
            valid_mask &= ~mask_arr

        finite = data[valid_mask]
        if finite.size == 0:
            raise ValueError("å¯ç”¨å›¾åƒåƒç´ ä¸ºç©ºï¼ˆå¯èƒ½è¢« mask å…¨éƒ¨å±è”½ï¼‰ã€‚")

        lo = float(np.nanpercentile(finite, 1.0))
        hi = float(np.nanpercentile(finite, 99.5))
        if not np.isfinite(lo) or not np.isfinite(hi) or hi <= lo:
            lo = float(np.nanmin(finite))
            hi = float(np.nanmax(finite))
            if hi <= lo:
                hi = lo + 1.0
        show_img = np.clip(data, lo, hi)
        show_img = np.where(np.isfinite(show_img), show_img, lo)

        try:
            cy = float(ai.poni1 / ai.pixel1)
            cx = float(ai.poni2 / ai.pixel2)
            if not (np.isfinite(cy) and np.isfinite(cx)):
                raise ValueError("center invalid")
        except Exception:
            cy = (data.shape[0] - 1) / 2.0
            cx = (data.shape[1] - 1) / 2.0

        return {
            "sample_path": sample_path,
            "ai": ai,
            "data": data,
            "valid_mask": valid_mask,
            "show_img": show_img,
            "cx": cx,
            "cy": cy,
        }

    def preview_iq_window_t2(self):
        try:
            ctx = self._get_t2_preview_context()
            if ctx is None:
                return

            use_sector = bool(self.t2_mode_sector.get())
            sector_specs = []
            chi_deg = None

            if use_sector:
                sector_specs = self.get_t2_sector_specs()
                chi_deg = self._compute_t2_chi_map_deg(ctx["ai"], ctx["data"].shape)
                iq_mask = np.zeros_like(ctx["valid_mask"], dtype=bool)
                for spec in sector_specs:
                    m, _, _, _ = self.build_sector_mask(chi_deg, spec["sec_min"], spec["sec_max"])
                    iq_mask |= m
                iq_mask = iq_mask & ctx["valid_mask"]
                sec_desc = "; ".join([f"S{s['index']}{s['label']}" for s in sector_specs[:6]])
                if len(sector_specs) > 6:
                    sec_desc += "; ..."
                mode_desc = f"æ‰‡åŒºæ¨¡å¼({len(sector_specs)}): {sec_desc}"
            else:
                iq_mask = np.asarray(ctx["valid_mask"], dtype=bool)
                mode_desc = "å…¨ç¯ (æœ‰æ•ˆåƒç´ )"

            if not np.any(iq_mask):
                raise ValueError("I-Q é¢„è§ˆåŒºåŸŸä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ‰‡åŒºèŒƒå›´æˆ– maskã€‚")

            top = tk.Toplevel(self.root)
            top.title(f"I-Q 2Dé¢„è§ˆ - {Path(ctx['sample_path']).name}")
            info = ttk.Label(
                top,
                text=(
                    f"æ ·å“: {Path(ctx['sample_path']).name} | æ¨¡å¼: {mode_desc} | è¦†ç›–åƒç´ : {np.mean(iq_mask)*100:.2f}%\n"
                    "è§’åº¦å®šä¹‰ï¼ˆpyFAI chiï¼‰ï¼š0Â°å‘å³ï¼Œ+90Â°å‘ä¸‹ï¼Œ-90Â°å‘ä¸Šï¼ŒÂ±180Â°å‘å·¦ã€‚"
                ),
                justify="left",
                style="Hint.TLabel",
            )
            info.pack(fill="x", padx=8, pady=(8, 4))

            fig = Figure(figsize=(7.2, 6.0), dpi=100)
            ax = fig.add_subplot(111)
            im = ax.imshow(ctx["show_img"], cmap="gray", origin="upper", interpolation="nearest")
            ov = np.ma.masked_where(~iq_mask, np.ones_like(ctx["show_img"]))
            ax.imshow(ov, cmap="autumn", origin="upper", interpolation="nearest", alpha=0.28, vmin=0.0, vmax=1.0)

            ax.plot(ctx["cx"], ctx["cy"], marker="+", color="cyan", ms=12, mew=2, label="Beam center")
            if use_sector:
                ray_len = float(max(ctx["data"].shape) * 0.75)
                palette = [
                    "#00d1ff", "#ff4d4d", "#3cb371", "#ff8c00", "#9370db",
                    "#ffd700", "#20b2aa", "#dc143c", "#1e90ff", "#8b4513",
                ]
                for i, spec in enumerate(sector_specs):
                    color = palette[i % len(palette)]
                    for j, ang_deg in enumerate([spec["sec_min"], spec["sec_max"]]):
                        ang = math.radians(float(ang_deg))
                        x2 = ctx["cx"] + math.cos(ang) * ray_len
                        y2 = ctx["cy"] + math.sin(ang) * ray_len
                        lbl = None
                        if j == 0 and i < 8:
                            lbl = f"S{spec['index']} {spec['label']}"
                        ax.plot(
                            [ctx["cx"], x2],
                            [ctx["cy"], y2],
                            color=color,
                            lw=1.5,
                            ls="-" if j == 0 else "--",
                            label=lbl,
                        )

            ax.set_title("Tab2 I-Q ç§¯åˆ†åŒºåŸŸé¢„è§ˆ")
            ax.set_xlabel("Pixel X")
            ax.set_ylabel("Pixel Y")
            ax.legend(loc="upper right", fontsize=8)

            cb = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
            cb.set_label("Intensity (clipped)")

            canvas = FigureCanvasTkAgg(fig, master=top)
            canvas.get_tk_widget().pack(fill="both", expand=True, padx=8, pady=6)
            canvas.draw()
            toolbar = NavigationToolbar2Tk(canvas, top)
            toolbar.update()

        except Exception as e:
            messagebox.showerror("I-Q é¢„è§ˆé”™è¯¯", f"{e}\n{traceback.format_exc()}")

    def preview_ichi_window_t2(self):
        try:
            ctx = self._get_t2_preview_context()
            if ctx is None:
                return

            qmin = float(self.t2_rad_qmin.get())
            qmax = float(self.t2_rad_qmax.get())
            if not (np.isfinite(qmin) and np.isfinite(qmax) and qmin < qmax):
                raise ValueError("I-chi é¢„è§ˆ q èŒƒå›´æ— æ•ˆï¼šqmin å¿…é¡» < qmaxã€‚")

            q_map, q_src = self._compute_t2_q_map_a_inv(ctx["ai"], ctx["data"].shape)
            q_mask = np.isfinite(q_map) & (q_map >= qmin) & (q_map <= qmax) & ctx["valid_mask"]
            if not np.any(q_mask):
                raise ValueError("I-chi q ç¯å¸¦ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ q èŒƒå›´ã€poni æˆ– maskã€‚")

            top = tk.Toplevel(self.root)
            top.title(f"I-chi 2Dé¢„è§ˆ - {Path(ctx['sample_path']).name}")
            info = ttk.Label(
                top,
                text=(
                    f"æ ·å“: {Path(ctx['sample_path']).name} | qåŒºé—´: [{qmin:.4g}, {qmax:.4g}] A^-1 | "
                    f"è¦†ç›–åƒç´ : {np.mean(q_mask)*100:.2f}%\n"
                    f"q æ˜ å°„å•ä½: {q_src}ï¼ˆç”¨äºå¯¹åº” Tab2 radial_chi çš„ q é€‰åŒºï¼‰ã€‚"
                ),
                justify="left",
                style="Hint.TLabel",
            )
            info.pack(fill="x", padx=8, pady=(8, 4))

            fig = Figure(figsize=(7.2, 6.0), dpi=100)
            ax = fig.add_subplot(111)
            im = ax.imshow(ctx["show_img"], cmap="gray", origin="upper", interpolation="nearest")
            ov = np.ma.masked_where(~q_mask, np.ones_like(ctx["show_img"]))
            ax.imshow(ov, cmap="spring", origin="upper", interpolation="nearest", alpha=0.30, vmin=0.0, vmax=1.0)

            ax.plot(ctx["cx"], ctx["cy"], marker="+", color="cyan", ms=12, mew=2, label="Beam center")
            try:
                contours = ax.contour(
                    q_map,
                    levels=[qmin, qmax],
                    colors=["#00d1ff", "#ff4d4d"],
                    linewidths=1.2,
                )
                if contours is not None:
                    ax.clabel(contours, inline=True, fontsize=8, fmt=lambda v: f"{v:.3g} A^-1")
            except Exception:
                pass

            ax.set_title("Tab2 I-chi (qç¯å¸¦) é¢„è§ˆ")
            ax.set_xlabel("Pixel X")
            ax.set_ylabel("Pixel Y")
            ax.legend(loc="upper right", fontsize=8)

            cb = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
            cb.set_label("Intensity (clipped)")

            canvas = FigureCanvasTkAgg(fig, master=top)
            canvas.get_tk_widget().pack(fill="both", expand=True, padx=8, pady=6)
            canvas.draw()
            toolbar = NavigationToolbar2Tk(canvas, top)
            toolbar.update()

        except Exception as e:
            messagebox.showerror("I-chi é¢„è§ˆé”™è¯¯", f"{e}\n{traceback.format_exc()}")

    def preview_sector_window_t2(self):
        # å…¼å®¹æ—§æŒ‰é’®/æ—§è°ƒç”¨å…¥å£ï¼šè½¬åˆ° I-Q é¢„è§ˆ
        self.preview_iq_window_t2()

    def open_mu_tool(self):
        top = tk.Toplevel(self.root); top.title("åˆé‡‘ Î¼ ä¼°ç®—å™¨ (30 keV)")
        entries = {}
        defaults = {"Ti":64, "Nb":24, "Zr":4, "Sn":8}
        
        ttk.Label(top, text="è´¨é‡åˆ†æ•° (wt%)", font=("Arial", 9, "bold")).grid(row=0, columnspan=2, pady=5)
        
        for i, (k,v) in enumerate(defaults.items()):
            ttk.Label(top, text=k).grid(row=i+1, column=0, padx=5)
            e = ttk.Entry(top, width=5); e.insert(0, v); e.grid(row=i+1, column=1, padx=5)
            entries[k] = e
            
        ttk.Label(top, text="å¯†åº¦ rho (g/cm3):").grid(row=6, column=0)
        e_rho = ttk.Entry(top, width=5); e_rho.insert(0, "5.4"); e_rho.grid(row=6, column=1)
        
        def c():
            try:
                w_tot = sum([float(e.get()) for e in entries.values()])
                if abs(w_tot-100) > 1: messagebox.showwarning("è­¦å‘Š", f"æ€» wt% = {w_tot}")
                mu_m = sum([float(e.get())/100 * XCOM_30KEV.get(k,0) for k,e in entries.items()])
                res = mu_m * float(e_rho.get())
                self.t2_mu.set(round(res, 2)); top.destroy()
            except Exception as e:
                messagebox.showerror("è¾“å…¥é”™è¯¯", f"Î¼ ä¼°ç®—å¤±è´¥: {e}")
        ttk.Button(top, text="åº”ç”¨åˆ°æ‰¹å¤„ç†", command=c).grid(row=7, columnspan=2, pady=10)

    def add_file_row(self, p, l, v, pat, cmd=None):
        f = ttk.Frame(p); f.pack(fill="x", pady=1)
        lbl = ttk.Label(f, text=l, width=15, anchor="e")
        lbl.pack(side="left")
        ent = ttk.Entry(f, textvariable=v)
        ent.pack(side="left", fill="x", expand=True)
        def b():
            fp = filedialog.askopenfilename(filetypes=[("File", pat)])
            if fp: v.set(fp); cmd(fp) if cmd else None
        btn = ttk.Button(f, text="...", width=3, command=b)
        btn.pack(side="left")
        return {"frame": f, "label": lbl, "entry": ent, "button": btn}

    def add_dir_row(self, p, l, v):
        f = ttk.Frame(p); f.pack(fill="x", pady=1)
        lbl = ttk.Label(f, text=l, width=15, anchor="e")
        lbl.pack(side="left")
        ent = ttk.Entry(f, textvariable=v)
        ent.pack(side="left", fill="x", expand=True)
        def b():
            dp = filedialog.askdirectory()
            if dp:
                v.set(dp)
        btn = ttk.Button(f, text="...", width=3, command=b)
        btn.pack(side="left")
        return {"frame": f, "label": lbl, "entry": ent, "button": btn}

    def add_grid_entry(self, p, v, r, c):
        e = ttk.Entry(p, textvariable=v, width=8, justify="center")
        e.grid(row=r, column=c, padx=2, pady=2)
        return e

    def on_load_std_t1(self, fp):
        e, m, t = self.parse_header(fp)
        if e is not None: self.t1_params["std_exp"].set(e)
        if m is not None: self.t1_params["std_i0"].set(m)
        if t is not None: self.t1_params["std_t"].set(t)
    def on_load_bg_t1(self, fp):
        e, m, t = self.parse_header(fp)
        if e is not None: self.t1_params["bg_exp"].set(e)
        if m is not None: self.t1_params["bg_i0"].set(m)
        if t is not None: self.t1_params["bg_t"].set(t)

    def add_batch_files(self):
        fs = filedialog.askopenfilenames(filetypes=[("TIFF", "*.tif *.tiff")])
        for f in fs:
            if f not in self.t2_files:
                self.t2_files.append(f)
                self.lb_batch.insert(tk.END, Path(f).name)
        self.refresh_queue_status()
    def clear_batch_files(self):
        self.t2_files = []; self.lb_batch.delete(0, tk.END)
        self.refresh_queue_status()

    def apply_session(self, session_path: str):
        try:
            sess = load_session(session_path)
        except Exception as e:
            messagebox.showerror("Session Error", f"Failed to read session:\n{e}")
            return

        notes = []
        geom = session_geometry(sess)
        if geom:
            px_mm = geom.get("px_mm")
            wl_a = geom.get("wl_A")
            dist_mm = geom.get("dist_mm")
            self.session_geometry_fallback = {
                "wavelength_a": float(wl_a) if wl_a is not None else None,
                "distance_m": (float(dist_mm) / 1000.0) if dist_mm is not None else None,
                "pixel1_m": (float(px_mm) / 1000.0) if px_mm is not None else None,
                "pixel2_m": (float(px_mm) / 1000.0) if px_mm is not None else None,
                "energy_kev": (HC_KEV_A / float(wl_a)) if (wl_a is not None and float(wl_a) > 0) else None,
            }
            notes.append("Session geometry loaded (used as consistency fallback when headers are missing).")

        # Optional calibration paths from session payload (forward-compatible)
        cal = sess.get("calibration", {}) if isinstance(sess.get("calibration", {}), dict) else {}
        candidate_paths = {
            "poni": str(cal.get("poni_path", sess.get("poni_path", ""))).strip(),
            "bg": str(cal.get("bg_path", sess.get("bg_path", ""))).strip(),
            "dark": str(cal.get("dark_path", sess.get("dark_path", ""))).strip(),
            "std": str(cal.get("std_path", sess.get("std_path", ""))).strip(),
        }
        if candidate_paths["poni"] and Path(candidate_paths["poni"]).is_file():
            self.global_vars["poni_path"].set(candidate_paths["poni"])
            notes.append(f"PONI loaded from session: {Path(candidate_paths['poni']).name}")
        if candidate_paths["bg"] and Path(candidate_paths["bg"]).is_file():
            self.global_vars["bg_path"].set(candidate_paths["bg"])
            notes.append(f"Background loaded from session: {Path(candidate_paths['bg']).name}")
        if candidate_paths["dark"] and Path(candidate_paths["dark"]).is_file():
            self.global_vars["dark_path"].set(candidate_paths["dark"])
            notes.append(f"Dark loaded from session: {Path(candidate_paths['dark']).name}")
        if candidate_paths["std"] and Path(candidate_paths["std"]).is_file():
            self.t1_files["std"].set(candidate_paths["std"])
            self.on_load_std_t1(candidate_paths["std"])
            notes.append(f"Std image loaded from session std_path: {Path(candidate_paths['std']).name}")

        data_path = str(sess.get("data_path", "")).strip()
        if data_path:
            p = Path(data_path)
            if p.is_file() and p.suffix.lower() in (".tif", ".tiff"):
                self.t1_files["std"].set(str(p))
                self.on_load_std_t1(str(p))
                notes.append(f"Std image loaded from session: {p.name}")
            elif p.is_file():
                notes.append(f"Session data is not TIFF, skipped for Std: {p.name}")
            else:
                notes.append(f"Session data path not found: {data_path}")

        if not notes:
            notes.append("Session loaded.")
        messagebox.showinfo("Session Loaded", "\n".join(notes))


SAXSAbsWorkbenchApp = BL19B2_RobustApp


def main(argv=None):
    parser = argparse.ArgumentParser(description="SAXSAbs Workbench")
    parser.add_argument("--session", type=str, default="", help="Path to session json")
    args = parser.parse_args(argv)

    root = tk.Tk()
    app = SAXSAbsWorkbenchApp(root)
    if args.session:
        root.after(80, lambda: app.apply_session(args.session))
    root.mainloop()

if __name__ == "__main__":
    main()

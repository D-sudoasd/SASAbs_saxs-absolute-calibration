"""SAXSAbs Workbench â€” GUI for SAXS absolute intensity calibration.

Part of the saxsabs package.
Repository: https://github.com/D-sudoasd/SASAbs_saxs-absolute-calibration
License: BSD-3-Clause
"""
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import argparse
import sys
import logging
import numpy as np
import fabio
import pyFAI
import matplotlib
matplotlib.use("TkAgg")
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.figure import Figure
from pathlib import Path
import traceback
import math
import pandas as pd
import datetime
import re
import json
import concurrent.futures
import threading
from types import SimpleNamespace

APP_NAME = "SAXSAbs Workbench"
APP_VERSION = "1.0.0"

logger = logging.getLogger(__name__)
SUPPORTED_LANGUAGES = ("en", "zh")

I18N = {
    "en": {
        "app_title": f"{APP_NAME} v{APP_VERSION}",
        "header_title": f"{APP_NAME}  |  Absolute Intensity Calibration",
        "theme_toggle": "ğŸŒ“ Theme",
        "lang_toggle_to_zh": "ä¸­æ–‡",
        "lang_toggle_to_en": "English",
        "tab1": "\U0001f4d0  1. K-Factor Calibration",
        "tab2": "\U0001f4e6  2. Batch Processing",
        "tab3": "\U0001f4c8  3. External 1D \u2192 Abs",
        "tab4": "\u2753  4. Help",
        "t1_guide_title": "Quick Start",
        "t1_guide_text": "â‘  Select standard/background/dark/geometry files\nâ‘¡ Verify auto-loaded Time, I0, T\nâ‘¢ Set standard thickness (mm)\nâ‘£ Run calibration to obtain K\nâ‘¤ Check Std Dev and valid points",
        "t1_files_title": "1. Calibration Files (Required)",
        "t1_phys_title": "2. Physical Parameters",
        "t1_run_btn": "\u25b6  Run K Calibration",
        "t1_hist_btn": "K History",
        "t1_report_title": "Analysis Report",
        "t1_plot_tip": "Plot: black dashed=net signal; blue=K-corrected; red circles=NIST",
        "t2_guide_title": "Batch Workflow",
        "t2_guide_text": "â‘  Ensure K, BG/Dark, and poni are ready\nâ‘¡ Select thickness logic\nâ‘¢ Select one or more integration modes\nâ‘£ Add sample files and run dry-check\nâ‘¤ Start batch and review batch_report.csv",
        "t2_mid_title": "Sample Queue",
        "t2_add_btn": "Add Files",
        "t2_clear_btn": "Clear Queue",
        "t2_check_btn": "Dry Check",
        "t2_run_btn": "\u25b6  Start Batch Processing",
        "t3_guide_title": "External 1D Workflow",
        "t3_guide_text": "â‘  Obtain K in Tab1\nâ‘¡ Select pipeline mode (scaled/raw)\nâ‘¢ Import external 1D files\nâ‘£ Select correction formula and X-axis type\nâ‘¤ Dry-check then batch-export absolute intensity",
        "t3_mid_title": "External 1D Queue",
        "t3_add_btn": "Add 1D Files",
        "t3_clear_btn": "Clear Queue",
        "t3_check_btn": "Dry Check",
        "t3_run_btn": "\u25b6  Start External 1D Calibration",
        "queue_files": "Queue files",
        "queue_dedup": "deduplicated",
        "out_auto_prefix": "Output directories will be created",
        "out_write_prefix": "Output directories under",
        "out_none_mode": "Output: no integration mode selected",
        "msg_help_title": "Help",
        "msg_help_copied": "Help text has been copied to clipboard.",
        "msg_preview_title": "Dry Check",
        "msg_ext_done_title": "External 1D Completed",
        "msg_ext_error_title": "External 1D Error",
        "msg_calib_error_title": "Calibration Error",
        "msg_k_history_title": "K History",
        "msg_batch_error_title": "Batch Processing Error",
        "msg_iq_preview_error_title": "I-Q Preview Error",
        "msg_ichi_preview_error_title": "I-chi Preview Error",
        "msg_warning_title": "Warning",
        "msg_input_error_title": "Input Error",
        "help_panel_title": "Program Help",
        "help_panel_intro": "Goal: obtain a reliable K factor in Tab1, then process robust batches in Tab2.",
        "help_scroll_label": "Help text:",
        "help_copy_btn": "Copy Help Text",
        "help_copy_tooltip": "Copy full help text for sharing or records.",
        "hint_prefix": "Note",
        "session_error_title": "Session Error",
        "session_error_body": "Failed to read session:\n{err}",
        "session_loaded_title": "Session Loaded",
        # --- Tab1 labels ---
        "lbl_t1_std_file": "Standard (GC):",
        "lbl_t1_bg_file": "Background:",
        "lbl_t1_dark_file": "Dark image:",
        "lbl_t1_poni_file": "Geometry (.poni):",
        "lbl_i0_semantic": "I0 mode:",
        "cb_solid_angle": "SolidAngle correction",
        # --- Tab1 hints ---
        "hint_t1_files": "Standard recommended: Glassy Carbon (GC); BG/Dark/poni must share the same geometry and energy.",
        "hint_t1_phys": "Time(s)=exposure; I0=incident monitor; T=transmission(0â€“1). Normalisation follows selected I0 mode.",
        # --- Tab1 tooltips ---
        "tip_t1_guide": "Follow steps 1â€“5 to avoid missing key parameters.",
        "tip_t1_std_entry": "Standard sample 2D image for absolute calibration (GC recommended).",
        "tip_t1_std_btn": "Browse to select standard file.",
        "tip_t1_bg_entry": "Empty-cell / air / background 2D image for subtraction.",
        "tip_t1_bg_btn": "Browse to select background image.",
        "tip_t1_bg_multi": "Multi-select BG images & average (normalised); for capillary blanks / repeats.",
        "tip_t1_dark_entry": "Detector dark-current / electronic noise image.",
        "tip_t1_dark_btn": "Browse to select dark image.",
        "tip_t1_poni_entry": "pyFAI geometry file; controls q conversion accuracy.",
        "tip_t1_poni_btn": "Browse to select .poni file.",
        "tip_t1_std_exp": "Standard exposure time (s).",
        "tip_t1_std_i0": "Standard I0 (monitor reading).",
        "tip_t1_std_t": "Standard transmission; should be in 0â€“1.",
        "tip_t1_std_thk": "Standard thickness (mm); for volume normalisation.",
        "tip_t1_bg_exp": "Background exposure time (s).",
        "tip_t1_bg_i0": "Background I0 (monitor reading).",
        "tip_t1_bg_t": "Background transmission.",
        "tip_t1_norm_mode": "rate: I0 is count rate; integrated: I0 is integrated counts.",
        "tip_t1_norm_hint": "Choose according to beamline output. Wrong choice adds exposure-related systematic error.",
        "tip_t1_solid_angle": "Shared by Tab1 calibration & Tab2 batch. Must be consistent or K is invalid.",
        "tip_t1_calibrate": "Run 2D BG subtraction + 1D integration + NIST matching; writes K factor.",
        "tip_t1_history": "View historical K factor trend to monitor instrument drift.",
        "tip_t1_report": "Displays calibration key metrics: K, valid points, Q overlap range and dispersion.",
        "tip_t1_plot": "If the blue line tracks the red dots, K calibration quality is good.",
        # --- Tab2 labels ---
        "lf_t2_global": "1. Global Settings",
        "lbl_t2_k_factor": "K factor:",
        "lbl_t2_bg_file": "Background:",
        "lbl_t2_i0_semantic": "I0 mode:",
        "lf_t2_thickness": "2. Thickness Strategy",
        "rb_t2_auto_thk": "Auto thickness (d = âˆ’ln(T)/Î¼)",
        "lbl_t2_mu": " Î¼(cmâ»Â¹):",
        "btn_t2_mu_est": "Î¼ est.",
        "rb_t2_fix_thk": "Fixed thickness (mm):",
        "lf_t2_integration": "3. Integration Modes (post BG subtraction)",
        "cb_t2_full_ring": "I-Q full ring",
        "cb_t2_sector": "I-Q sector",
        "btn_t2_iq_preview": "Preview I-Q",
        "lbl_t2_multi_sector": " Multi-sector:",
        "lbl_t2_sector_example": " e.g. -25~25;45~65",
        "cb_t2_sec_save_each": "Save sectors separately",
        "cb_t2_sec_save_sum": "Save merged sector",
        "cb_t2_texture": "I-chi texture",
        "btn_t2_chi_preview": "Preview I-chi",
        "lf_t2_correction": "4. Correction Parameters",
        "cb_t2_solid_angle": "Apply Solid Angle correction",
        "lbl_t2_error_model": "Error model:",
        "lbl_t2_mask": "Mask file:",
        "lbl_t2_flat": "Flat file:",
        "lf_t2_execution": "5. Reference Matching & Execution",
        "rb_t2_ref_fixed": "Fixed BG/Dark",
        "rb_t2_ref_auto": "Auto-match BG/Dark",
        "btn_t2_bg_lib": "BG Library",
        "btn_t2_dark_lib": "Dark Library",
        "btn_t2_clear_lib": "Clear Lib",
        "lbl_t2_workers": "Workers:",
        "cb_t2_resume": "Resume (skip existing output)",
        "cb_t2_overwrite": "Force overwrite",
        "cb_t2_strict": "Strict instrument consistency",
        "lbl_t2_tolerance": "Tolerance(%):",
        "lbl_t2_outdir": "Output dir:",
        # --- Tab2 hints ---
        "hint_t2_global": "K from Tab1. I0 mode selects normalisation formula; BG path for quick confirmation.",
        "hint_t2_thickness": "Auto: d=âˆ’ln(T)/Î¼ ; Fixed: all samples use same thickness (mm).",
        "hint_t2_integration": "Multi-select & output to different folders: full-ring / sector / texture run simultaneously.",
        "hint_t2_correction": "Recommend enabling solid angle. Optional mask / flat / polarisation & error model.",
        "hint_t2_execution": "Fix BG/Dark, or auto-match the closest BG/Dark by metadata.",
        "hint_t2_queue": "Add multiple files. Click 'Dry Check' first to verify headers & thickness.",
        # --- Tab2 tooltips ---
        "tip_t2_guide": "Pre-check before running batch significantly reduces mid-run failures.",
        "tip_t2_k_factor": "Absolute intensity scale factor. Must be > 0.",
        "tip_t2_bg_label": "Current background path (shared from Tab1).",
        "tip_t2_norm_mode": "Global: rate means I0 is count rate; integrated means I0 is integrated counts.",
        "tip_t2_norm_hint": "Affects normalisation factors in both calibration and batch.",
        "tip_t2_auto_thk": "Suitable when every sample has reliable transmission T.",
        "tip_t2_mu": "Linear attenuation coefficient Î¼, unit cmâ»Â¹, must be > 0.",
        "tip_t2_mu_est": "Estimate Î¼ from alloy composition (30 keV empirical).",
        "tip_t2_fix_thk": "When transmission is unreliable or missing, use fixed thickness.",
        "tip_t2_fix_thk_val": "Uniform thickness for all samples, in mm.",
        "tip_t2_mu_label": "Larger Î¼ â†’ smaller thickness for same T.",
        "tip_t2_full": "Recommended for isotropic samples. Can be combined with other modes.",
        "tip_t2_sector": "Integrate a specified azimuthal sector, highlighting directional structure.",
        "tip_t2_sec_min": "Sector start angle (Â°). Supports wrap-around Â±180Â° (e.g. 170 to âˆ’170).",
        "tip_t2_sec_max": "Sector end angle (Â°). Same as start (mod 360) is invalid.",
        "tip_t2_sec_preview": "Open 2D preview of I-Q integration region (sector or full ring).",
        "tip_t2_sec_multi": "Multi-sector list. '-25~25;45~65' or '-25,25 45,65'; empty = use single sector above.",
        "tip_t2_sec_each": "Each sector outputs to its own subfolder (sector_XX_*).",
        "tip_t2_sec_sum": "Merge all sectors by pixel weight into one I-Q and save separately.",
        "tip_t2_texture": "Output I vs azimuthal angle chi in a given q range. Runs alongside I-Q.",
        "tip_t2_qmin": "Texture analysis q minimum (Ã…â»Â¹).",
        "tip_t2_qmax": "Texture analysis q maximum (Ã…â»Â¹), must exceed q_min.",
        "tip_t2_chi_preview": "Open 2D preview of I-chi q-ring band range.",
        "tip_t2_solid_angle": "Must match Tab1 calibration. Mismatch will block batch.",
        "tip_t2_error_model": "azimuthal: azimuthal scatter; poisson: counting stats; none: no errors.",
        "tip_t2_polarization": "Polarisation factor, usually âˆ’1 to 1. 0 = unpolarised.",
        "tip_t2_mask": "Mask image: non-zero pixels are excluded.",
        "tip_t2_flat": "Flat-field correction image (optional).",
        "tip_t2_ref_fixed": "All samples use Tab1 BG/Dark.",
        "tip_t2_ref_auto": "Auto-select BG & Dark closest in exposure/I0/T/time.",
        "tip_t2_bg_lib": "Select background file library for auto-matching.",
        "tip_t2_dark_lib": "Select dark file library for auto-matching.",
        "tip_t2_clear_lib": "Clear BG/Dark libraries.",
        "tip_t2_workers": "Parallel threads; 1 = serial. Suggest 1â€“8.",
        "tip_t2_resume": "Skip existing output files; supports resume after interruption.",
        "tip_t2_overwrite": "Ignore existing output and recalculate.",
        "tip_t2_strict": "Check energy/wavelength/distance/pixel/size consistency; stop on mismatch.",
        "tip_t2_tolerance": "Consistency tolerance %, e.g. 0.5 means 0.5%.",
        "tip_t2_add": "Multi-select TIFF files.",
        "tip_t2_clear": "Clear queue; does not delete files on disk.",
        "tip_t2_check": "Batch-check each file's exp/mon/T and thickness availability.",
        "tip_t2_listbox": "Current sample queue.",
        "tip_t2_run": "Run batch. Single-file failure does not abort the batch.",
        "tip_t2_progress": "Batch processing progress.",
        "tip_t2_outdir": "Optional. Empty = output next to sample files.",
        "tip_t2_out_label": "Output files and batch_report.csv will be written here.",
        # --- Tab3 labels ---
        "lf_t3_global": "1. Global & Formula",
        "lbl_t3_k_factor": "K factor:",
        "lbl_t3_pipeline": "Pipeline:",
        "rb_t3_scaled": "Scale only",
        "rb_t3_raw": "Raw 1D full correction",
        "rb_t3_kd_formula": "Ext. 1D w/o thickness: I_abs = I_rel Ã— K / d",
        "lbl_t3_thk": "Fixed thickness(mm):",
        "rb_t3_k_formula": "Ext. 1D w/ thickness: I_abs = I_rel Ã— K",
        "lbl_t3_x_type": "X-axis type:",
        "lbl_t3_i0_semantic": "I0 mode:",
        "lf_t3_execution": "2. Execution Strategy",
        "cb_t3_resume": "Resume (skip existing output)",
        "cb_t3_overwrite": "Force overwrite",
        "lbl_t3_formats": "Supported: .dat .txt .chi .csv (need X & I columns; Error optional)",
        "lf_t3_raw_params": "3. Raw 1D Correction Params (raw pipeline)",
        "btn_t3_meta_from_batch": "Generate metadata from Tab2 report",
        "cb_t3_meta_thk": "Prefer thk_mm from metadata",
        "cb_t3_sync_bg": "Sync BG params with Tab1 global (bg_exp/bg_i0/bg_t)",
        "lbl_t3_sample_params": "Sample fixed params exp/i0/T:",
        "lbl_t3_bg_params": "BG fixed params exp/i0/T:",
        "lbl_t3_outdir": "Output dir:",
        # --- Tab3 hints ---
        "hint_t3_global": "K from Tab1. Choose pipeline, then formula. Raw pipeline uses exp/I0/T and BG1D/Dark1D.",
        "hint_t3_execution": "Recommend dry-check first. Resume to avoid redundant overwrites.",
        "hint_t3_raw": "Only active when pipeline = Raw 1D. Can use Tab2's batch_report.csv or metadata.csv directly.",
        "hint_t3_queue": "Click 'Dry Check' to verify column parsing for each file.",
        # --- Tab3 tooltips ---
        "tip_t3_guide": "For data already integrated in pyFAI or other software; absolute calibration only.",
        "tip_t3_k": "Must be > 0. Uses latest Tab1 calibration value.",
        "tip_t3_scaled": "For external 1D already BG-subtracted & normalised; just apply absolute scale.",
        "tip_t3_raw": "For external 1D with raw integrated intensity; full 1D-level BG subtraction & normalisation here.",
        "tip_t3_kd": "For external integrated result still in relative intensity (not divided by thickness).",
        "tip_t3_thk": "Only used in K/d mode. Unit: mm.",
        "tip_t3_k_only": "For external integrated result already divided by thickness.",
        "tip_t3_x_mode": "'auto' infers Q_Ã…â»Â¹ or Chi_deg from column names / suffix.",
        "tip_t3_resume": "Skip if output exists; for resuming large batches.",
        "tip_t3_overwrite": "Ignore existing results and recalculate.",
        "tip_t3_meta": "Optional. Supports metadata.csv or Tab2's batch_report.csv.",
        "tip_t3_bg1d": "Required (raw pipeline). BG 1D integrated the same way as the sample.",
        "tip_t3_dark1d": "Optional. Not supplied â†’ treated as zero.",
        "tip_t3_meta_from_batch": "One-click: generate Tab3 metadata.csv from Tab2 batch_report.csv; auto-fill path.",
        "tip_t3_meta_thk": "If enabled and sample's metadata has thk_mm, overrides fixed thickness.",
        "tip_t3_sync_bg": "When enabled, Tab3 BG params auto-update from Tab1/global, avoiding stale values.",
        "tip_t3_add": "Multi-select external integration result files.",
        "tip_t3_clear": "Clear queue only; does not delete files on disk.",
        "tip_t3_check": "Check column recognition, point count, and X-axis type inference.",
        "tip_t3_listbox": "Current external 1D file list for conversion.",
        "tip_t3_run": "Batch-convert external 1D relative intensity to absolute using chosen formula.",
        "tip_t3_progress": "External 1D batch progress.",
        "tip_t3_outdir": "Optional. Empty = output next to first input file.",
        # --- Window titles ---
        "title_t3_dryrun": "External 1D Dry Check Results",
        "title_k_history": "K Factor History Trend",
        "title_t2_dryrun": "Batch Dry Check Results",
        "title_iq_preview": "I-Q 2D Preview â€“ {name}",
        "title_ichi_preview": "I-chi 2D Preview â€“ {name}",
        "title_mu_tool": "Universal Î¼ Calculator (any energy)",
        # --- Standard selector ---
        "lbl_t1_std_type": "Standard:",
        "opt_std_srm3600": "NIST SRM 3600 (GC)",
        "opt_std_water": "Water (H\u2082O)",
        "opt_std_lupolen": "Lupolen (user curve)",
        "opt_std_custom": "Custom (user file)",
        "lbl_t1_water_temp": "Water T (Â°C):",
        "lbl_t1_std_ref_file": "Ref. curve file:",
        "hint_t1_std_water": "Water: q-independent, dÎ£/dÎ© = 0.01632 cm\u207b\xb9 at 20 \u00b0C (Orthaber et al. 2000)",
        "hint_t1_std_lupolen": "Lupolen: batch-dependent; load your beamline calibration curve.",
        # --- Buffer subtraction ---
        "lf_t3_buffer": "Buffer / Solvent Subtraction",
        "cb_t3_buffer_enable": "Enable buffer subtraction",
        "lbl_t3_buffer_file": "Buffer 1D file:",
        "lbl_t3_alpha": "\u03b1 (scale):",
        "lbl_t3_buffer_status": "(not loaded)",
        "lbl_t2_alpha": "BG \u03b1-scale:",
        "cb_t2_buffer_enable": "Enable BG \u03b1-scaling",
        # --- Output format ---
        "lbl_output_format": "Output format:",
        "opt_fmt_tsv": "TSV (tab-separated)",
        "opt_fmt_csv": "CSV (comma-separated)",
        "opt_fmt_cansas_xml": "canSAS 1D XML",
        "opt_fmt_nxcansas_h5": "NXcanSAS HDF5",
        # --- Mu tool new keys ---
        "lbl_mu_energy": "Energy (keV):",
        "lbl_mu_energy_or_wl": "or wavelength (Ã…):",
        "lbl_mu_preset": "Preset material:",
        "lbl_mu_custom_comp": "Custom (El:wt%, ...)",
        "lbl_mu_result_murho": "\u03bc/\u03c1 (cm\xb2/g):",
        "lbl_mu_result_mu": "\u03bc_linear (cm\u207b\xb9):",
        "btn_mu_add_row": "+ Element",
        "btn_mu_del_row": "- Element",
        "lbl_mu_contrib": "Element contributions",
        # --- Messagebox bodies ---
        "msg_meta_gen_title": "Metadata Generated",
        "msg_batch_done_title": "Batch Completed",
        "msg_k_history_empty": "No K history yet; run calibration first.",
        "msg_k_history_file_empty": "History file is empty.",
        "msg_k_history_read_error": "Failed to read history: {e}",
        # --- Dry-run panel labels ---
        "pre_k_factor": "K factor:",
        "pre_pipeline": "Pipeline:",
        "pre_corr_mode": "Correction mode:",
        "pre_fixed_thk": "Fixed thickness(mm):",
        "pre_x_mode": "X-axis mode:",
        "pre_i0_semantic": "I0 mode:",
        "pre_warning_header": "[Dry-Check Warnings]",
        "pre_pass_t3": "[Dry-Check Passed] No obvious issues with parameters.",
        "pre_i0_norm": "I0 normalisation mode:",
        "pre_integ_mode": "Integration mode:",
        "pre_integ_none": "None",
        "pre_sector_output": "Sector output:",
        "pre_sector_list": "Sector list:",
        "pre_ref_mode": "Reference mode:",
        "pre_error_model": "Error model:",
        "pre_workers": "Workers:",
        "pre_pass_t2": "[Dry-Check Passed] No obvious configuration issues.",
        # --- Status / health labels ---
        "status_ok": "OK",
        "status_fail": "FAIL",
        "status_no_match": "No match",
        "status_match_fail": "Match failed",
        # --- Lib info ---
        "var_bg_lib": "BG lib: {n}",
        "var_dark_lib": "Dark lib: {n}",
        # --- Mu tool ---
        "lbl_mu_wt_pct": "Wt% fraction",
        "lbl_mu_density": "Density Ï (g/cmÂ³):",
        "btn_mu_apply": "Apply to batch",
        # --- File row labels (Tab3) ---
        "lbl_t3_bg1d_file": "BG 1D file:",
        "lbl_t3_dark1d_file": "Dark 1D file:",
        # --- Report messages ---
        "rpt_start_calib": "Start calibration (robust mode)...",
        "rpt_i0_norm_mode": "I0 normalisation mode: {mode} (norm={formula})",
        "rpt_solid_angle": "SolidAngle correction: {state}",
        "rpt_calib_ok": "Calibration succeeded (robust estimate)",
        # --- Ext 1D done messagebox ---
        "msg_ext_done_body": "External 1D absolute calibration completed.\nSuccess: {ok}\nSkipped: {skip}\nFailed: {fail}\nOutput dir: {out_dir}\nReport: {report}\nMeta: {meta}",
        # --- Dry-run warnings (Tab3) ---
        "warn_k_le_zero": "K factor â‰¤ 0.",
        "warn_kd_thk_le_zero": "K/d mode: fixed thickness must be > 0 mm.",
        "warn_meta_read_fail": "metadata CSV read failed: {e}",
        "warn_raw_no_meta": "Raw pipeline: no metadata CSV; fixed sample params will be used for all.",
        "warn_raw_no_bg1d": "Raw pipeline: BG 1D file is missing.",
        "warn_bg1d_read_fail": "BG 1D read failed: {e}",
        "warn_dark1d_read_fail": "Dark 1D read failed: {e}",
        "warn_bg_norm_invalid": "BG normalisation factor â‰¤ 0; check BG exp/i0/T.",
        # --- Dry-run warnings (Tab2) ---
        "warn_no_integ_mode": "No integration mode selected (check at least one).",
        "warn_sector_no_output": "Sector mode: no output selected (save each / merge).",
        "warn_sector_angle_invalid": "Sector angle range invalid: {e}",
        "warn_texture_q_invalid": "Texture q range invalid: qmin must be < qmax.",
        "warn_auto_thk_mu": "Auto thickness mode: Î¼ must be > 0.",
        "warn_fix_thk_le_zero": "Fixed thickness must be > 0 mm.",
        "warn_auto_bg_empty": "Auto-match mode: BG library is empty.",
        "warn_auto_dark_empty": "Auto-match mode: Dark library is empty.",
        "warn_inst_issues": "Instrument consistency found {n} issues (see details below).",
        "warn_bg_norm_mismatch": "BG_Norm vs sample Norm_s magnitude mismatch (BG/sample median={ratio:.3g}, BG_Norm={bg_norm:.6g}, SampleMed={med:.6g}).",
        # --- Dry-run ext 1D status/reason ---
        "reason_norm_invalid": "Sample normalisation factor invalid (exp/i0/T)",
        "reason_thk_invalid": "Thickness invalid (fixed thickness or metadata thk_mm)",
        # --- Ext 1D messagebox ---
        "msg_t3_queue_empty": "Queue is empty; please add external 1D files first.",
        # --- Preview info labels ---
        "info_iq_sector": "Sector mode({n}): {desc}",
        "info_iq_full": "Full ring (valid pixels)",
        "info_iq_title": "Tab2 I-Q Integration Preview",
        "info_ichi_title": "Tab2 I-chi (q-ring) Preview",
        "info_iq_line1": "Sample: {name} | Mode: {mode} | Coverage: {pct:.2f}%",
        "info_iq_line2": "Angle convention (pyFAI chi): 0Â° right, +90Â° down, -90Â° up, Â±180Â° left.",
        "info_ichi_line1": "Sample: {name} | q range: [{qmin:.4g}, {qmax:.4g}] Ã…â»Â¹ | Coverage: {pct:.2f}%",
        "info_ichi_line2": "q-map unit: {src} (corresponds to Tab2 radial_chi q selection).",
        # --- Mu tool messagebox ---
        "msg_mu_wt_warn": "Total wt% = {w_tot}",
        "msg_mu_fail": "Î¼ estimation failed: {e}",
    },
    "zh": {
        "app_title": f"{APP_NAME} v{APP_VERSION}",
        "header_title": f"{APP_NAME}ï½œç»å¯¹å¼ºåº¦æ ¡æ­£",
        "theme_toggle": "ğŸŒ“ åˆ‡æ¢æ·±è‰²/æµ…è‰²æ¨¡å¼",
        "lang_toggle_to_zh": "ä¸­æ–‡",
        "lang_toggle_to_en": "English",
        "tab1": "\U0001f4d0  1. K å› å­æ ‡å®š",
        "tab2": "\U0001f4e6  2. æ‰¹å¤„ç†",
        "tab3": "\U0001f4c8  3. å¤–éƒ¨ 1D \u2192 ç»å¯¹å¼ºåº¦",
        "tab4": "\u2753  4. å¸®åŠ©",
        "t1_guide_title": "å¿«é€Ÿæµç¨‹ï¼ˆæ–°æ‰‹ï¼‰",
        "t1_guide_text": "â‘  é€‰æ‹©æ ‡å‡†æ ·/æœ¬åº•/æš—åœº/å‡ ä½•æ–‡ä»¶\nâ‘¡ æ ¸å¯¹è‡ªåŠ¨è¯»å–çš„ Timeã€I0ã€T\nâ‘¢ å¡«å†™æ ‡å‡†æ ·åšåº¦(mm)\nâ‘£ ç‚¹å‡»è¿è¡Œæ ‡å®šï¼Œå¾—åˆ° K å› å­\nâ‘¤ æŸ¥çœ‹æŠ¥å‘Šä¸­çš„ Std Dev ä¸ç‚¹æ•°",
        "t1_files_title": "1. æ ‡å®šæ–‡ä»¶ï¼ˆå¿…é¡»ï¼‰",
        "t1_phys_title": "2. ç‰©ç†å‚æ•°ï¼ˆæ ¸å¿ƒè¾“å…¥ï¼‰",
        "t1_run_btn": "\u25b6  è¿è¡Œ K å› å­æ ‡å®š",
        "t1_hist_btn": "K å†å²",
        "t1_report_title": "åˆ†ææŠ¥å‘Šï¼ˆå»ºè®®é‡ç‚¹çœ‹ Std Devï¼‰",
        "t1_plot_tip": "å›¾ç¤ºè¯´æ˜ï¼šé»‘è™šçº¿=å‡€ä¿¡å·ï¼›è“çº¿=K æ ¡æ­£åï¼›çº¢åœˆ=NIST å‚è€ƒç‚¹",
        "t2_guide_title": "æ‰¹å¤„ç†å·¥ä½œæµï¼ˆæ¨èé¡ºåºï¼‰",
        "t2_guide_text": "â‘  å…ˆç¡®è®¤ K å› å­å’Œ BG/æš—åœº/poni å·²å°±ç»ª\nâ‘¡ é€‰æ‹©åšåº¦é€»è¾‘ï¼ˆè‡ªåŠ¨/å›ºå®šï¼‰\nâ‘¢ é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªç§¯åˆ†æ¨¡å¼ï¼ˆå¯åŒæ—¶å‹¾é€‰ï¼‰\nâ‘£ æ·»åŠ æ ·å“æ–‡ä»¶å¹¶ç‚¹å‡»é¢„æ£€æŸ¥\nâ‘¤ å¯åŠ¨æ‰¹å¤„ç†å¹¶æŸ¥çœ‹ batch_report.csv",
        "t2_mid_title": "æ ·å“é˜Ÿåˆ—",
        "t2_add_btn": "æ·»åŠ æ–‡ä»¶",
        "t2_clear_btn": "æ¸…ç©ºé˜Ÿåˆ—",
        "t2_check_btn": "é¢„æ£€æŸ¥",
        "t2_run_btn": "\u25b6  å¼€å§‹æ‰¹å¤„ç†",
        "t3_guide_title": "å¤–éƒ¨ 1D ç»å¯¹å¼ºåº¦æ ¡æ­£æµç¨‹",
        "t3_guide_text": "â‘  å…ˆåœ¨ Tab1 å¾—åˆ°å¯ä¿¡ K å› å­\nâ‘¡ é€‰æ‹©æµç¨‹ï¼šä»…æ¯”ä¾‹ç¼©æ”¾ / åŸå§‹1Då®Œæ•´æ ¡æ­£\nâ‘¢ å¯¼å…¥å¤–éƒ¨1Dæ–‡ä»¶ï¼ˆåŸå§‹æ¨¡å¼è¿˜éœ€ BG1D/Dark1D ä¸å‚æ•°ï¼‰\nâ‘£ é€‰æ‹©æ ¡æ­£å…¬å¼ï¼ˆK/d æˆ– Kï¼‰ä¸ X è½´ç±»å‹\nâ‘¤ å…ˆé¢„æ£€æŸ¥ï¼Œå†æ‰¹é‡è¾“å‡ºç»å¯¹å¼ºåº¦è¡¨æ ¼",
        "t3_mid_title": "å¤–éƒ¨ 1D æ–‡ä»¶é˜Ÿåˆ—",
        "t3_add_btn": "æ·»åŠ 1Dæ–‡ä»¶",
        "t3_clear_btn": "æ¸…ç©ºé˜Ÿåˆ—",
        "t3_check_btn": "é¢„æ£€æŸ¥",
        "t3_run_btn": "\u25b6  å¼€å§‹å¤–éƒ¨ 1D ç»å¯¹å¼ºåº¦æ ¡æ­£",
        "queue_files": "é˜Ÿåˆ—æ–‡ä»¶",
        "queue_dedup": "å»é‡å",
        "out_auto_prefix": "è¾“å‡ºç›®å½•å°†è‡ªåŠ¨åˆ›å»º",
        "out_write_prefix": "è¾“å‡ºç›®å½•å°†å†™å…¥",
        "out_none_mode": "è¾“å‡ºç›®å½•: æœªé€‰æ‹©ç§¯åˆ†æ¨¡å¼",
        "msg_help_title": "å¸®åŠ©",
        "msg_help_copied": "å¸®åŠ©æ–‡æœ¬å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ã€‚",
        "msg_preview_title": "é¢„æ£€æŸ¥",
        "msg_ext_done_title": "å¤–éƒ¨1Dæ ¡æ­£å®Œæˆ",
        "msg_ext_error_title": "å¤–éƒ¨1Dæ ¡æ­£é”™è¯¯",
        "msg_calib_error_title": "æ ‡å®šé”™è¯¯",
        "msg_k_history_title": "K å†å²",
        "msg_batch_error_title": "æ‰¹å¤„ç†é”™è¯¯",
        "msg_iq_preview_error_title": "I-Q é¢„è§ˆé”™è¯¯",
        "msg_ichi_preview_error_title": "I-chi é¢„è§ˆé”™è¯¯",
        "msg_warning_title": "è­¦å‘Š",
        "msg_input_error_title": "è¾“å…¥é”™è¯¯",
        "help_panel_title": "ç¨‹åºå¸®åŠ©ï¼ˆæ–°æ‰‹ç‰ˆï¼‰",
        "help_panel_intro": "ç›®æ ‡ï¼šå…ˆåœ¨ Tab1 å¾—åˆ°å¯é  K å› å­ï¼Œå†åœ¨ Tab2 åšç¨³å¥æ‰¹å¤„ç†ã€‚",
        "help_scroll_label": "å¸®åŠ©æ–‡æœ¬ï¼ˆå¯æ»šåŠ¨ï¼‰ï¼š",
        "help_copy_btn": "å¤åˆ¶å¸®åŠ©æ–‡æœ¬",
        "help_copy_tooltip": "å¤åˆ¶å®Œæ•´å¸®åŠ©å†…å®¹ï¼Œæ–¹ä¾¿å‘ç»™åŒäº‹æˆ–å­˜æ¡£ã€‚",
        "hint_prefix": "æ³¨é‡Š",
        "session_error_title": "ä¼šè¯é”™è¯¯",
        "session_error_body": "è¯»å–ä¼šè¯å¤±è´¥:\n{err}",
        "session_loaded_title": "ä¼šè¯å·²åŠ è½½",
        # --- Tab1 labels ---
        "lbl_t1_std_file": "æ ‡å‡†æ · (GC):",
        "lbl_t1_bg_file": "èƒŒæ™¯å›¾åƒ:",
        "lbl_t1_dark_file": "æš—åœºå›¾åƒ:",
        "lbl_t1_poni_file": "å‡ ä½•æ–‡ä»¶ (.poni):",
        "lbl_i0_semantic": "I0 è¯­ä¹‰:",
        "cb_solid_angle": "SolidAngleä¿®æ­£",
        # --- Tab1 hints ---
        "hint_t1_files": "æ ‡å‡†æ ·å»ºè®®ç”¨ç»ç’ƒç¢³ï¼ˆGCï¼‰ï¼›èƒŒæ™¯/æš—åœº/poni åº”ä¸æ ·å“ä¿æŒåŒä¸€å®éªŒå‡ ä½•ä¸èƒ½é‡ã€‚",
        "hint_t1_phys": "Time(s)=æ›å…‰æ—¶é—´ï¼›I0=å…¥å°„å¼ºåº¦ç›‘æµ‹å€¼ï¼›T=é€è¿‡ç‡(0~1)ã€‚å½’ä¸€åŒ–æŒ‰ä¸‹æ–¹ I0 è¯­ä¹‰é€‰æ‹©å…¬å¼ã€‚",
        # --- Tab1 tooltips ---
        "tip_t1_guide": "æŒ‰ 1~5 æ­¥æ‰§è¡Œï¼ŒåŸºæœ¬ä¸ä¼šæ¼å…³é”®å‚æ•°ã€‚",
        "tip_t1_std_entry": "ç”¨äºç»å¯¹å¼ºåº¦æ ‡å®šçš„æ ‡å‡†æ ·äºŒç»´å›¾åƒï¼ˆæ¨è GCï¼‰ã€‚",
        "tip_t1_std_btn": "ç‚¹å‡»é€‰æ‹©æ ‡å‡†æ ·æ–‡ä»¶ã€‚",
        "tip_t1_bg_entry": "ç©ºæ ·å“/ç©ºæ°”æˆ–æœ¬åº•æ•£å°„å›¾åƒï¼Œç”¨äº 2D æœ¬åº•æ‰£é™¤ã€‚",
        "tip_t1_bg_btn": "ç‚¹å‡»é€‰æ‹©èƒŒæ™¯å›¾åƒã€‚",
        "tip_t1_bg_multi": "å¤šé€‰èƒŒæ™¯å›¾å¹¶åˆå¹¶æ‰£é™¤ï¼ˆå½’ä¸€åŒ–åå¹³å‡ï¼‰ï¼Œé€‚ç”¨äºç©ºæ¯›ç»†ç®¡/ç©ºç™½é‡å¤ã€‚",
        "tip_t1_dark_entry": "æ¢æµ‹å™¨æš—ç”µæµ/æœ¬åº•å™ªå£°å›¾åƒã€‚",
        "tip_t1_dark_btn": "ç‚¹å‡»é€‰æ‹©æš—åœºå›¾åƒã€‚",
        "tip_t1_poni_entry": "pyFAI å‡ ä½•æ ‡å®šæ–‡ä»¶ï¼Œå†³å®š q è½¬æ¢ç²¾åº¦ã€‚",
        "tip_t1_poni_btn": "ç‚¹å‡»é€‰æ‹© .poni æ–‡ä»¶ã€‚",
        "tip_t1_std_exp": "æ ‡å‡†æ ·æ›å…‰æ—¶é—´ï¼ˆç§’ï¼‰ã€‚",
        "tip_t1_std_i0": "æ ‡å‡†æ · I0ï¼ˆç›‘æµ‹å™¨è¯»æ•°ï¼‰ã€‚",
        "tip_t1_std_t": "æ ‡å‡†æ ·é€è¿‡ç‡ï¼Œå»ºè®®åœ¨ 0~1 ä¹‹é—´ã€‚",
        "tip_t1_std_thk": "æ ‡å‡†æ ·åšåº¦ï¼ˆmmï¼‰ï¼Œç”¨äºä½“ç§¯å½’ä¸€åŒ–ã€‚",
        "tip_t1_bg_exp": "èƒŒæ™¯å›¾æ›å…‰æ—¶é—´ï¼ˆç§’ï¼‰ã€‚",
        "tip_t1_bg_i0": "èƒŒæ™¯å›¾ I0ï¼ˆç›‘æµ‹å™¨è¯»æ•°ï¼‰ã€‚",
        "tip_t1_bg_t": "èƒŒæ™¯å›¾é€è¿‡ç‡ã€‚",
        "tip_t1_norm_mode": "rate: I0 æ˜¯æ¯ç§’è®¡æ•°ç‡ï¼›integrated: I0 æ˜¯æ›å…‰ç§¯åˆ†è®¡æ•°ã€‚",
        "tip_t1_norm_hint": "è¯·æŒ‰çº¿ç«™å®é™…è¾“å‡ºé€‰æ‹©ã€‚é€‰é”™ä¼šå¼•å…¥æ›å…‰æ—¶é—´ç›¸å…³ç³»ç»Ÿè¯¯å·®ã€‚",
        "tip_t1_solid_angle": "Tab1æ ‡å®šä¸Tab2æ‰¹å¤„ç†å…±ç”¨æ­¤è®¾ç½®ã€‚ä¸¤è€…å¿…é¡»ä¸€è‡´ï¼Œå¦åˆ™ K å› å­æ— æ•ˆã€‚",
        "tip_t1_calibrate": "æ‰§è¡Œ 2D æ‰£èƒŒæ™¯ + 1D ç§¯åˆ† + NIST åŒ¹é…ï¼Œè‡ªåŠ¨å†™å…¥ K å› å­ã€‚",
        "tip_t1_history": "æŸ¥çœ‹å†å² K å› å­è¶‹åŠ¿ï¼Œç›‘æ§ä»ªå™¨æ¼‚ç§»ã€‚",
        "tip_t1_report": "ä¼šæ˜¾ç¤ºæ ‡å®šå…³é”®æŒ‡æ ‡ï¼šKã€æœ‰æ•ˆç‚¹æ•°ã€Q é‡å åŒºé—´å’Œç¦»æ•£åº¦ã€‚",
        "tip_t1_plot": "è‹¥è“çº¿ä¸çº¢ç‚¹è¶‹åŠ¿ä¸€è‡´ï¼Œé€šå¸¸è¯´æ˜ K æ ‡å®šè´¨é‡è¾ƒå¥½ã€‚",
        # --- Tab2 labels ---
        "lf_t2_global": "1. å…¨å±€é…ç½®",
        "lbl_t2_k_factor": "K å› å­:",
        "lbl_t2_bg_file": "èƒŒæ™¯æ–‡ä»¶:",
        "lbl_t2_i0_semantic": "I0 è¯­ä¹‰:",
        "lf_t2_thickness": "2. åšåº¦ç­–ç•¥",
        "rb_t2_auto_thk": "è‡ªåŠ¨åšåº¦ (d = -ln(T)/Î¼)",
        "lbl_t2_mu": " Î¼(cmâ»Â¹):",
        "btn_t2_mu_est": "Î¼ä¼°ç®—",
        "rb_t2_fix_thk": "å›ºå®šåšåº¦ (mm):",
        "lf_t2_integration": "3. ç§¯åˆ†æ¨¡å¼ï¼ˆ2D æ‰£èƒŒæ™¯åï¼‰",
        "cb_t2_full_ring": "I-Q å…¨ç¯",
        "cb_t2_sector": "I-Q æ‰‡åŒº",
        "btn_t2_iq_preview": "é¢„è§ˆI-Q",
        "lbl_t2_multi_sector": " å¤šæ‰‡åŒº:",
        "lbl_t2_sector_example": " ä¾‹:-25~25;45~65",
        "cb_t2_sec_save_each": "åˆ†æ‰‡åŒºåˆ†åˆ«ä¿å­˜",
        "cb_t2_sec_save_sum": "æ‰‡åŒºåˆå¹¶ä¿å­˜",
        "cb_t2_texture": "I-chi ç»‡æ„",
        "btn_t2_chi_preview": "é¢„è§ˆI-chi",
        "lf_t2_correction": "4. ä¿®æ­£å‚æ•°",
        "cb_t2_solid_angle": "åº”ç”¨ Solid Angle ä¿®æ­£",
        "lbl_t2_error_model": "è¯¯å·®æ¨¡å‹:",
        "lbl_t2_mask": "Mask æ–‡ä»¶:",
        "lbl_t2_flat": "Flat æ–‡ä»¶:",
        "lf_t2_execution": "5. å‚è€ƒåŒ¹é…ä¸æ‰§è¡Œ",
        "rb_t2_ref_fixed": "å›ºå®š BG/Dark",
        "rb_t2_ref_auto": "è‡ªåŠ¨åŒ¹é… BG/Dark",
        "btn_t2_bg_lib": "é€‰æ‹© BG åº“",
        "btn_t2_dark_lib": "é€‰æ‹© Dark åº“",
        "btn_t2_clear_lib": "æ¸…ç©ºåº“",
        "lbl_t2_workers": "å¹¶è¡Œçº¿ç¨‹:",
        "cb_t2_resume": "æ–­ç‚¹ç»­è·‘(è·³è¿‡å·²å­˜åœ¨è¾“å‡º)",
        "cb_t2_overwrite": "å¼ºåˆ¶è¦†ç›–è¾“å‡º",
        "cb_t2_strict": "ä¸¥æ ¼ä»ªå™¨ä¸€è‡´æ€§æ ¡éªŒ",
        "lbl_t2_tolerance": "é˜ˆå€¼(%):",
        "lbl_t2_outdir": "è¾“å‡ºæ ¹ç›®å½•:",
        # --- Tab2 hints ---
        "hint_t2_global": "K å› å­æ¥è‡ª Tab1 æ ‡å®šç»“æœã€‚I0 è¯­ä¹‰å†³å®šå½’ä¸€åŒ–å…¬å¼ï¼›BG è·¯å¾„ä»…ç”¨äºå¿«é€Ÿç¡®è®¤ã€‚",
        "hint_t2_thickness": "è‡ªåŠ¨æ¨¡å¼: d=-ln(T)/muï¼›å›ºå®šæ¨¡å¼: æ‰€æœ‰æ ·å“ä½¿ç”¨åŒä¸€åšåº¦(mm)ã€‚",
        "hint_t2_integration": "å¯å¤šé€‰å¹¶ä¸€æ¬¡æ€§è¾“å‡ºåˆ°ä¸åŒæ–‡ä»¶å¤¹ï¼šå…¨ç¯/æ‰‡åŒº/ç»‡æ„å¯åŒæ—¶è¿è¡Œã€‚",
        "hint_t2_correction": "å»ºè®®å¼€å¯ solid angleã€‚å¯é€‰ mask/flat/polarization ä¸è¯¯å·®æ¨¡å‹ã€‚",
        "hint_t2_execution": "å¯å›ºå®š BG/Darkï¼Œæˆ–æŒ‰å…ƒæ•°æ®è‡ªåŠ¨åŒ¹é…æœ€æ¥è¿‘çš„ BG/Darkã€‚",
        "hint_t2_queue": 'å¯ä¸€æ¬¡æ·»åŠ å¤šä¸ªæ–‡ä»¶ã€‚å»ºè®®å…ˆç‚¹"é¢„æ£€æŸ¥"ï¼Œç¡®è®¤å¤´ä¿¡æ¯ä¸åšåº¦è®¡ç®—æ˜¯å¦æ­£å¸¸ã€‚',
        # --- Tab2 tooltips ---
        "tip_t2_guide": "å…ˆé¢„æ£€æŸ¥å†æ­£å¼è·‘æ‰¹ï¼Œå¯æ˜¾è‘—å‡å°‘ä¸­é€”å¤±è´¥ã€‚",
        "tip_t2_k_factor": "ç»å¯¹å¼ºåº¦æ¯”ä¾‹å› å­ã€‚å¿…é¡»å¤§äº 0ã€‚",
        "tip_t2_bg_label": "å½“å‰å¯ç”¨çš„èƒŒæ™¯å›¾è·¯å¾„ï¼ˆç”± Tab1 å…±äº«ï¼‰ã€‚",
        "tip_t2_norm_mode": "å…¨å±€ç”Ÿæ•ˆï¼šrate è¡¨ç¤º I0 ä¸ºè®¡æ•°ç‡ï¼›integrated è¡¨ç¤º I0 ä¸ºç§¯åˆ†è®¡æ•°ã€‚",
        "tip_t2_norm_hint": "è¯¥è®¾ç½®ä¼šå½±å“æ ‡å®šä¸æ‰¹å¤„ç†çš„æ‰€æœ‰å½’ä¸€åŒ–å› å­ã€‚",
        "tip_t2_auto_thk": "é€‚åˆæ¯ä¸ªæ ·å“éƒ½å…·æœ‰å¯é é€è¿‡ç‡ T çš„æƒ…å†µã€‚",
        "tip_t2_mu": "çº¿æ€§è¡°å‡ç³»æ•° muï¼Œå•ä½ cm^-1ï¼Œå¿…é¡»å¤§äº 0ã€‚",
        "tip_t2_mu_est": "æŒ‰åˆé‡‘æˆåˆ†ä¼°ç®— muï¼ˆ30 keV ç»éªŒï¼‰ã€‚",
        "tip_t2_fix_thk": "é€è¿‡ç‡ä¸ç¨³å®šæˆ–ç¼ºå¤±æ—¶ï¼Œå»ºè®®æ”¹ä¸ºå›ºå®šåšåº¦ã€‚",
        "tip_t2_fix_thk_val": "æ‰€æœ‰æ ·å“ç»Ÿä¸€åšåº¦å€¼ï¼Œå•ä½ mmã€‚",
        "tip_t2_mu_label": "mu è¶Šå¤§ï¼ŒæŒ‰åŒæ · T ç®—å‡ºçš„åšåº¦è¶Šå°ã€‚",
        "tip_t2_full": "å¯¹å„å‘åŒæ€§æ ·å“ä¼˜å…ˆæ¨èã€‚å¯ä¸å…¶ä»–æ¨¡å¼åŒæ—¶å‹¾é€‰ã€‚",
        "tip_t2_sector": "ä»…å¯¹æŒ‡å®šæ–¹ä½è§’æ‰‡åŒºç§¯åˆ†ï¼Œçªå‡ºæ–¹å‘æ€§ç»“æ„ã€‚å¯å¤šé€‰å¹¶è¡Œè¾“å‡ºã€‚",
        "tip_t2_sec_min": "æ‰‡åŒºèµ·å§‹è§’ï¼ˆåº¦ï¼‰ã€‚æ”¯æŒè·¨ Â±180Â°ï¼ˆä¾‹å¦‚ 170 åˆ° -170ï¼‰ã€‚",
        "tip_t2_sec_max": "æ‰‡åŒºç»“æŸè§’ï¼ˆåº¦ï¼‰ã€‚ä¸èµ·å§‹è§’ç›¸åŒï¼ˆæ¨¡360ï¼‰æ— æ•ˆã€‚",
        "tip_t2_sec_preview": "å¼¹å‡º2Dçª—å£é¢„è§ˆ I-Q ç§¯åˆ†åŒºåŸŸï¼ˆæ‰‡åŒºæˆ–å…¨ç¯ï¼‰ï¼Œç”¨äºç¡®è®¤é€‰åŒºã€‚",
        "tip_t2_sec_multi": "å¤šæ‰‡åŒºåˆ—è¡¨ã€‚æ”¯æŒ `-25~25;45~65`ã€`-25,25 45,65` ç­‰æ ¼å¼ï¼›ç•™ç©ºæ—¶ä½¿ç”¨ä¸Šæ–¹å•æ‰‡åŒºã€‚",
        "tip_t2_sec_each": "æ¯ä¸ªæ‰‡åŒºè¾“å‡ºåˆ°ç‹¬ç«‹å­æ–‡ä»¶å¤¹ï¼ˆsector_XX_*ï¼‰ã€‚",
        "tip_t2_sec_sum": "å°†æ‰€æœ‰æ‰‡åŒºæŒ‰åƒç´ æƒé‡åˆå¹¶æˆä¸€æ¡ I-Qï¼Œå¹¶å•ç‹¬è¾“å‡ºã€‚",
        "tip_t2_texture": "åœ¨ç»™å®š q èŒƒå›´å†…è¾“å‡º I éšæ–¹ä½è§’ chi çš„åˆ†å¸ƒã€‚å¯ä¸ I-Q åŒæ—¶è¾“å‡ºã€‚",
        "tip_t2_qmin": "ç»‡æ„åˆ†æ q æœ€å°å€¼ï¼ˆA^-1ï¼‰ã€‚",
        "tip_t2_qmax": "ç»‡æ„åˆ†æ q æœ€å¤§å€¼ï¼ˆA^-1ï¼‰ï¼Œéœ€å¤§äº q_minã€‚",
        "tip_t2_chi_preview": "å¼¹å‡º2Dçª—å£é¢„è§ˆ I-chi ä½¿ç”¨çš„ q ç¯å¸¦èŒƒå›´ã€‚",
        "tip_t2_solid_angle": "å¿…é¡»ä¸ Tab1 æ ‡å®šæ—¶ä¿æŒä¸€è‡´ã€‚è‹¥ä¸ä¸€è‡´ç¨‹åºä¼šé˜»æ–­æ‰¹å¤„ç†ã€‚",
        "tip_t2_error_model": "azimuthal: æ–¹ä½ç¦»æ•£ï¼›poisson: è®¡æ•°ç»Ÿè®¡ï¼›none: ä¸è®¡ç®—è¯¯å·®ã€‚",
        "tip_t2_polarization": "åæŒ¯å› å­ï¼Œé€šå¸¸åœ¨ -1 åˆ° 1ã€‚0 è¡¨ç¤ºä¸åæŒ¯ã€‚",
        "tip_t2_mask": "æ©è†œå›¾ï¼šéé›¶åƒç´ è§†ä¸ºæ— æ•ˆåŒºåŸŸã€‚",
        "tip_t2_flat": "å¹³åœºæ ¡æ­£å›¾ï¼ˆå¯é€‰ï¼‰ã€‚",
        "tip_t2_ref_fixed": "å…¨æ‰¹æ¬¡ç»Ÿä¸€ä½¿ç”¨ Tab1 æŒ‡å®šçš„ BG/Darkã€‚",
        "tip_t2_ref_auto": "æŒ‰æ›å…‰/I0/T/æ—¶é—´ä¸æ ·å“æœ€æ¥è¿‘åŸåˆ™è‡ªåŠ¨é€‰ BG å’Œ Darkã€‚",
        "tip_t2_bg_lib": "é€‰æ‹©å¯ä¾›è‡ªåŠ¨åŒ¹é…çš„èƒŒæ™¯æ–‡ä»¶é›†åˆã€‚",
        "tip_t2_dark_lib": "é€‰æ‹©å¯ä¾›è‡ªåŠ¨åŒ¹é…çš„æš—åœºæ–‡ä»¶é›†åˆã€‚",
        "tip_t2_clear_lib": "æ¸…ç©º BG/Dark åº“ã€‚",
        "tip_t2_workers": "å¹¶è¡Œçº¿ç¨‹æ•°ï¼Œ1 è¡¨ç¤ºä¸²è¡Œã€‚å»ºè®® 1~8ã€‚",
        "tip_t2_resume": "å·²å­˜åœ¨è¾“å‡ºæ–‡ä»¶æ—¶è‡ªåŠ¨è·³è¿‡ï¼Œæ”¯æŒä¸­æ–­åç»­è·‘ã€‚",
        "tip_t2_overwrite": "å¿½ç•¥å·²å­˜åœ¨è¾“å‡ºå¹¶é‡æ–°è®¡ç®—ã€‚",
        "tip_t2_strict": "æ£€æŸ¥èƒ½é‡/æ³¢é•¿/è·ç¦»/åƒç´ /å°ºå¯¸ä¸€è‡´æ€§ï¼Œä¸ä¸€è‡´åˆ™åœæ­¢ã€‚",
        "tip_t2_tolerance": "ä¸€è‡´æ€§é˜ˆå€¼ç™¾åˆ†æ¯”ï¼Œä¾‹å¦‚ 0.5 è¡¨ç¤º 0.5%ã€‚",
        "tip_t2_add": "æ”¯æŒå¤šé€‰ TIFF æ–‡ä»¶ã€‚",
        "tip_t2_clear": "æ¸…ç©ºé˜Ÿåˆ—ï¼Œä¸ä¼šåˆ é™¤ç£ç›˜æ–‡ä»¶ã€‚",
        "tip_t2_check": "æ‰¹é‡æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶çš„ exp/mon/T å’Œåšåº¦å¯ç”¨æ€§ã€‚",
        "tip_t2_listbox": "æ˜¾ç¤ºå½“å‰å¾…å¤„ç†æ ·å“åˆ—è¡¨ã€‚",
        "tip_t2_run": "æ‰§è¡Œæ‰¹å¤„ç†ã€‚å•æ–‡ä»¶å¤±è´¥ä¸ä¼šä¸­æ–­æ•´æ‰¹ã€‚",
        "tip_t2_progress": "æ˜¾ç¤ºæ‰¹å¤„ç†è¿›åº¦ã€‚",
        "tip_t2_outdir": "å¯é€‰ã€‚ä¸å¡«æ—¶é»˜è®¤è¾“å‡ºåˆ°æ ·å“æ‰€åœ¨ç›®å½•ã€‚",
        "tip_t2_out_label": "è¾“å‡ºæ–‡ä»¶ä¸ batch_report.csv ä¼šå†™å…¥è¯¥ç›®å½•ã€‚",
        # --- Tab3 labels ---
        "lf_t3_global": "1. å…¨å±€ä¸å…¬å¼",
        "lbl_t3_k_factor": "K å› å­:",
        "lbl_t3_pipeline": "æµç¨‹:",
        "rb_t3_scaled": "ä»…æ¯”ä¾‹ç¼©æ”¾",
        "rb_t3_raw": "åŸå§‹1Då®Œæ•´æ ¡æ­£",
        "rb_t3_kd_formula": "å¤–éƒ¨1Dæœªé™¤åšåº¦: I_abs = I_rel * K / d",
        "lbl_t3_thk": "å›ºå®šåšåº¦(mm):",
        "rb_t3_k_formula": "å¤–éƒ¨1Då·²é™¤åšåº¦: I_abs = I_rel * K",
        "lbl_t3_x_type": "Xè½´ç±»å‹:",
        "lbl_t3_i0_semantic": "I0è¯­ä¹‰:",
        "lf_t3_execution": "2. æ‰§è¡Œç­–ç•¥",
        "cb_t3_resume": "æ–­ç‚¹ç»­è·‘(è·³è¿‡å·²å­˜åœ¨è¾“å‡º)",
        "cb_t3_overwrite": "å¼ºåˆ¶è¦†ç›–è¾“å‡º",
        "lbl_t3_formats": "æ”¯æŒæ ¼å¼: .dat .txt .chi .csvï¼ˆåˆ—è‡³å°‘åŒ…å« X ä¸ Iï¼›Error å¯é€‰ï¼‰",
        "lf_t3_raw_params": "3. åŸå§‹1Dæ ¡æ­£å‚æ•°ï¼ˆrawæµç¨‹ï¼‰",
        "btn_t3_meta_from_batch": "ç”± Tab2 æŠ¥å‘Šç”Ÿæˆ metadata",
        "cb_t3_meta_thk": "ä¼˜å…ˆä½¿ç”¨ metadata ä¸­çš„ thk_mm",
        "cb_t3_sync_bg": "BGå‚æ•°è·Ÿéš Tab1 å…¨å±€(bg_exp/bg_i0/bg_t)",
        "lbl_t3_sample_params": "æ ·å“å›ºå®šå‚æ•° exp/i0/T:",
        "lbl_t3_bg_params": "BGå›ºå®šå‚æ•° exp/i0/T:",
        "lbl_t3_outdir": "è¾“å‡ºæ ¹ç›®å½•:",
        # --- Tab3 hints ---
        "hint_t3_global": "K æ¥è‡ª Tab1ã€‚å…ˆé€‰æµç¨‹ï¼Œå†é€‰å…¬å¼ã€‚åŸå§‹1Dæµç¨‹ä¼šç”¨åˆ° exp/I0/T ä¸ BG1D/Dark1Dã€‚",
        "hint_t3_execution": "å»ºè®®å…ˆé¢„æ£€æŸ¥ã€‚å¯æ–­ç‚¹ç»­è·‘ï¼Œé¿å…é‡å¤è¦†ç›–ã€‚",
        "hint_t3_raw": "ä»…å½“æµç¨‹=åŸå§‹1Då®Œæ•´æ ¡æ­£æ—¶ç”Ÿæ•ˆã€‚å¯ç›´æ¥ä½¿ç”¨ Tab2 çš„ batch_report.csv æˆ– metadata.csvã€‚",
        "hint_t3_queue": 'å»ºè®®å…ˆç‚¹"é¢„æ£€æŸ¥"ç¡®è®¤æ¯ä¸ªæ–‡ä»¶çš„åˆ—è§£ææƒ…å†µã€‚',
        # --- Tab3 tooltips ---
        "tip_t3_guide": "é€‚åˆä½ åœ¨ pyFAI/å…¶ä»–è½¯ä»¶å®Œæˆç§¯åˆ†åï¼Œä»…åœ¨æœ¬ç¨‹åºåšç»å¯¹æ ‡å®šã€‚",
        "tip_t3_k": "å¿…é¡» >0ã€‚ä¼˜å…ˆä½¿ç”¨ Tab1 æœ€æ–°æ ‡å®šå€¼ã€‚",
        "tip_t3_scaled": "é€‚åˆå¤–éƒ¨1Då·²åšè¿‡æœ¬åº•/å½’ä¸€åŒ–ï¼Œä»…éœ€ç»å¯¹å¼ºåº¦æ˜ å°„ã€‚",
        "tip_t3_raw": "é€‚åˆå¤–éƒ¨1Dæ˜¯åŸå§‹ç§¯åˆ†å¼ºåº¦ï¼Œéœ€è¦åœ¨æœ¬é¡µå®Œæˆ1Dçº§æ‰£æœ¬åº•å’Œå½’ä¸€åŒ–ã€‚",
        "tip_t3_kd": "é€‚ç”¨äºå¤–éƒ¨ç§¯åˆ†ç»“æœä»æ˜¯ç›¸å¯¹å¼ºåº¦ï¼ˆå°šæœªé™¤åšåº¦ï¼‰ã€‚",
        "tip_t3_thk": "ä»…åœ¨ K/d æ¨¡å¼ä¸‹ä½¿ç”¨ã€‚å•ä½ mmã€‚",
        "tip_t3_k_only": "é€‚ç”¨äºå¤–éƒ¨ç§¯åˆ†ç»“æœå·²ç»åšäº†åšåº¦å½’ä¸€åŒ–ã€‚",
        "tip_t3_x_mode": "auto ä¼šæ ¹æ®åˆ—å/åç¼€æ¨æ–­ Q_A^-1 æˆ– Chi_degã€‚",
        "tip_t3_resume": "è¾“å‡ºå­˜åœ¨æ—¶è·³è¿‡ï¼Œé€‚åˆå¤§æ‰¹é‡ä¸­æ–­åç»§ç»­ã€‚",
        "tip_t3_overwrite": "å¿½ç•¥å·²å­˜åœ¨ç»“æœå¹¶é‡ç®—ã€‚",
        "tip_t3_meta": "å¯é€‰ã€‚æ”¯æŒ metadata.csvï¼Œæˆ–ç›´æ¥é€‰æ‹© Tab2 çš„ batch_report.csvã€‚",
        "tip_t3_bg1d": "å¿…å¡«ï¼ˆrawæµç¨‹ï¼‰ã€‚ä¸æ ·å“åŒç§¯åˆ†æ–¹å¼å¾—åˆ°çš„ BG 1Dã€‚",
        "tip_t3_dark1d": "å¯é€‰ã€‚æœªæä¾›åˆ™æŒ‰ 0 å¤„ç†ã€‚",
        "tip_t3_meta_from_batch": "ä» Tab2 çš„ batch_report.csv ä¸€é”®ç”Ÿæˆ Tab3 å¯ç”¨ metadata.csvï¼Œå¹¶è‡ªåŠ¨å›å¡«è·¯å¾„ã€‚",
        "tip_t3_meta_thk": "å¼€å¯åï¼Œè‹¥æŸæ ·å“ metadata å« thk_mmï¼Œåˆ™è¦†ç›–å›ºå®šåšåº¦ã€‚",
        "tip_t3_sync_bg": "å¼€å¯å Tab3 çš„ BG å‚æ•°ä¼šéš Tab1/å…¨å±€å˜åŒ–è‡ªåŠ¨æ›´æ–°ï¼Œé¿å…é™ˆæ—§å€¼ã€‚",
        "tip_t3_add": "æ”¯æŒå¤šé€‰å¤–éƒ¨ç§¯åˆ†ç»“æœæ–‡ä»¶ã€‚",
        "tip_t3_clear": "ä»…æ¸…ç©ºé˜Ÿåˆ—ï¼Œä¸åˆ é™¤ç£ç›˜æ–‡ä»¶ã€‚",
        "tip_t3_check": "æ£€æŸ¥åˆ—è¯†åˆ«ã€ç‚¹æ•°å’Œåæ ‡ç±»å‹æ¨æ–­ã€‚",
        "tip_t3_listbox": "å½“å‰å¾…è½¬æ¢çš„å¤–éƒ¨1Dæ–‡ä»¶åˆ—è¡¨ã€‚",
        "tip_t3_run": "å°†å¤–éƒ¨1Dç›¸å¯¹å¼ºåº¦æŒ‰é€‰å®šå…¬å¼æ‰¹é‡è½¬æ¢ä¸ºç»å¯¹å¼ºåº¦ã€‚",
        "tip_t3_progress": "æ˜¾ç¤ºå¤–éƒ¨1Dæ‰¹å¤„ç†è¿›åº¦ã€‚",
        "tip_t3_outdir": "å¯é€‰ã€‚ä¸å¡«æ—¶é»˜è®¤è¾“å‡ºåˆ°é¦–ä¸ªè¾“å…¥æ–‡ä»¶æ‰€åœ¨ç›®å½•ã€‚",
        # --- Window titles ---
        "title_t3_dryrun": "å¤–éƒ¨1Dé¢„æ£€æŸ¥ç»“æœ",
        "title_k_history": "K å› å­å†å²è¶‹åŠ¿",
        "title_t2_dryrun": "æ‰¹å¤„ç†é¢„æ£€æŸ¥ç»“æœ",
        "title_iq_preview": "I-Q 2Dé¢„è§ˆ - {name}",
        "title_ichi_preview": "I-chi 2Dé¢„è§ˆ - {name}",
        "title_mu_tool": "é€šç”¨ Î¼ è®¡ç®—å™¨ï¼ˆä»»æ„èƒ½é‡ï¼‰",
        # --- æ ‡å‡†æ ·é€‰æ‹© ---
        "lbl_t1_std_type": "æ ‡å‡†æ ·å“:",
        "opt_std_srm3600": "NIST SRM 3600 (GC)",
        "opt_std_water": "çº¯æ°´ (H\u2082O)",
        "opt_std_lupolen": "Lupolen (ç”¨æˆ·æ›²çº¿)",
        "opt_std_custom": "è‡ªå®šä¹‰ (ç”¨æˆ·æ–‡ä»¶)",
        "lbl_t1_water_temp": "æ°´æ¸© (Â°C):",
        "lbl_t1_std_ref_file": "å‚è€ƒæ›²çº¿æ–‡ä»¶:",
        "hint_t1_std_water": "æ°´æ ‡å‡†: qæ— å…³, dÎ£/dÎ©=0.01632 cm\u207b\xb9 (20 \u00b0C) (Orthaber et al. 2000)",
        "hint_t1_std_lupolen": "Lupolen: æ‰¹æ¬¡ç›¸å…³; è¯·åŠ è½½å…‰æŸçº¿æ ‡å®šæ›²çº¿ã€‚",
        # --- ç¼“å†²æ¶²æ‰£é™¤ ---
        "lf_t3_buffer": "ç¼“å†²æ¶²/æº¶å‰‚æ‰£é™¤",
        "cb_t3_buffer_enable": "å¯ç”¨ç¼“å†²æ¶²æ‰£é™¤",
        "lbl_t3_buffer_file": "ç¼“å†²æ¶²1Dæ–‡ä»¶:",
        "lbl_t3_alpha": "\u03b1 (ç¼©æ”¾):",
        "lbl_t3_buffer_status": "(æœªåŠ è½½)",
        "lbl_t2_alpha": "èƒŒæ™¯ \u03b1ç¼©æ”¾:",
        "cb_t2_buffer_enable": "å¯ç”¨èƒŒæ™¯ \u03b1-ç¼©æ”¾",
        # --- è¾“å‡ºæ ¼å¼ ---
        "lbl_output_format": "è¾“å‡ºæ ¼å¼:",
        "opt_fmt_tsv": "TSV (åˆ¶è¡¨ç¬¦åˆ†éš”)",
        "opt_fmt_csv": "CSV (é€—å·åˆ†éš”)",
        "opt_fmt_cansas_xml": "canSAS 1D XML",
        "opt_fmt_nxcansas_h5": "NXcanSAS HDF5",
        # --- Î¼ è®¡ç®—å™¨æ–°é”® ---
        "lbl_mu_energy": "èƒ½é‡ (keV):",
        "lbl_mu_energy_or_wl": "æˆ–æ³¢é•¿ (Ã…):",
        "lbl_mu_preset": "é¢„è®¾ææ–™:",
        "lbl_mu_custom_comp": "è‡ªå®šä¹‰ (El:wt%, ...)",
        "lbl_mu_result_murho": "\u03bc/\u03c1 (cm\xb2/g):",
        "lbl_mu_result_mu": "\u03bc_linear (cm\u207b\xb9):",
        "btn_mu_add_row": "+ å…ƒç´ ",
        "btn_mu_del_row": "- å…ƒç´ ",
        "lbl_mu_contrib": "å„å…ƒç´ è´¡çŒ®",
        # --- Messagebox bodies ---
        "msg_meta_gen_title": "metadata å·²ç”Ÿæˆ",
        "msg_batch_done_title": "æ‰¹å¤„ç†å®Œæˆ",
        "msg_k_history_empty": "å°šæ—  K å†å²è®°å½•ï¼Œè¯·å…ˆè¿è¡Œä¸€æ¬¡æ ‡å®šã€‚",
        "msg_k_history_file_empty": "å†å²æ–‡ä»¶ä¸ºç©ºã€‚",
        "msg_k_history_read_error": "è¯»å–å†å²å¤±è´¥: {e}",
        # --- Dry-run panel labels ---
        "pre_k_factor": "K å› å­:",
        "pre_pipeline": "æµç¨‹:",
        "pre_corr_mode": "æ ¡æ­£æ¨¡å¼:",
        "pre_fixed_thk": "å›ºå®šåšåº¦(mm):",
        "pre_x_mode": "Xè½´æ¨¡å¼:",
        "pre_i0_semantic": "I0è¯­ä¹‰:",
        "pre_warning_header": "[é¢„æ£€æŸ¥è­¦å‘Š]",
        "pre_pass_t3": "[é¢„æ£€æŸ¥é€šè¿‡] å‚æ•°æœªè§æ˜æ˜¾é—®é¢˜ã€‚",
        "pre_i0_norm": "I0 å½’ä¸€åŒ–æ¨¡å¼:",
        "pre_integ_mode": "ç§¯åˆ†æ¨¡å¼:",
        "pre_integ_none": "æ— ",
        "pre_sector_output": "æ‰‡åŒºè¾“å‡º:",
        "pre_sector_list": "æ‰‡åŒºåˆ—è¡¨:",
        "pre_ref_mode": "å‚è€ƒæ¨¡å¼:",
        "pre_error_model": "è¯¯å·®æ¨¡å‹:",
        "pre_workers": "å¹¶è¡Œçº¿ç¨‹:",
        "pre_pass_t2": "[é¢„æ£€æŸ¥é€šè¿‡] æœªå‘ç°æ˜æ˜¾é…ç½®é—®é¢˜ã€‚",
        # --- Status / health labels ---
        "status_ok": "æ­£å¸¸",
        "status_fail": "å¤±è´¥",
        "status_no_match": "æ— åŒ¹é…",
        "status_match_fail": "åŒ¹é…å¤±è´¥",
        # --- Lib info ---
        "var_bg_lib": "BGåº“: {n}",
        "var_dark_lib": "Darkåº“: {n}",
        # --- Mu tool ---
        "lbl_mu_wt_pct": "è´¨é‡åˆ†æ•° (wt%)",
        "lbl_mu_density": "å¯†åº¦ rho (g/cm3):",
        "btn_mu_apply": "åº”ç”¨åˆ°æ‰¹å¤„ç†",
        # --- File row labels (Tab3) ---
        "lbl_t3_bg1d_file": "BG 1D æ–‡ä»¶:",
        "lbl_t3_dark1d_file": "Dark 1D æ–‡ä»¶:",
        # --- Report messages ---
        "rpt_start_calib": "å¼€å§‹æ ‡å®šï¼ˆç¨³å¥æ¨¡å¼ï¼‰...",
        "rpt_i0_norm_mode": "I0 å½’ä¸€åŒ–æ¨¡å¼: {mode} (norm={formula})",
        "rpt_solid_angle": "SolidAngle ä¿®æ­£: {state}",
        "rpt_calib_ok": "æ ‡å®šæˆåŠŸï¼ˆç¨³å¥ä¼°è®¡ï¼‰",
        # --- Ext 1D done messagebox ---
        "msg_ext_done_body": "å¤–éƒ¨1Dç»å¯¹å¼ºåº¦æ ¡æ­£å®Œæˆã€‚\næˆåŠŸ: {ok}\nè·³è¿‡: {skip}\nå¤±è´¥: {fail}\nè¾“å‡ºç›®å½•: {out_dir}\næŠ¥å‘Š: {report}\nå…ƒæ•°æ®: {meta}",
        # --- Dry-run warnings (Tab3) ---
        "warn_k_le_zero": "K å› å­ <= 0ã€‚",
        "warn_kd_thk_le_zero": "K/d æ¨¡å¼ä¸‹å›ºå®šåšåº¦å¿…é¡» > 0 mmã€‚",
        "warn_meta_read_fail": "metadata CSV è¯»å–å¤±è´¥: {e}",
        "warn_raw_no_meta": "rawæµç¨‹æœªæä¾› metadata CSVï¼Œå°†å…¨éƒ¨ä½¿ç”¨å›ºå®šæ ·å“å‚æ•°ã€‚",
        "warn_raw_no_bg1d": "rawæµç¨‹ç¼ºå°‘ BG 1D æ–‡ä»¶ã€‚",
        "warn_bg1d_read_fail": "BG 1D è¯»å–å¤±è´¥: {e}",
        "warn_dark1d_read_fail": "Dark 1D è¯»å–å¤±è´¥: {e}",
        "warn_bg_norm_invalid": "BG å½’ä¸€åŒ–å› å­ <=0ï¼Œè¯·æ£€æŸ¥ BG exp/i0/Tã€‚",
        # --- Dry-run warnings (Tab2) ---
        "warn_no_integ_mode": "æœªé€‰æ‹©ç§¯åˆ†æ¨¡å¼ï¼ˆè‡³å°‘å‹¾é€‰ä¸€ç§ï¼‰ã€‚",
        "warn_sector_no_output": "æ‰‡åŒºæ¨¡å¼æœªå‹¾é€‰ä»»ä½•è¾“å‡ºï¼ˆåˆ†åˆ«ä¿å­˜/åˆå¹¶ä¿å­˜ï¼‰ã€‚",
        "warn_sector_angle_invalid": "æ‰‡åŒºè§’åº¦èŒƒå›´æ— æ•ˆï¼š{e}",
        "warn_texture_q_invalid": "ç»‡æ„ q èŒƒå›´æ— æ•ˆï¼šqmin å¿…é¡» < qmaxã€‚",
        "warn_auto_thk_mu": "è‡ªåŠ¨åšåº¦æ¨¡å¼ä¸‹ mu å¿…é¡» > 0ã€‚",
        "warn_fix_thk_le_zero": "å›ºå®šåšåº¦å¿…é¡» > 0 mmã€‚",
        "warn_auto_bg_empty": "è‡ªåŠ¨åŒ¹é…æ¨¡å¼ä¸‹ BG åº“ä¸ºç©ºã€‚",
        "warn_auto_dark_empty": "è‡ªåŠ¨åŒ¹é…æ¨¡å¼ä¸‹ Dark åº“ä¸ºç©ºã€‚",
        "warn_inst_issues": "ä»ªå™¨ä¸€è‡´æ€§å‘ç° {n} é¡¹é—®é¢˜ï¼ˆè§ä¸‹æ–¹è¯¦æƒ…ï¼‰ã€‚",
        "warn_bg_norm_mismatch": "BG_Norm ä¸æ ·å“ Norm_s é‡çº§å·®å¼‚è¿‡å¤§ (BG/æ ·å“ä¸­ä½={ratio:.3g}, BG_Norm={bg_norm:.6g}, SampleMed={med:.6g})ã€‚",
        # --- Dry-run ext 1D status/reason ---
        "reason_norm_invalid": "æ ·å“å½’ä¸€åŒ–å› å­æ— æ•ˆï¼ˆexp/i0/Tï¼‰",
        "reason_thk_invalid": "åšåº¦æ— æ•ˆï¼ˆå›ºå®šåšåº¦æˆ–metadata thk_mmï¼‰",
        # --- Ext 1D messagebox ---
        "msg_t3_queue_empty": "é˜Ÿåˆ—ä¸ºç©ºï¼Œè¯·å…ˆæ·»åŠ å¤–éƒ¨1Dæ–‡ä»¶ã€‚",
        # --- Preview info labels ---
        "info_iq_sector": "æ‰‡åŒºæ¨¡å¼({n}): {desc}",
        "info_iq_full": "å…¨ç¯ (æœ‰æ•ˆåƒç´ )",
        "info_iq_title": "Tab2 I-Q ç§¯åˆ†åŒºåŸŸé¢„è§ˆ",
        "info_ichi_title": "Tab2 I-chi (qç¯å¸¦) é¢„è§ˆ",
        "info_iq_line1": "æ ·å“: {name} | æ¨¡å¼: {mode} | è¦†ç›–åƒç´ : {pct:.2f}%",
        "info_iq_line2": "è§’åº¦å®šä¹‰ï¼ˆpyFAI chiï¼‰ï¼š0Â°å‘å³ï¼Œ+90Â°å‘ä¸‹ï¼Œ-90Â°å‘ä¸Šï¼ŒÂ±180Â°å‘å·¦ã€‚",
        "info_ichi_line1": "æ ·å“: {name} | qåŒºé—´: [{qmin:.4g}, {qmax:.4g}] A^-1 | è¦†ç›–åƒç´ : {pct:.2f}%",
        "info_ichi_line2": "q æ˜ å°„å•ä½: {src}ï¼ˆç”¨äºå¯¹åº” Tab2 radial_chi çš„ q é€‰åŒºï¼‰ã€‚",
        # --- Mu tool messagebox ---
        "msg_mu_wt_warn": "æ€» wt% = {w_tot}",
        "msg_mu_fail": "Î¼ ä¼°ç®—å¤±è´¥: {e}",
    },
}

try:
    from saxs_ui_kit import apply_ios_theme, promote_primary_buttons, toggle_theme, ToolTip
except Exception:
    # ---- sv_ttk Sun-Valley theme (lightweight Win11-style) ----
    try:
        import sv_ttk as _sv_ttk
    except ImportError:
        _sv_ttk = None

    def apply_ios_theme(root):
        if _sv_ttk is not None:
            _sv_ttk.set_theme("light")

    def promote_primary_buttons(root):
        return None  # sv_ttk handles Accent.TButton natively

    def toggle_theme(root):
        if _sv_ttk is not None:
            _sv_ttk.toggle_theme()
            # update native tk widgets after theme switch
            app = getattr(root, '_app_ref', None)
            if app is not None:
                app._sync_native_widget_colors()

    class ToolTip:
        """Minimal cross-platform tooltip for ttk / tk widgets."""
        _DELAY_MS = 450
        def __init__(self, widget, text):
            self.widget = widget
            self.text = text
            self._tw = None
            self._id_after = None
            widget.bind("<Enter>", self._schedule, add="+")
            widget.bind("<Leave>", self._hide, add="+")
            widget.bind("<ButtonPress>", self._hide, add="+")

        def _schedule(self, event=None):
            self._hide()
            self._id_after = self.widget.after(self._DELAY_MS, self._show)

        def _show(self):
            if not self.text:
                return
            x = self.widget.winfo_rootx() + 20
            y = self.widget.winfo_rooty() + self.widget.winfo_height() + 4
            tw = tk.Toplevel(self.widget)
            tw.wm_overrideredirect(True)
            tw.wm_geometry(f"+{x}+{y}")
            # Adapt colours to current theme
            is_dark = (_sv_ttk is not None and _sv_ttk.get_theme() == "dark")
            bg = "#3a3a3a" if is_dark else "#ffffe1"
            fg = "#e0e0e0" if is_dark else "#1a1a1a"
            lbl = tk.Label(tw, text=self.text, justify="left",
                           background=bg, foreground=fg,
                           relief="solid", borderwidth=1,
                           font=("Segoe UI", 9), wraplength=360,
                           padx=6, pady=4)
            lbl.pack()
            self._tw = tw

        def _hide(self, event=None):
            if self._id_after:
                self.widget.after_cancel(self._id_after)
                self._id_after = None
            if self._tw:
                self._tw.destroy()
                self._tw = None

        def update_text(self, new_text):
            self.text = new_text

try:
    from saxs_core import load_session, session_geometry
except Exception:
    def load_session(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)

    def session_geometry(session_payload):
        if not isinstance(session_payload, dict):
            return {}
        geom = session_payload.get("geometry", {})
        return geom if isinstance(geom, dict) else {}

try:
    import saxs_mpl_style
except Exception:
    class _SaxsMplStyleFallback:
        @staticmethod
        def apply_nature_style():
            return None

    saxs_mpl_style = _SaxsMplStyleFallback()

_SRC_DIR = Path(__file__).resolve().parent / "src"
if _SRC_DIR.exists() and str(_SRC_DIR) not in sys.path:
    sys.path.insert(0, str(_SRC_DIR))

try:
    from saxsabs.core.calibration import estimate_k_factor_robust
except Exception:
    estimate_k_factor_robust = None

try:
    from saxsabs.constants import (
        NIST_SRM3600_DATA,
        STANDARD_REGISTRY,
        get_reference_data,
        water_dsdw,
    )
except Exception:
    NIST_SRM3600_DATA = np.array([
        [0.008, 35.0], [0.010, 34.2], [0.020, 30.8], [0.030, 28.8],
        [0.040, 27.5], [0.050, 26.8], [0.060, 26.3], [0.080, 25.4],
        [0.100, 23.6], [0.120, 20.8], [0.150, 15.8], [0.180, 10.9],
        [0.200, 8.4],  [0.220, 6.5],  [0.250, 4.2]
    ])
    STANDARD_REGISTRY = None
    get_reference_data = None
    water_dsdw = None

try:
    from saxsabs.core.mu_calculator import (
        calculate_mu,
        mu_rho_single,
        parse_composition_string,
        MATERIAL_PRESETS,
    )
except Exception:
    calculate_mu = None
    mu_rho_single = None
    parse_composition_string = None
    MATERIAL_PRESETS = None

try:
    from saxsabs.core.buffer_subtraction import subtract_buffer
except Exception:
    subtract_buffer = None

try:
    from saxsabs.core.execution_policy import parse_run_policy, should_skip_all_existing
except Exception:
    parse_run_policy = None

    def should_skip_all_existing(existing_flags, policy):
        if not existing_flags:
            return False
        resume_enabled = bool(getattr(policy, "resume_enabled", False))
        overwrite_existing = bool(getattr(policy, "overwrite_existing", False))
        if overwrite_existing:
            return False
        if not resume_enabled:
            return False
        return all(bool(x) for x in existing_flags)

try:
    from saxsabs.core.preflight import evaluate_preflight_gate
except Exception:
    evaluate_preflight_gate = None

try:
    from saxsabs.io.writers import write_cansas1d_xml, write_nxcansas_h5
except Exception:
    write_cansas1d_xml = None
    write_nxcansas_h5 = None

FLOAT_PATTERN = re.compile(r"[-+]?\d*\.?\d+(?:[eE][-+]?\d+)?")
HC_KEV_A = 12.398419843320025  # E(keV) * lambda(A)
MONITOR_NORM_MODES = ("rate", "integrated")

class SAXSAbsWorkbenchApp:
    def __init__(self, root, language="en"):
        self.root = root
        self.language = (language or "en").strip().lower()
        if self.language not in SUPPORTED_LANGUAGES:
            self.language = "en"
        self.root.title(self.tr("app_title"))
        self.root.geometry("1280x900")
        self.root.minsize(1024, 700)
        
        # Apply Nature style globally
        saxs_mpl_style.apply_nature_style()
        
        self.set_style()
        self._tooltips = []
        
        # Top bar for theme toggle
        top_bar = ttk.Frame(self.root)
        top_bar.pack(fill="x", padx=16, pady=(12, 6))
        top_bar.columnconfigure(0, weight=1)
        self.lbl_header_title = ttk.Label(top_bar, text=self.tr("header_title"), style="Title.TLabel")
        self.lbl_header_title.grid(row=0, column=0, sticky="w")

        self.btn_theme = ttk.Button(top_bar, text=self.tr("theme_toggle"), command=lambda: toggle_theme(self.root))
        self.btn_theme.grid(row=0, column=1, sticky="e", padx=(8, 0))

        self.btn_lang = ttk.Button(top_bar, text=self._lang_button_text(), width=10, command=self.toggle_language)
        self.btn_lang.grid(row=0, column=2, sticky="e", padx=(8, 0))

        # Separator under top bar
        ttk.Separator(self.root, orient="horizontal").pack(fill="x", padx=12, pady=(0, 4))
        
        # === å…¨å±€å…±äº«çŠ¶æ€ ===
        self.global_vars = {
            "k_factor": tk.DoubleVar(value=1.0),
            "poni_path": tk.StringVar(),
            "bg_path": tk.StringVar(),
            "dark_path": tk.StringVar(),
            "bg_exp": tk.DoubleVar(value=1.0),
            "bg_i0": tk.DoubleVar(value=1.0),
            "bg_t": tk.DoubleVar(value=1.0),
            "monitor_mode": tk.StringVar(value="rate"),
            "apply_solid_angle": tk.BooleanVar(value=True),
            "k_solid_angle": tk.StringVar(value="unknown"),
        }
        self.session_geometry_fallback = {}

        # === å¸ƒå±€ ===
        self.nb = ttk.Notebook(root)
        self.nb.pack(expand=1, fill="both", padx=8, pady=(0, 8))

        self.tab1 = ttk.Frame(self.nb)
        self.tab2 = ttk.Frame(self.nb)
        self.tab3 = ttk.Frame(self.nb)
        self.tab_help = ttk.Frame(self.nb)

        self.nb.add(self.tab1, text=self.tr("tab1"))
        self.nb.add(self.tab2, text=self.tr("tab2"))
        self.nb.add(self.tab3, text=self.tr("tab3"))
        self.nb.add(self.tab_help, text=self.tr("tab4"))

        # --- Status bar ---
        status_sep = ttk.Separator(self.root, orient="horizontal")
        status_sep.pack(fill="x", side="bottom")
        self._status_var = tk.StringVar(value="Ready")
        self._status_bar = ttk.Label(
            self.root, textvariable=self._status_var, style="Status.TLabel", anchor="w"
        )
        self._status_bar.pack(fill="x", side="bottom")

        self.init_tab1_k_calc()
        self.init_tab2_batch()
        self.init_tab3_external_1d()
        self.init_tab_help()
        promote_primary_buttons(self.root)

    def tr(self, key):
        lang_pack = I18N.get(self.language, I18N["en"])
        return lang_pack.get(key, key)

    def _lang_button_text(self):
        return self.tr("lang_toggle_to_zh") if self.language == "en" else self.tr("lang_toggle_to_en")

    def toggle_language(self):
        self.language = "zh" if self.language == "en" else "en"
        self.refresh_ui_language()

    def refresh_ui_language(self):
        self.root.title(self.tr("app_title"))
        if hasattr(self, "lbl_header_title"):
            self.lbl_header_title.configure(text=self.tr("header_title"))
        if hasattr(self, "btn_theme"):
            self.btn_theme.configure(text=self.tr("theme_toggle"))
        if hasattr(self, "btn_lang"):
            self.btn_lang.configure(text=self._lang_button_text())
        if hasattr(self, "nb"):
            self.nb.tab(self.tab1, text=self.tr("tab1"))
            self.nb.tab(self.tab2, text=self.tr("tab2"))
            self.nb.tab(self.tab3, text=self.tr("tab3"))
            self.nb.tab(self.tab_help, text=self.tr("tab4"))
        if hasattr(self, "_i18n_widgets"):
            for widget, key in self._i18n_widgets:
                try:
                    widget.configure(text=self.tr(key))
                except Exception:
                    pass
        if hasattr(self, "_i18n_tooltips"):
            for tt, key in self._i18n_tooltips:
                try:
                    tt.text = self.tr(key)
                except Exception:
                    pass
        if hasattr(self, "_i18n_hints"):
            for lbl, key in self._i18n_hints:
                try:
                    lbl.configure(text=f"{self.tr('hint_prefix')}: {self.tr(key)}")
                except Exception:
                    pass
        self.refresh_help_text()
        self.refresh_queue_status()
        self.refresh_external_1d_status()

    def _register_i18n_widget(self, widget, key):
        if not hasattr(self, "_i18n_widgets"):
            self._i18n_widgets = []
        self._i18n_widgets.append((widget, key))

    def _fmt_queue_info(self, total, uniq):
        if total == uniq:
            return f"{self.tr('queue_files')}: {uniq}"
        return f"{self.tr('queue_files')}: {total} ({self.tr('queue_dedup')} {uniq})"

    def split_path_list(self, raw):
        if raw is None:
            return []
        s = str(raw).strip()
        if not s:
            return []

        tokens = [t.strip().strip('"').strip("'") for t in re.split(r"[;\n\|]+", s) if t.strip()]
        if not tokens:
            tokens = [s]

        out = []
        seen = set()
        for t in tokens:
            p = str(Path(t))
            k = p.lower()
            if k in seen:
                continue
            seen.add(k)
            out.append(p)
        return out

    def build_composite_bg_net(self, bg_paths, d_dark, monitor_mode, fallback_triplet, ref_shape=None):
        nets = []
        norms = []
        used_paths = []
        dark = np.asarray(d_dark, dtype=np.float64)

        for bg_path in bg_paths:
            img = fabio.open(bg_path)
            d_bg = np.asarray(img.data, dtype=np.float64)
            self._assert_same_shape(d_bg, dark, "bg", "dark")
            if ref_shape is not None and tuple(d_bg.shape) != tuple(ref_shape):
                raise ValueError(f"BG å°ºå¯¸ä¸åŒ¹é…: {d_bg.shape} vs {ref_shape}")

            exp, mon, trans = self.parse_header(bg_path, header_dict=getattr(img, "header", {}))
            n = self.compute_norm_factor(exp, mon, trans, monitor_mode)
            if not np.isfinite(n) or n <= 0:
                n = self.compute_norm_factor(fallback_triplet[0], fallback_triplet[1], fallback_triplet[2], monitor_mode)
            if not np.isfinite(n) or n <= 0:
                raise ValueError(f"èƒŒæ™¯å½’ä¸€åŒ–å› å­æ— æ•ˆ: {Path(bg_path).name}")

            nets.append((d_bg - dark) / float(n))
            norms.append(float(n))
            used_paths.append(str(bg_path))

        if not nets:
            raise ValueError("æœªæä¾›å¯ç”¨èƒŒæ™¯å›¾åƒã€‚")

        bg_net = np.nanmean(np.stack(nets, axis=0), axis=0)
        return bg_net, norms, used_paths

    def _localize_runtime_text(self, msg):
        if self.language != "en":
            return msg
        text = str(msg)
        repl = {
            # --- Report / log prefixes ---
            "å¼€å§‹æ ‡å®šï¼ˆç¨³å¥æ¨¡å¼ï¼‰": "Start calibration (robust mode)",
            "æ ‡å®šæˆåŠŸï¼ˆç¨³å¥ä¼°è®¡ï¼‰": "Calibration succeeded (robust estimate)",
            "æ‰¹å¤„ç†é”™è¯¯": "Batch processing error",
            "å¤–éƒ¨1Dç»å¯¹å¼ºåº¦æ ¡æ­£å®Œæˆ": "External 1D absolute calibration completed",
            "æ‰¹å¤„ç†å®Œæˆ": "Batch processing completed",
            # --- Status values ---
            "æˆåŠŸ": "Success",
            "å¤±è´¥": "Failed",
            "å·²è·³è¿‡": "Skipped",
            "éƒ¨åˆ†æˆåŠŸ": "Partially successful",
            "æ­£å¸¸": "OK",
            "æ— åŒ¹é…": "No match",
            "åŒ¹é…å¤±è´¥": "Match failed",
            # --- Queue / output ---
            "è¾“å‡ºç›®å½•å°†è‡ªåŠ¨åˆ›å»º": "Output directories will be created",
            "è¾“å‡ºç›®å½•å°†å†™å…¥": "Output directories under",
            "é˜Ÿåˆ—æ–‡ä»¶": "Queue files",
            "å»é‡å": "deduplicated",
            # --- Log prefixes ---
            "é…ç½®": "Config",
            "æç¤º": "Hint",
            "è­¦å‘Š": "Warning",
            "é”™è¯¯": "Error",
            "è·³è¿‡": "Skip",
            # --- Log messages ---
            "æ‰€æœ‰è¾“å‡ºå·²å­˜åœ¨": "all outputs already exist",
            "æ‰€æœ‰æ¨¡å¼è¾“å‡ºå·²å­˜åœ¨": "all mode outputs already exist",
            "æ— è¾“å‡º": "no output",
            "å‡€ä¿¡å·å…¨éƒ¨ä¸ºæ— æ•ˆå€¼ï¼Œæ— æ³•è¾“å‡º": "Net signal all invalid; cannot output",
            # --- Exception / validation messages ---
            "æ–‡ä»¶ä¸å®Œæ•´ï¼šè¯·å…ˆé€‰æ‹©æ ‡å‡†æ ·ã€èƒŒæ™¯ã€æš—åœºå’Œ poni": "Incomplete files: select standard, BG, dark, and poni first",
            "æ ‡å‡†æ ·åšåº¦å¿…é¡» > 0 mm": "Standard thickness must be > 0 mm",
            "é˜Ÿåˆ—ä¸ºç©ºï¼šè¯·å…ˆæ·»åŠ å¤–éƒ¨1Dæ–‡ä»¶": "Queue is empty: add external 1D files first",
            "K å› å­æ— æ•ˆï¼ˆå¿…é¡» > 0ï¼‰": "K factor invalid (must be > 0)",
            "æœªçŸ¥æµç¨‹æ¨¡å¼": "Unknown pipeline mode",
            "æœªçŸ¥æ ¡æ­£æ¨¡å¼": "Unknown correction mode",
            "K/d æ¨¡å¼ä¸‹å›ºå®šåšåº¦å¿…é¡» > 0 mm": "K/d mode: fixed thickness must be > 0 mm",
            "rawæµç¨‹å¿…é¡»æä¾› BG 1D æ–‡ä»¶": "Raw pipeline: BG 1D file required",
            "rawæµç¨‹ä¸‹ BG å½’ä¸€åŒ–å› å­æ— æ•ˆï¼Œè¯·æ£€æŸ¥ BG exp/i0/T": "Raw pipeline: BG norm factor invalid; check BG exp/i0/T",
            "æ ·å“å½’ä¸€åŒ–å› å­æ— æ•ˆï¼ˆexp/i0/Tï¼‰": "Sample norm factor invalid (exp/i0/T)",
            "åšåº¦æ— æ•ˆï¼ˆå›ºå®šåšåº¦æˆ–metadata thk_mmï¼‰": "Thickness invalid (fixed or metadata thk_mm)",
            "BG å°ºå¯¸ä¸åŒ¹é…": "BG shape mismatch",
            "èƒŒæ™¯å½’ä¸€åŒ–å› å­æ— æ•ˆ": "Background norm factor invalid",
            "æœªæä¾›å¯ç”¨èƒŒæ™¯å›¾åƒ": "No usable background images provided",
            "æœªæä¾›èƒŒæ™¯å›¾åƒ": "No background images provided",
            "å½’ä¸€åŒ–å› å­ <= 0": "Normalisation factor <= 0",
            "æ‰£èƒŒæ™¯åä¿¡å·è¿‡å¼±": "Signal too weak after BG subtraction",
            # --- I0 / normalisation ---
            "I0 å½’ä¸€åŒ–æ¨¡å¼ä»…æ”¯æŒ": "I0 normalisation mode only supports",
            "æœªçŸ¥ I0 å½’ä¸€åŒ–æ¨¡å¼": "Unknown I0 normalisation mode",
            # --- Parser messages ---
            "è§’åº¦éæ³•": "Invalid angle",
            "æ‰‡åŒºè§’åº¦èŒƒå›´æ— æ•ˆ": "Invalid sector angle range",
            "æ‰‡åŒºè§£æåä¸ºç©º": "Sector parsing result is empty",
            "æ— æ³•è§£ææ–‡ä»¶": "Cannot parse file",
            "æ— æ³•è¯†åˆ«æœ‰æ•ˆæ•°å€¼åˆ—": "Cannot identify valid numeric columns",
            "æ–‡ä»¶æ— æ³•è¯»å–": "File unreadable",
            # --- Metadata ---
            "metadata CSV ç¼ºå°‘æ–‡ä»¶åˆ—": "metadata CSV missing file column",
            "æœªä»æŠ¥å‘Šä¸­æå–åˆ°å¯ç”¨ metadata è¡Œ": "No usable metadata rows extracted from report",
            # --- Instrument check ---
            "æ— æ³•è¯»å–æ–‡ä»¶å¤´": "Cannot read file header",
            "å›¾åƒå°ºå¯¸ä¸ä¸€è‡´": "Image dimensions inconsistent",
            "æ¢æµ‹å™¨å‹å·ä¸ä¸€è‡´": "Detector model inconsistent",
            "æ— æ³•è¯»å– poni åšä¸€è‡´æ€§æ£€æŸ¥": "Cannot read poni for consistency check",
            # --- Batch / load_data ---
            "ç¼ºå°‘è¾“å‡ºç›®å½•æ˜ å°„": "Missing output directory mapping",
            "æ‰‡åŒºç»“æœä¸å®Œæ•´ï¼Œæ— æ³•åˆå¹¶": "Sector results incomplete; cannot merge",
            "ä¸æ”¯æŒçš„ç§¯åˆ†æ¨¡å¼": "Unsupported integration mode",
            "æ–‡ä»¶å¤´ç¼ºå°‘å…³é”®å­—æ®µ": "File header missing key fields",
            "è‡ªåŠ¨åŒ¹é…å¤±è´¥": "Auto-match failed",
            "å¹¶è¡Œçº¿ç¨‹æ•°å¿…é¡»ä¸ºæ­£æ•´æ•°": "Worker count must be a positive integer",
            # --- Preview ---
            "è¯·å…ˆåœ¨ Tab1/Tab2 è®¾ç½® poni æ–‡ä»¶": "Please set poni file in Tab1/Tab2 first",
            "I-chi q ç¯å¸¦ä¸ºç©º": "I-chi q-ring band is empty",
            "I-Q é¢„è§ˆåŒºåŸŸä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ‰‡åŒºèŒƒå›´æˆ– mask": "I-Q preview area empty; check sector range or mask",
            "I-chi é¢„è§ˆ q èŒƒå›´æ— æ•ˆï¼šqmin å¿…é¡» < qmax": "I-chi preview q range invalid: qmin must be < qmax",
            # --- Misc ---
            "è®¡ç®—å¾—åˆ°çš„ K <= 0": "Computed K <= 0",
            "è¾“å‡ºå·²å­˜åœ¨": "output already exists",
            "ç¼ºå°‘æ–‡ä»¶å¤´å­—æ®µ": "Missing header fields",
            "åŒ¹é…åˆ°çš„ BG å¤´å‚æ•°ä¸å®Œæ•´": "Matched BG header params incomplete",
            "pyFAI ä¸æ”¯æŒ radial_unitï¼Œq åŒºé—´å·²æŒ‰ A^-1->nm^-1 è½¬æ¢": "pyFAI unsupported radial_unit; q range converted A^-1->nm^-1",
            "æ¨¡å¼å¤±è´¥": "Mode failed",
        }
        for k, v in repl.items():
            text = text.replace(k, v)
        return text

    def show_info(self, title_key, message):
        messagebox.showinfo(self.tr(title_key), message)

    def show_error(self, title_key, message):
        messagebox.showerror(self.tr(title_key), message)

    def show_warning(self, title_key, message):
        messagebox.showwarning(self.tr(title_key), message)

    def set_style(self):
        # Apply Sun-Valley theme first (light by default)
        apply_ios_theme(self.root)
        style = ttk.Style()
        # Only fall back to clam if sv_ttk is not active
        current = style.theme_use()
        if "sun-valley" not in current and "sv" not in current:
            try:
                style.theme_use("clam")
            except Exception:
                pass

        # --- Unified typography hierarchy ---
        _FONT_FAMILY = "Segoe UI"
        # Detect current theme for adaptive foreground colours
        try:
            import sv_ttk as _sv
            _is_dark = _sv.get_theme() == "dark"
        except Exception:
            _is_dark = False
        _title_fg = "#e0e0e0" if _is_dark else "#1a1a2e"
        _accent_fg = "#60a5fa" if _is_dark else "#0078d4"
        _hint_fg = "#9ca3af" if _is_dark else "#6b7280"

        style.configure("Title.TLabel",
                        font=(_FONT_FAMILY, 13, "bold"),
                        foreground=_title_fg)
        style.configure("Bold.TLabel",
                        font=(_FONT_FAMILY, 9, "bold"))
        style.configure("Group.TLabelframe.Label",
                        font=(_FONT_FAMILY, 9, "bold"),
                        foreground=_accent_fg)
        style.configure("Hint.TLabel",
                        font=(_FONT_FAMILY, 8),
                        foreground=_hint_fg)
        # Accent button font (sv_ttk supplies colours automatically)
        style.configure("Accent.TButton",
                        font=(_FONT_FAMILY, 10, "bold"))
        # Tab label â€“ slightly larger, padded
        style.configure("TNotebook.Tab",
                        font=(_FONT_FAMILY, 10),
                        padding=(14, 6))
        # LabelFrame internal padding â€“ breathable
        style.configure("Group.TLabelframe",
                        padding=(10, 8))
        # Status bar style
        style.configure("Status.TLabel",
                        font=(_FONT_FAMILY, 8),
                        foreground=_hint_fg,
                        padding=(8, 3))

        # Store references for dark-mode syncing (initialise only once)
        if not hasattr(self, "_native_widgets"):
            self._native_widgets: list = []
        if not hasattr(self, "_scroll_canvases"):
            self._scroll_canvases: list = []
        self.root._app_ref = self  # allow toggle_theme callback to reach us

    def _register_native_widget(self, widget):
        """Track a tk.Text or tk.Listbox so its colours follow the theme."""
        self._native_widgets.append(widget)
        self._apply_native_colors(widget)

    def _apply_native_colors(self, widget):
        """Set bg/fg on a single native tk widget according to current theme."""
        try:
            import sv_ttk as _sv
            is_dark = _sv.get_theme() == "dark"
        except Exception:
            is_dark = False
        if is_dark:
            bg, fg, sel_bg, sel_fg = "#2b2b2b", "#e0e0e0", "#264f78", "#ffffff"
            ins = "#e0e0e0"
        else:
            bg, fg, sel_bg, sel_fg = "#ffffff", "#1a1a1a", "#0078d4", "#ffffff"
            ins = "#1a1a1a"
        try:
            widget.configure(bg=bg, fg=fg, selectbackground=sel_bg, selectforeground=sel_fg)
            if isinstance(widget, tk.Text):
                widget.configure(insertbackground=ins)
        except Exception:
            pass

    def _sync_native_widget_colors(self):
        """Called after theme toggle to update all native tk widgets + mpl."""
        # Re-apply adaptive ttk styles (Title, Hint, Group, Status, Tab)
        self.set_style()

        alive = []
        for w in self._native_widgets:
            try:
                w.winfo_exists()  # raises TclError if destroyed
                self._apply_native_colors(w)
                alive.append(w)
            except Exception:
                pass
        self._native_widgets = alive

        # Update scroll-canvas backgrounds
        try:
            import sv_ttk as _sv
            is_dark = _sv.get_theme() == "dark"
        except Exception:
            is_dark = False
        canvas_bg = "#1e1e1e" if is_dark else "#fafafa"
        alive_c = []
        for c in self._scroll_canvases:
            try:
                c.winfo_exists()
                c.configure(bg=canvas_bg)
                alive_c.append(c)
            except Exception:
                pass
        self._scroll_canvases = alive_c

        # Update matplotlib figure backgrounds if present
        fig_bg = "#2b2b2b" if is_dark else "#fafafa"
        ax_bg = "#1e1e1e" if is_dark else "#ffffff"
        txt_c = "#e0e0e0" if is_dark else "#1a1a1a"
        import matplotlib as mpl
        mpl.rcParams.update({
            "figure.facecolor": fig_bg,
            "axes.facecolor": ax_bg,
            "text.color": txt_c,
            "axes.labelcolor": txt_c,
            "xtick.color": txt_c,
            "ytick.color": txt_c,
        })
        for attr in ("fig", "fig_preview"):
            fig = getattr(self, attr, None)
            if fig is not None:
                fig.set_facecolor(fig_bg)
                for ax in fig.get_axes():
                    ax.set_facecolor(ax_bg)
                fig.canvas.draw_idle()

    def _make_scrollable_frame(self, parent):
        """Wrap *parent* with a vertical-scrollable Canvas; return inner Frame."""
        # Choose canvas bg matching theme
        try:
            import sv_ttk as _sv
            _bg = "#1e1e1e" if _sv.get_theme() == "dark" else "#fafafa"
        except Exception:
            _bg = "#fafafa"
        canvas = tk.Canvas(parent, highlightthickness=0, borderwidth=0, bg=_bg)
        vsb = ttk.Scrollbar(parent, orient="vertical", command=canvas.yview)
        inner = ttk.Frame(canvas)
        inner.bind(
            "<Configure>",
            lambda _: canvas.configure(scrollregion=canvas.bbox("all")),
        )
        win_id = canvas.create_window((0, 0), window=inner, anchor="nw")
        canvas.bind(
            "<Configure>",
            lambda e: canvas.itemconfig(win_id, width=e.width),
        )
        canvas.configure(yscrollcommand=vsb.set)
        vsb.pack(side="right", fill="y")
        canvas.pack(side="left", fill="both", expand=True)

        def _on_mousewheel(event):
            canvas.yview_scroll(int(-1 * (event.delta / 120)), "units")

        canvas.bind("<Enter>", lambda _: canvas.bind_all("<MouseWheel>", _on_mousewheel))
        canvas.bind("<Leave>", lambda _: canvas.unbind_all("<MouseWheel>"))
        # Track for dark-mode sync
        self._scroll_canvases.append(canvas)
        return inner

    def add_tooltip(self, widget, text_or_key):
        if widget is None or not text_or_key:
            return
        # If text_or_key is a known i18n key, resolve it; otherwise use raw text
        lang_pack = I18N.get("en", {})
        is_key = text_or_key in lang_pack
        resolved = self.tr(text_or_key) if is_key else text_or_key
        tt = ToolTip(widget, resolved)
        self._tooltips.append(tt)
        if is_key:
            if not hasattr(self, "_i18n_tooltips"):
                self._i18n_tooltips = []
            self._i18n_tooltips.append((tt, text_or_key))

    def add_hint(self, parent, text_or_key, wraplength=420):
        lang_pack = I18N.get("en", {})
        is_key = text_or_key in lang_pack
        resolved = self.tr(text_or_key) if is_key else text_or_key
        lbl = ttk.Label(parent, text=f"{self.tr('hint_prefix')}: {resolved}", style="Hint.TLabel", justify="left", wraplength=wraplength)
        lbl.pack(fill="x", padx=3, pady=(1, 3))
        if is_key:
            if not hasattr(self, "_i18n_hints"):
                self._i18n_hints = []
            self._i18n_hints.append((lbl, text_or_key))
        return lbl

    # =========================================================================
    # æ ¸å¿ƒè§£æå™¨
    # =========================================================================
    def _norm_key(self, key):
        return str(key).strip().lower().replace("_", "").replace(" ", "")

    def _extract_float(self, value):
        if value is None:
            return None
        if isinstance(value, (int, float, np.number)):
            return float(value)

        s = str(value).strip()
        if not s:
            return None

        # æ”¯æŒæ¬§æ´²å°æ•°é€—å·ï¼Œé¿å… "0,85" æ— æ³•è§£æ
        if "," in s and "." not in s:
            s = s.replace(",", ".")
        else:
            s = s.replace(",", "")

        m = FLOAT_PATTERN.search(s)
        if not m:
            return None
        try:
            return float(m.group(0))
        except Exception:
            return None

    def _normalize_transmission(self, trans, raw=None, key=None):
        if trans is None:
            return None
        t = float(trans)
        raw_s = str(raw).strip().lower() if raw is not None else ""
        key_s = self._norm_key(key) if key is not None else ""

        # é€è¿‡ç‡å½’ä¸€åŒ–ç­–ç•¥ï¼š
        # 1) æ˜ç¡®ç™¾åˆ†å·/percent/pct -> æŒ‰ç™¾åˆ†æ•°å¤„ç†
        # 2) 1.0~2.0 è§†ä¸ºè½»å¾®æ¼‚ç§»ï¼Œå¤¹ç´§åˆ° 1.0ï¼ˆé¿å…æŠŠ 1.25 è¯¯åˆ¤æˆ 1.25%ï¼‰
        # 3) 2.0~100 è§†ä½œç™¾åˆ†æ•°å­—é¢é‡ï¼ˆå¦‚ 85 -> 0.85ï¼‰
        has_pct_hint = (
            "%" in raw_s
            or "percent" in raw_s
            or "pct" in raw_s
            or "percent" in key_s
            or "pct" in key_s
        )
        if has_pct_hint:
            t /= 100.0
        elif 1.0 < t <= 2.0:
            # ç§»é™¤æ¿€è¿›æˆªæ–­ï¼Œä¿ç•™ç‰©ç†çœŸå®æ€§
            pass
        elif 2.0 < t <= 100.0:
            t /= 100.0
        return t

    def _assert_same_shape(self, a, b, a_name, b_name):
        if a.shape != b.shape:
            raise ValueError(f"Shape mismatch: {a_name}{a.shape} vs {b_name}{b.shape}")

    def get_monitor_mode(self):
        mode = str(self.global_vars["monitor_mode"].get()).strip().lower()
        if mode not in MONITOR_NORM_MODES:
            raise ValueError(f"I0 å½’ä¸€åŒ–æ¨¡å¼ä»…æ”¯æŒ: {', '.join(MONITOR_NORM_MODES)}")
        return mode

    def monitor_norm_formula(self, mode):
        if mode == "rate":
            return "exp * I0 * T"
        if mode == "integrated":
            return "I0 * T"
        raise ValueError(f"æœªçŸ¥ I0 å½’ä¸€åŒ–æ¨¡å¼: {mode}")

    def compute_norm_factor(self, exp, mon, trans, mode):
        if mon is None or trans is None:
            return np.nan
        try:
            mon_v = float(mon)
            trans_v = float(trans)
        except Exception:
            return np.nan

        if not (np.isfinite(mon_v) and np.isfinite(trans_v)):
            return np.nan
        if mon_v <= 0 or trans_v <= 0:
            return np.nan
        if trans_v > 1.0:
            logger.warning(
                "Transmission T=%.4f > 1.0 (physically impossible); "
                "normalization factor set to NaN. Check header parsing.",
                trans_v,
            )
            return np.nan

        if mode == "rate":
            if exp is None:
                return np.nan
            try:
                exp_v = float(exp)
            except Exception:
                return np.nan
            if not np.isfinite(exp_v) or exp_v <= 0:
                return np.nan
            return exp_v * mon_v * trans_v

        if mode == "integrated":
            return mon_v * trans_v

        raise ValueError(f"æœªçŸ¥ I0 å½’ä¸€åŒ–æ¨¡å¼: {mode}")

    def parse_header(self, filepath, header_dict=None):
        meta = {}

        def add_meta(k, v):
            if k is None or v is None:
                return
            nk = self._norm_key(k)
            if nk:
                meta[nk] = str(v).strip()

        exp_keys = ["exposuretime", "counttime", "acqtime", "exposure", "time"]
        mon_keys = ["monitor", "beammonitor", "ionchamber", "mon", "i0", "flux"]
        trans_keys = ["sampletransmission", "transmission", "trans", "abs"]
        exp_exact_only = {"time"}
        mon_exact_only = {"mon", "i0"}
        trans_exact_only = {"abs"}

        def get_val(keys, exact_only=None):
            exact_only = set(exact_only or [])
            # 1) exact
            for k in keys:
                if k in meta:
                    return meta[k], k

            # 2) prefix/suffixï¼ˆé¿å…é€šé… contains è¯¯å‘½ä¸­ï¼‰
            for mk, mv in meta.items():
                for k in keys:
                    if k in exact_only:
                        continue
                    if mk.startswith(k) or mk.endswith(k):
                        return mv, mk

            # 3) contains ä»…ç”¨äºè¾ƒé•¿å…³é”®å­—
            for mk, mv in meta.items():
                for k in keys:
                    if k in exact_only or len(k) < 6:
                        continue
                    if k in mk:
                        return mv, mk
            return None, None

        def has_keys():
            exp_raw, _ = get_val(exp_keys, exact_only=exp_exact_only)
            mon_raw, _ = get_val(mon_keys, exact_only=mon_exact_only)
            trans_raw, _ = get_val(trans_keys, exact_only=trans_exact_only)
            return (exp_raw is not None) and (mon_raw is not None) and (trans_raw is not None)

        # ä¼˜å…ˆè¯»å– FabIO headerï¼ˆå¯¹ tiff/edf æ›´ç¨³å¥ï¼‰
        need_text_fallback = True
        if header_dict is not None:
            for k, v in header_dict.items():
                add_meta(k, v)
            need_text_fallback = not has_keys()
        else:
            try:
                img = fabio.open(filepath)
                for k, v in getattr(img, "header", {}).items():
                    add_meta(k, v)
                need_text_fallback = not has_keys()
            except Exception:
                need_text_fallback = True

        # å›é€€ï¼šä»æ–‡ä»¶æ–‡æœ¬å¤´æå–
        if need_text_fallback:
            try:
                with open(filepath, "rb") as f:
                    head_bytes = f.read(65536)
                # æŸäº› TIFF å¤´å­—æ®µç”± NUL åˆ†éš”ï¼Œå…ˆæ›¿æ¢å¯é™ä½é”®å€¼ç²˜è¿é£é™©
                head_str = head_bytes.decode("utf-8", errors="ignore").replace("\x00", "\n")
                for line in head_str.splitlines():
                    line = line.strip().lstrip("#").strip()
                    if not line:
                        continue
                    parts = []
                    if "=" in line:
                        parts = line.split("=", 1)
                    elif ":" in line:
                        parts = line.split(":", 1)
                    else:
                        parts = line.split(None, 1)
                    if len(parts) == 2:
                        k = str(parts[0]).strip()
                        # é™åˆ¶ key å½¢æ€ï¼Œé™ä½ä»äºŒè¿›åˆ¶å™ªå£°ä¸­è¯¯è§£æçš„æ¦‚ç‡
                        if not re.match(r"^[A-Za-z_][A-Za-z0-9_\- ]{0,64}$", k):
                            continue
                        add_meta(k, parts[1])
            except Exception:
                pass

        exp_raw, exp_key = get_val(exp_keys, exact_only=exp_exact_only)
        mon_raw, _ = get_val(mon_keys, exact_only=mon_exact_only)
        trans_raw, trans_key = get_val(trans_keys, exact_only=trans_exact_only)

        exp = self._extract_float(exp_raw)
        mon = self._extract_float(mon_raw)
        trans = self._extract_float(trans_raw)

        # æ—¶é—´å•ä½å…¼å®¹ï¼šms/us è‡ªåŠ¨è½¬ä¸ºç§’
        if exp is not None:
            exp_tag = f"{exp_key or ''} {exp_raw or ''}".lower()
            if "ms" in exp_tag:
                exp /= 1000.0
            elif "us" in exp_tag:
                exp /= 1_000_000.0

        trans = self._normalize_transmission(trans, raw=trans_raw, key=trans_key)
        return exp, mon, trans

    def normalize_header_dict(self, header_dict):
        meta = {}
        if not header_dict:
            return meta
        for k, v in header_dict.items():
            nk = self._norm_key(k)
            if nk:
                meta[nk] = str(v).strip()
        return meta

    def meta_get_raw(self, meta, keys):
        for k in keys:
            if k in meta:
                return meta[k], k
        for mk, mv in meta.items():
            for k in keys:
                if k in mk:
                    return mv, mk
        return None, None

    def value_with_unit_to_si(self, raw, target):
        val = self._extract_float(raw)
        if val is None:
            return None
        s = str(raw).lower() if raw is not None else ""

        if target == "distance_m":
            if "mm" in s:
                return val / 1000.0
            if "cm" in s:
                return val / 100.0
            if "um" in s or "micron" in s:
                return val / 1_000_000.0
            if "nm" in s:
                return val / 1_000_000_000.0
            if " m" in f" {s}" or s.endswith("m"):
                return val
            if val > 20:
                return val / 1000.0
            return val

        if target == "pixel_m":
            if "um" in s or "micron" in s:
                return val / 1_000_000.0
            if "mm" in s:
                return val / 1000.0
            if "nm" in s:
                return val / 1_000_000_000.0
            if " m" in f" {s}" or s.endswith("m"):
                return val
            if val > 10:
                return val / 1_000_000.0
            if val > 0.01:
                return val / 1000.0
            return val

        if target == "wavelength_a":
            if "nm" in s:
                return val * 10.0
            if "pm" in s:
                return val / 100.0
            if "m" in s and "mm" not in s and "um" not in s and "nm" not in s:
                return val * 1e10
            return val

        if target == "energy_kev":
            if "mev" in s:
                return val * 1000.0
            if "ev" in s and "kev" not in s:
                return val / 1000.0
            return val

        return val

    def extract_instrument_signature(self, filepath, header_dict=None, shape=None):
        meta = self.normalize_header_dict(header_dict)
        if not meta:
            try:
                img = fabio.open(filepath)
                meta = self.normalize_header_dict(getattr(img, "header", {}))
                if shape is None:
                    shape = tuple(img.data.shape)
            except Exception:
                pass

        wl_raw, _ = self.meta_get_raw(meta, ["wavelength", "lambda", "wave"])
        en_raw, _ = self.meta_get_raw(meta, ["energykev", "energy", "xrayenergy", "beamenergy"])
        dist_raw, _ = self.meta_get_raw(meta, ["detdistance", "distance", "sampledetdist", "camlength"])
        px1_raw, _ = self.meta_get_raw(meta, ["pixel1", "pixelsizey", "pixely", "ypixelsize"])
        px2_raw, _ = self.meta_get_raw(meta, ["pixel2", "pixelsizex", "pixelx", "xpixelsize"])
        det_raw, _ = self.meta_get_raw(meta, ["detector", "detectorname", "detector_model"])

        wl_a = self.value_with_unit_to_si(wl_raw, "wavelength_a")
        en_kev = self.value_with_unit_to_si(en_raw, "energy_kev")
        dist_m = self.value_with_unit_to_si(dist_raw, "distance_m")
        px1_m = self.value_with_unit_to_si(px1_raw, "pixel_m")
        px2_m = self.value_with_unit_to_si(px2_raw, "pixel_m")

        if wl_a is None and en_kev and en_kev > 0:
            wl_a = HC_KEV_A / en_kev
        if en_kev is None and wl_a and wl_a > 0:
            en_kev = HC_KEV_A / wl_a

        return {
            "distance_m": dist_m,
            "pixel1_m": px1_m,
            "pixel2_m": px2_m,
        }

    def relative_diff(self, a, b):
        if a is None or b is None:
            return None
        if not (np.isfinite(a) and np.isfinite(b)):
            return None
        den = max(abs(a), 1e-12)
        return abs(a - b) / den

    def normalize_azimuth_deg(self, angle_deg):
        a = float(angle_deg)
        if not np.isfinite(a):
            raise ValueError(f"è§’åº¦éæ³•: {angle_deg}")
        return ((a + 180.0) % 360.0) - 180.0

    def resolve_sector_range(self, sec_min, sec_max):
        s1 = self.normalize_azimuth_deg(sec_min)
        s2 = self.normalize_azimuth_deg(sec_max)
        span = (s2 - s1 + 360.0) % 360.0
        if np.isclose(span, 0.0, atol=1e-9):
            raise ValueError("æ‰‡åŒºè§’åº¦èŒƒå›´æ— æ•ˆï¼šsec_min ä¸ sec_max ä¸èƒ½ç›¸åŒï¼ˆæ¨¡360ï¼‰ã€‚")

        wrap = s1 > s2
        if wrap:
            segments = [(s1, 180.0), (-180.0, s2)]
        else:
            segments = [(s1, s2)]
        return s1, s2, wrap, segments

    def build_sector_mask(self, chi_deg, sec_min, sec_max):
        s1, s2, wrap, _ = self.resolve_sector_range(sec_min, sec_max)
        chi = np.asarray(chi_deg, dtype=np.float64)
        if wrap:
            mask = (chi >= s1) | (chi <= s2)
        else:
            mask = (chi >= s1) & (chi <= s2)
        return mask, s1, s2, wrap

    def _sector_value_token(self, value):
        s = f"{float(value):.3f}".rstrip("0").rstrip(".")
        if s in {"", "-0"}:
            s = "0"
        s = s.replace("-", "m").replace("+", "p").replace(".", "p")
        return s

    def sector_folder_name(self, idx, sec_min, sec_max):
        return f"sector_{int(idx):02d}_{self._sector_value_token(sec_min)}_to_{self._sector_value_token(sec_max)}"

    def parse_sector_specs(self, text, fallback_pair=None):
        raw = str(text).strip() if text is not None else ""
        pairs = []

        if raw:
            norm = (
                raw.replace("ï¼Œ", ",")
                .replace("ï¼›", ";")
                .replace("ï¼š", ":")
                .replace("ï½", "~")
                .replace("â†’", "->")
                .replace("è‡³", "to")
            )
            pat = re.compile(
                r"([-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)\s*(?:~|,|:|->|to)\s*([-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)",
                re.IGNORECASE,
            )
            for m in pat.finditer(norm):
                pairs.append((float(m.group(1)), float(m.group(2))))

            if not pairs:
                nums = [float(x) for x in FLOAT_PATTERN.findall(norm)]
                if len(nums) >= 2 and len(nums) % 2 == 0:
                    pairs = list(zip(nums[::2], nums[1::2]))

        if not pairs:
            if raw:
                raise ValueError(
                    "æœªè§£æåˆ°æ‰‡åŒºèŒƒå›´ã€‚å¯ç”¨ç¤ºä¾‹ï¼š-25~25;45~65 æˆ– -25,25 45,65ã€‚"
                )
            if fallback_pair is not None:
                a, b = fallback_pair
                pairs = [(float(a), float(b))]
            else:
                raise ValueError("æœªæä¾›æ‰‡åŒºèŒƒå›´ã€‚")

        specs = []
        seen = set()
        for a, b in pairs:
            s1, s2, wrap, segments = self.resolve_sector_range(a, b)
            sig = (round(float(s1), 6), round(float(s2), 6))
            if sig in seen:
                continue
            seen.add(sig)
            idx = len(specs) + 1
            specs.append({
                "index": idx,
                "input_min": float(a),
                "input_max": float(b),
                "sec_min": float(s1),
                "sec_max": float(s2),
                "wrap": bool(wrap),
                "segments": list(segments),
                "label": f"[{s1:.2f},{s2:.2f}]",
                "key": self.sector_folder_name(idx, s1, s2),
            })

        if not specs:
            raise ValueError("æ‰‡åŒºè§£æåä¸ºç©ºï¼Œè¯·æ£€æŸ¥è¾“å…¥ã€‚")
        return specs

    def get_t2_sector_specs(self):
        txt = self.t2_sector_ranges_text.get().strip() if hasattr(self, "t2_sector_ranges_text") else ""
        fallback = (float(self.t2_sec_min.get()), float(self.t2_sec_max.get()))
        return self.parse_sector_specs(txt, fallback_pair=fallback)

    def merge_integrate1d_results(self, results):
        if not results:
            raise ValueError("æ— å¯åˆå¹¶ç§¯åˆ†ç»“æœã€‚")

        r0 = np.asarray(results[0].radial, dtype=np.float64)
        if r0.size < 2:
            raise ValueError("ç§¯åˆ†ç»“æœç‚¹æ•°ä¸è¶³ã€‚")

        sum_w = np.zeros_like(r0, dtype=np.float64)
        sum_iw = np.zeros_like(r0, dtype=np.float64)
        sum_sw2 = np.zeros_like(r0, dtype=np.float64)
        has_sigma = False

        for res in results:
            rr = np.asarray(res.radial, dtype=np.float64)
            if rr.shape != r0.shape or not np.allclose(rr, r0, rtol=1e-7, atol=1e-12, equal_nan=False):
                raise ValueError("åˆ†æ®µæ‰‡åŒºç§¯åˆ†çš„ q ç½‘æ ¼ä¸ä¸€è‡´ï¼Œæ— æ³•åˆå¹¶ã€‚")

            i = np.asarray(res.intensity, dtype=np.float64)
            w = getattr(res, "count", None)
            if w is None:
                w = np.where(np.isfinite(i), 1.0, 0.0)
            else:
                w = np.asarray(w, dtype=np.float64)
                if w.shape != r0.shape:
                    w = np.where(np.isfinite(i), 1.0, 0.0)
                w = np.nan_to_num(w, nan=0.0, posinf=0.0, neginf=0.0)
                w = np.maximum(w, 0.0)

            i_num = np.nan_to_num(i, nan=0.0, posinf=0.0, neginf=0.0)
            sum_iw += i_num * w
            sum_w += w

            sigma = getattr(res, "sigma", None)
            if sigma is not None:
                s = np.asarray(sigma, dtype=np.float64)
                if s.shape == r0.shape:
                    term = np.nan_to_num(s, nan=0.0, posinf=0.0, neginf=0.0) * w
                    sum_sw2 += term * term
                    has_sigma = True

        i_merge = np.divide(sum_iw, sum_w, out=np.full_like(sum_iw, np.nan), where=sum_w > 0)
        sigma_merge = None
        if has_sigma:
            sigma_merge = np.divide(
                np.sqrt(sum_sw2),
                sum_w,
                out=np.full_like(sum_w, np.nan),
                where=sum_w > 0,
            )

        return SimpleNamespace(
            radial=r0,
            intensity=i_merge,
            sigma=sigma_merge,
            count=sum_w,
        )

    def integrate1d_sector(self, ai, img, npt, sec_min, sec_max, **kwargs):
        s1, s2, wrap, segments = self.resolve_sector_range(sec_min, sec_max)

        if len(segments) == 1:
            res = ai.integrate1d(
                img,
                npt,
                unit="q_A^-1",
                azimuth_range=segments[0],
                **kwargs,
            )
            return res, s1, s2, wrap

        parts = []
        for seg in segments:
            parts.append(
                ai.integrate1d(
                    img,
                    npt,
                    unit="q_A^-1",
                    azimuth_range=seg,
                    **kwargs,
                )
            )
        res = self.merge_integrate1d_results(parts)
        return res, s1, s2, wrap

    def check_instrument_consistency(self, file_paths, poni_path=None, tol_pct=0.5):
        if not file_paths:
            return []
        tol = max(float(tol_pct), 0.01) / 100.0
        sigs = []
        for fp in file_paths:
            try:
                img = fabio.open(fp)
                d = img.data
                sig = self.extract_instrument_signature(fp, header_dict=getattr(img, "header", {}), shape=d.shape)
                sigs.append(sig)
            except Exception as e:
                sigs.append({"path": str(fp), "shape": None, "error": str(e)})

        ref = sigs[0]
        fallback = self.session_geometry_fallback if isinstance(self.session_geometry_fallback, dict) else {}
        if fallback:
            for key in ("wavelength_a", "distance_m", "pixel1_m", "pixel2_m", "energy_kev"):
                if ref.get(key) is None and fallback.get(key) is not None:
                    ref[key] = fallback.get(key)

        issues = []
        for s in sigs[1:]:
            p = Path(s.get("path", "")).name
            if "error" in s:
                issues.append(f"{p}: æ— æ³•è¯»å–æ–‡ä»¶å¤´ ({s['error']})")
                continue

            if ref.get("shape") and s.get("shape") and ref["shape"] != s["shape"]:
                issues.append(f"{p}: å›¾åƒå°ºå¯¸ä¸ä¸€è‡´ {s['shape']} != {ref['shape']}")

            if ref.get("detector") and s.get("detector") and ref["detector"] != s["detector"]:
                issues.append(f"{p}: æ¢æµ‹å™¨å‹å·ä¸ä¸€è‡´ {s['detector']} != {ref['detector']}")

            for key, label in [
                ("energy_kev", "èƒ½é‡(keV)"),
                ("wavelength_a", "æ³¢é•¿(A)"),
                ("distance_m", "æ ·æ¢è·(m)"),
                ("pixel1_m", "pixel1(m)"),
                ("pixel2_m", "pixel2(m)"),
            ]:
                rd = self.relative_diff(s.get(key), ref.get(key))
                if rd is not None and rd > tol:
                    issues.append(
                        f"{p}: {label} åå·® {rd*100:.3f}% è¶…è¿‡é˜ˆå€¼ {tol*100:.3f}%"
                    )

        if poni_path:
            try:
                ai = pyFAI.load(poni_path)
                ai_wl_a = ai.wavelength * 1e10 if getattr(ai, "wavelength", None) else None
                if ai_wl_a and ref.get("wavelength_a"):
                    rd = self.relative_diff(ai_wl_a, ref["wavelength_a"])
                    if rd is not None and rd > tol:
                        issues.append(
                            f"poni æ³¢é•¿ä¸æ ·å“å¤´ä¿¡æ¯ä¸ä¸€è‡´: {ai_wl_a:.6g} A vs {ref['wavelength_a']:.6g} A"
                        )
            except Exception as e:
                issues.append(f"æ— æ³•è¯»å– poni åšä¸€è‡´æ€§æ£€æŸ¥: {e}")

        return issues

    def build_output_stem_map(self, files):
        name_count = {}
        for fp in files:
            stem = Path(fp).stem
            name_count[stem] = name_count.get(stem, 0) + 1

        used = set()
        out = {}
        for fp in files:
            p = Path(fp)
            stem = p.stem
            if name_count[stem] == 1:
                candidate = stem
            else:
                candidate = f"{p.parent.name}_{stem}"

            if candidate in used:
                idx = 2
                while f"{candidate}_{idx}" in used:
                    idx += 1
                candidate = f"{candidate}_{idx}"

            used.add(candidate)
            out[fp] = candidate
        return out

    def mode_output_path(self, save_dirs, mode, out_stem):
        ext = ".chi" if mode == "radial_chi" else ".dat"
        return save_dirs[mode] / f"{out_stem}{ext}"

    def build_sample_output_targets(self, context, out_stem):
        targets = []
        for mode in context["selected_modes"]:
            if mode != "1d_sector":
                targets.append((mode, self.mode_output_path(context["save_dirs"], mode, out_stem)))
                continue

            if context.get("sector_save_each", True):
                for spec in context.get("sector_specs", []):
                    d = context.get("sector_save_dirs", {}).get(spec["key"])
                    if d is None:
                        continue
                    targets.append((f"1d_sector{spec['label']}", d / f"{out_stem}.dat"))

            if context.get("sector_save_combined", False):
                d = context.get("sector_combined_dir", None)
                if d is not None:
                    targets.append(("1d_sector_sum", d / f"{out_stem}.dat"))
        return targets

    def save_profile_table(self, out_path, x, i_abs, i_err, x_label, output_format="tsv"):
        # Origin-friendly text table: first row is column names, tab-separated.
        out_path = Path(out_path)
        x_arr = np.asarray(x, dtype=np.float64)
        i_arr = np.asarray(i_abs, dtype=np.float64)
        e_arr = np.asarray(i_err, dtype=np.float64)

        if output_format in ("cansas_xml", "nxcansas_h5") and str(x_label) != "Q_A^-1":
            raise ValueError(
                f"è¾“å‡ºæ ¼å¼ {output_format} ä»…æ”¯æŒ Q_A^-1 è½´æ•°æ®ï¼Œå½“å‰ä¸º {x_label}ã€‚"
            )

        if output_format == "cansas_xml" and write_cansas1d_xml is not None:
            xml_path = out_path.with_suffix(".xml")
            write_cansas1d_xml(xml_path, x_arr, i_arr, e_arr)
            return
        if output_format == "nxcansas_h5" and write_nxcansas_h5 is not None:
            h5_path = out_path.with_suffix(".h5")
            write_nxcansas_h5(h5_path, x_arr, i_arr, e_arr)
            return

        df = pd.DataFrame({
            x_label: x_arr,
            "I_abs_cm^-1": i_arr,
            "Error_cm^-1": e_arr,
        })
        df.replace([np.inf, -np.inf], np.nan, inplace=True)
        sep = "," if output_format == "csv" else "\t"
        suffix = ".csv" if output_format == "csv" else ".dat"
        final_path = out_path.with_suffix(suffix) if output_format == "csv" else out_path
        df.to_csv(
            final_path,
            sep=sep,
            index=False,
            encoding="utf-8-sig",
            na_rep="",
            float_format="%.10g",
        )

    def load_optional_array(self, path, name):
        if not path:
            return None
        p = Path(path)
        if p.suffix.lower() == ".npy":
            arr = np.load(path)
        else:
            arr = fabio.open(path).data
        if arr is None:
            raise ValueError(f"{name} æ–‡ä»¶æ— æ³•è¯»å–: {path}")
        return np.asarray(arr)

    def profile_health_issue(self, i_abs):
        arr = np.asarray(i_abs, dtype=np.float64)
        arr = arr[np.isfinite(arr)]
        if arr.size < 50:
            return None
        non_pos_frac = float(np.mean(arr <= 0))
        if non_pos_frac >= 0.98:
            return (
                f"ç§¯åˆ†ç»“æœå¼‚å¸¸ï¼šéæ­£å€¼æ¯”ä¾‹ {non_pos_frac*100:.1f}% "
                "(ç–‘ä¼¼è¿‡æ‰£èƒŒæ™¯æˆ–å½’ä¸€åŒ–è®¾ç½®é”™è¯¯)"
            )
        return None

    def build_reference_library(self, paths):
        refs = []
        for p in list(dict.fromkeys(paths or [])):
            try:
                img = fabio.open(p)
                data = np.asarray(img.data)
                exp, mon, trans = self.parse_header(p, header_dict=getattr(img, "header", {}))
                refs.append({
                    "path": str(p),
                    "shape": tuple(data.shape),
                    "exp": exp,
                    "mon": mon,
                    "trans": trans,
                    "mtime": Path(p).stat().st_mtime if Path(p).exists() else None,
                })
            except Exception:
                continue
        return refs

    def reference_score(self, sample_meta, ref_meta, kind="bg"):
        score = 0.0
        used = 0.0

        se, re = sample_meta.get("exp"), ref_meta.get("exp")
        sm, rm = sample_meta.get("mon"), ref_meta.get("mon")
        st, rt = sample_meta.get("trans"), ref_meta.get("trans")
        stime, rtime = sample_meta.get("mtime"), ref_meta.get("mtime")

        if se and re and se > 0 and re > 0:
            score += self.relative_diff(se, re) * 1.0
            used += 1.0
        if sm and rm and sm > 0 and rm > 0:
            score += self.relative_diff(sm, rm) * 0.8
            used += 0.8
        if kind == "bg" and st and rt and st > 0 and rt > 0:
            score += abs(st - rt) * 1.5
            used += 1.5
        if stime and rtime:
            dt_h = abs(stime - rtime) / 3600.0
            score += min(dt_h / 24.0, 3.0) * 0.5
            used += 0.5

        if used == 0:
            return 1e9
        return score / used

    def select_best_reference(self, sample_meta, refs, kind="bg"):
        if not refs:
            return None, None
        same_shape = [r for r in refs if r.get("shape") == sample_meta.get("shape")]
        pool = same_shape if same_shape else refs
        scored = []
        for r in pool:
            scored.append((self.reference_score(sample_meta, r, kind=kind), r))
        scored.sort(key=lambda x: x[0])
        return scored[0][1], scored[0][0]

    # =========================================================================
    # TAB 1: K-Factor Calibration
    # =========================================================================
    def init_tab1_k_calc(self):
        p = self.tab1
        left_panel = ttk.Frame(p, width=400)
        left_panel.pack(side="left", fill="y", padx=5, pady=5)

        # æµç¨‹æç¤º
        f_guide = ttk.LabelFrame(left_panel, text=self.tr("t1_guide_title"), style="Group.TLabelframe")
        self._register_i18n_widget(f_guide, "t1_guide_title")
        f_guide.pack(fill="x", pady=5)
        guide_text = self.tr("t1_guide_text")
        lbl_guide = ttk.Label(f_guide, text=guide_text, justify="left", style="Hint.TLabel")
        self._register_i18n_widget(lbl_guide, "t1_guide_text")
        lbl_guide.pack(fill="x", padx=4, pady=3)
        self.add_tooltip(lbl_guide, "tip_t1_guide")

        # 1. æ–‡ä»¶åŒº
        f_files = ttk.LabelFrame(left_panel, text=self.tr("t1_files_title"), style="Group.TLabelframe")
        self._register_i18n_widget(f_files, "t1_files_title")
        f_files.pack(fill="x", pady=5)
        self.add_hint(f_files, "hint_t1_files")
        
        self.t1_files = {
            "std": tk.StringVar(), "bg": self.global_vars["bg_path"],
            "dark": self.global_vars["dark_path"], "poni": self.global_vars["poni_path"]
        }

        # --- Standard type selector row ---
        self.t1_std_type = tk.StringVar(value="SRM3600")
        self.t1_water_temp = tk.DoubleVar(value=20.0)
        self.t1_std_ref_path = tk.StringVar()

        row_std_type = ttk.Frame(f_files); row_std_type.pack(fill="x", pady=1)
        lbl_std_type = ttk.Label(row_std_type, text=self.tr("lbl_t1_std_type"), width=15, anchor="e")
        lbl_std_type.pack(side="left")
        self._register_i18n_widget(lbl_std_type, "lbl_t1_std_type")
        std_options = [
            self.tr("opt_std_srm3600"),
            self.tr("opt_std_water"),
            self.tr("opt_std_lupolen"),
            self.tr("opt_std_custom"),
        ]
        self._t1_std_option_map = {
            self.tr("opt_std_srm3600"): "SRM3600",
            self.tr("opt_std_water"): "Water_20C",
            self.tr("opt_std_lupolen"): "Lupolen",
            self.tr("opt_std_custom"): "Custom",
        }
        self.t1_std_combo = ttk.Combobox(row_std_type, values=std_options, width=25, state="readonly")
        self.t1_std_combo.current(0)
        self.t1_std_combo.pack(side="left", padx=5)
        self.t1_std_combo.bind("<<ComboboxSelected>>", self._on_std_type_changed)

        # Water temperature row (hidden by default)
        self.t1_water_row = ttk.Frame(f_files)
        lbl_wt = ttk.Label(self.t1_water_row, text=self.tr("lbl_t1_water_temp"), width=15, anchor="e")
        lbl_wt.pack(side="left")
        self._register_i18n_widget(lbl_wt, "lbl_t1_water_temp")
        ttk.Entry(self.t1_water_row, textvariable=self.t1_water_temp, width=8).pack(side="left", padx=5)
        # Not packed initially â€” shown when Water is selected

        # Reference curve file row (hidden by default)
        self.t1_ref_row = self.add_file_row(f_files, self.tr("lbl_t1_std_ref_file"), self.t1_std_ref_path, "*.dat *.txt *.csv *.xml")
        self.t1_ref_row["frame"].pack_forget()  # hidden by default

        row_std = self.add_file_row(f_files, self.tr("lbl_t1_std_file"), self.t1_files["std"], "*.tif", self.on_load_std_t1)
        self.add_tooltip(row_std["entry"], "tip_t1_std_entry")
        self.add_tooltip(row_std["button"], "tip_t1_std_btn")

        row_bg = self.add_file_row(f_files, self.tr("lbl_t1_bg_file"), self.t1_files["bg"], "*.tif", self.on_load_bg_t1)
        self.add_tooltip(row_bg["entry"], "tip_t1_bg_entry")
        self.add_tooltip(row_bg["button"], "tip_t1_bg_btn")
        btn_bg_multi = ttk.Button(row_bg["frame"], text="+", width=3, command=self.select_multi_bg_t1)
        btn_bg_multi.pack(side="left", padx=(2, 0))
        self.add_tooltip(btn_bg_multi, "tip_t1_bg_multi")

        row_dark = self.add_file_row(f_files, self.tr("lbl_t1_dark_file"), self.t1_files["dark"], "*.tif")
        self.add_tooltip(row_dark["entry"], "tip_t1_dark_entry")
        self.add_tooltip(row_dark["button"], "tip_t1_dark_btn")

        row_poni = self.add_file_row(f_files, self.tr("lbl_t1_poni_file"), self.t1_files["poni"], "*.poni")
        self.add_tooltip(row_poni["entry"], "tip_t1_poni_entry")
        self.add_tooltip(row_poni["button"], "tip_t1_poni_btn")

        # 2. ç‰©ç†å‚æ•°
        f_phys = ttk.LabelFrame(left_panel, text=self.tr("t1_phys_title"), style="Group.TLabelframe")
        self._register_i18n_widget(f_phys, "t1_phys_title")
        f_phys.pack(fill="x", pady=5)
        self.add_hint(f_phys, "hint_t1_phys")
        f_phys_grid = ttk.Frame(f_phys)
        f_phys_grid.pack(fill="x")
        
        self.t1_params = {
            "std_exp": tk.DoubleVar(value=1.0), "std_i0": tk.DoubleVar(value=1.0),
            "std_t": tk.DoubleVar(value=1.0), "std_thk": tk.DoubleVar(value=1.0),
            "bg_exp": self.global_vars["bg_exp"], "bg_i0": self.global_vars["bg_i0"], "bg_t": self.global_vars["bg_t"]
        }
        
        headers = ["Time(s)", "I0(Mon)", "Trans(T)", "Thk(mm)"]
        for i, h in enumerate(headers):
            ttk.Label(f_phys_grid, text=h, style="Hint.TLabel").grid(row=0, column=i+1)
        
        ttk.Label(f_phys_grid, text="Std:", style="Bold.TLabel").grid(row=1, column=0, pady=2)
        e_std_exp = self.add_grid_entry(f_phys_grid, self.t1_params["std_exp"], 1, 1)
        e_std_i0 = self.add_grid_entry(f_phys_grid, self.t1_params["std_i0"], 1, 2)
        e_std_t = self.add_grid_entry(f_phys_grid, self.t1_params["std_t"], 1, 3)
        e_std_thk = self.add_grid_entry(f_phys_grid, self.t1_params["std_thk"], 1, 4)
        
        ttk.Label(f_phys_grid, text="BG:", style="Bold.TLabel").grid(row=2, column=0, pady=2)
        e_bg_exp = self.add_grid_entry(f_phys_grid, self.t1_params["bg_exp"], 2, 1)
        e_bg_i0 = self.add_grid_entry(f_phys_grid, self.t1_params["bg_i0"], 2, 2)
        e_bg_t = self.add_grid_entry(f_phys_grid, self.t1_params["bg_t"], 2, 3)
        ttk.Label(f_phys_grid, text="-").grid(row=2, column=4)

        norm_row = ttk.Frame(f_phys)
        norm_row.pack(fill="x", pady=(3, 0))
        lbl_i0_t1 = ttk.Label(norm_row, text=self.tr("lbl_i0_semantic"))
        lbl_i0_t1.pack(side="left")
        self._register_i18n_widget(lbl_i0_t1, "lbl_i0_semantic")
        cb_norm_t1 = ttk.Combobox(
            norm_row,
            textvariable=self.global_vars["monitor_mode"],
            width=11,
            state="readonly",
            values=MONITOR_NORM_MODES,
        )
        cb_norm_t1.pack(side="left", padx=(4, 6))
        lbl_norm_hint_t1 = ttk.Label(
            norm_row,
            text="rate: exp*I0*T | integrated: I0*T",
            style="Hint.TLabel",
        )
        lbl_norm_hint_t1.pack(side="left")
        cb_solid_t1 = ttk.Checkbutton(
            norm_row,
            text=self.tr("cb_solid_angle"),
            variable=self.global_vars["apply_solid_angle"],
        )
        cb_solid_t1.pack(side="left", padx=(8, 0))
        self._register_i18n_widget(cb_solid_t1, "cb_solid_angle")

        self.add_tooltip(e_std_exp, "tip_t1_std_exp")
        self.add_tooltip(e_std_i0, "tip_t1_std_i0")
        self.add_tooltip(e_std_t, "tip_t1_std_t")
        self.add_tooltip(e_std_thk, "tip_t1_std_thk")
        self.add_tooltip(e_bg_exp, "tip_t1_bg_exp")
        self.add_tooltip(e_bg_i0, "tip_t1_bg_i0")
        self.add_tooltip(e_bg_t, "tip_t1_bg_t")
        self.add_tooltip(cb_norm_t1, "tip_t1_norm_mode")
        self.add_tooltip(lbl_norm_hint_t1, "tip_t1_norm_hint")
        self.add_tooltip(cb_solid_t1, "tip_t1_solid_angle")

        # 3. æ“ä½œæŒ‰é’®
        btn_row = ttk.Frame(left_panel)
        btn_row.pack(fill="x", pady=10)
        btn_cal = ttk.Button(btn_row, text=self.tr("t1_run_btn"), command=self.run_calibration, style="Accent.TButton")
        self._register_i18n_widget(btn_cal, "t1_run_btn")
        btn_cal.pack(side="left", fill="x", expand=True, ipady=5)
        btn_hist = ttk.Button(btn_row, text=self.tr("t1_hist_btn"), command=self.open_k_history)
        self._register_i18n_widget(btn_hist, "t1_hist_btn")
        btn_hist.pack(side="left", padx=(6, 0))
        self.add_tooltip(btn_cal, "tip_t1_calibrate")
        self.add_tooltip(btn_hist, "tip_t1_history")

        # 4. æŠ¥å‘Š
        f_rep = ttk.LabelFrame(left_panel, text=self.tr("t1_report_title"), style="Group.TLabelframe")
        self._register_i18n_widget(f_rep, "t1_report_title")
        f_rep.pack(fill="both", expand=True, pady=5)
        self.txt_report = tk.Text(f_rep, font=("Consolas", 9), height=15, width=40)
        self.txt_report.pack(fill="both", expand=True)
        # Configure semantic highlight tags for report text
        self.txt_report.tag_configure("error", foreground="#dc2626")
        self.txt_report.tag_configure("success", foreground="#16a34a", font=("Consolas", 9, "bold"))
        self.txt_report.tag_configure("warning", foreground="#d97706")
        self._register_native_widget(self.txt_report)
        self.add_tooltip(self.txt_report, "tip_t1_report")

        # --- å³ä¾§å›¾å½¢ ---
        right_panel = ttk.Frame(p)
        right_panel.pack(side="right", fill="both", expand=True, padx=5, pady=5)
        lbl_plot_tip = ttk.Label(
            right_panel,
            text=self.tr("t1_plot_tip"),
            style="Hint.TLabel",
        )
        self._register_i18n_widget(lbl_plot_tip, "t1_plot_tip")
        lbl_plot_tip.pack(anchor="w", pady=(0, 2))
        self.fig1 = Figure(figsize=(6, 5), dpi=100)
        self.ax1 = self.fig1.add_subplot(111)
        self.canvas1 = FigureCanvasTkAgg(self.fig1, master=right_panel)
        self.canvas1.get_tk_widget().pack(fill="both", expand=True)
        self.toolbar1 = NavigationToolbar2Tk(self.canvas1, right_panel)
        self.toolbar1.update()
        self.add_tooltip(lbl_plot_tip, "tip_t1_plot")

    # =========================================================================
    # TAB 2: Batch Processing
    # =========================================================================
    def init_tab2_batch(self):
        p = self._make_scrollable_frame(self.tab2)
        
        self.t2_files = []
        self.t2_mu = tk.DoubleVar(value=20.2)
        self.t2_calc_mode = tk.StringVar(value="auto") 
        self.t2_fixed_thk = tk.DoubleVar(value=1.0)
        self.t2_ref_mode = tk.StringVar(value="fixed")
        self.t2_error_model = tk.StringVar(value="azimuthal")
        self.t2_apply_solid_angle = self.global_vars["apply_solid_angle"]
        self.t2_polarization = tk.DoubleVar(value=0.0)
        self.t2_output_root = tk.StringVar(value="")
        self.t2_mask_path = tk.StringVar()
        self.t2_flat_path = tk.StringVar()
        self.t2_resume_enabled = tk.BooleanVar(value=True)
        self.t2_overwrite = tk.BooleanVar(value=False)
        self.t2_workers = tk.IntVar(value=1)
        self.t2_strict_instrument = tk.BooleanVar(value=True)
        self.t2_instr_tol_pct = tk.DoubleVar(value=0.5)
        self.t2_alpha = tk.DoubleVar(value=1.0)
        self.t2_alpha_enabled = tk.BooleanVar(value=False)
        self.t2_output_format = tk.StringVar(value="tsv")
        self.t2_bg_candidates = []
        self.t2_dark_candidates = []
        self.t2_bg_lib_info = tk.StringVar(value=self.tr("var_bg_lib").format(n=0))
        self.t2_dark_lib_info = tk.StringVar(value=self.tr("var_dark_lib").format(n=0))
        
        self.t2_mode_full = tk.BooleanVar(value=True)
        self.t2_mode_sector = tk.BooleanVar(value=False)
        self.t2_mode_chi = tk.BooleanVar(value=False)
        self.t2_sec_min = tk.DoubleVar(value=-20)
        self.t2_sec_max = tk.DoubleVar(value=20)
        self.t2_sector_ranges_text = tk.StringVar(value="")
        self.t2_sector_save_each = tk.BooleanVar(value=True)
        self.t2_sector_save_combined = tk.BooleanVar(value=False)
        self.t2_rad_qmin = tk.DoubleVar(value=0.5)
        self.t2_rad_qmax = tk.DoubleVar(value=2.5)

        # æµç¨‹æç¤º
        f_guide = ttk.LabelFrame(p, text=self.tr("t2_guide_title"), style="Group.TLabelframe")
        self._register_i18n_widget(f_guide, "t2_guide_title")
        f_guide.pack(fill="x", padx=10, pady=(8, 3))
        guide = self.tr("t2_guide_text")
        lbl_guide = ttk.Label(f_guide, text=guide, justify="left", style="Hint.TLabel")
        self._register_i18n_widget(lbl_guide, "t2_guide_text")
        lbl_guide.pack(fill="x", padx=4, pady=3)
        self.add_tooltip(lbl_guide, "tip_t2_guide")

        # --- Settings ---
        top_frame = ttk.Frame(p)
        top_frame.pack(fill="x", padx=10, pady=5)
        
        # 1. Global
        c1 = ttk.LabelFrame(top_frame, text=self.tr("lf_t2_global"), style="Group.TLabelframe")
        c1.pack(side="left", fill="y", padx=5)
        self._register_i18n_widget(c1, "lf_t2_global")
        self.add_hint(c1, "hint_t2_global", wraplength=300)
        c1_grid = ttk.Frame(c1)
        c1_grid.pack(fill="x")
        lbl_k = ttk.Label(c1_grid, text=self.tr("lbl_t2_k_factor"))
        lbl_k.grid(row=0, column=0, sticky="e")
        self._register_i18n_widget(lbl_k, "lbl_t2_k_factor")
        e_k = ttk.Entry(c1_grid, textvariable=self.global_vars["k_factor"], width=10)
        e_k.grid(row=0, column=1, padx=5)
        lbl_bgf = ttk.Label(c1_grid, text=self.tr("lbl_t2_bg_file"))
        lbl_bgf.grid(row=1, column=0, sticky="e")
        self._register_i18n_widget(lbl_bgf, "lbl_t2_bg_file")
        lbl_bg = ttk.Label(c1_grid, textvariable=self.global_vars["bg_path"], width=20, style="Hint.TLabel")
        lbl_bg.grid(row=1, column=1, padx=5)
        lbl_i0 = ttk.Label(c1_grid, text=self.tr("lbl_t2_i0_semantic"))
        lbl_i0.grid(row=2, column=0, sticky="e")
        self._register_i18n_widget(lbl_i0, "lbl_t2_i0_semantic")
        cb_norm_t2 = ttk.Combobox(
            c1_grid,
            textvariable=self.global_vars["monitor_mode"],
            width=11,
            state="readonly",
            values=MONITOR_NORM_MODES,
        )
        cb_norm_t2.grid(row=2, column=1, padx=5, pady=(2, 0), sticky="w")
        lbl_norm_hint_t2 = ttk.Label(c1_grid, text="rate: exp*I0*T / integrated: I0*T", style="Hint.TLabel")
        lbl_norm_hint_t2.grid(row=3, column=0, columnspan=2, sticky="w", padx=2)
        self.add_tooltip(e_k, "tip_t2_k_factor")
        self.add_tooltip(lbl_bg, "tip_t2_bg_label")
        self.add_tooltip(cb_norm_t2, "tip_t2_norm_mode")
        self.add_tooltip(lbl_norm_hint_t2, "tip_t2_norm_hint")

        # 2. Thickness
        c2 = ttk.LabelFrame(top_frame, text=self.tr("lf_t2_thickness"), style="Group.TLabelframe")
        c2.pack(side="left", fill="y", padx=5)
        self._register_i18n_widget(c2, "lf_t2_thickness")
        self.add_hint(c2, "hint_t2_thickness", wraplength=320)
        
        r1 = ttk.Frame(c2); r1.pack(anchor="w")
        rb_auto = ttk.Radiobutton(r1, text=self.tr("rb_t2_auto_thk"), variable=self.t2_calc_mode, value="auto")
        rb_auto.pack(side="left")
        self._register_i18n_widget(rb_auto, "rb_t2_auto_thk")
        lbl_mu = ttk.Label(r1, text=self.tr("lbl_t2_mu"))
        lbl_mu.pack(side="left")
        self._register_i18n_widget(lbl_mu, "lbl_t2_mu")
        e_mu = ttk.Entry(r1, textvariable=self.t2_mu, width=6)
        e_mu.pack(side="left")
        btn_est = ttk.Button(r1, text=self.tr("btn_t2_mu_est"), command=self.open_mu_tool, width=8)
        btn_est.pack(side="left", padx=2)
        self._register_i18n_widget(btn_est, "btn_t2_mu_est")
        
        r2 = ttk.Frame(c2); r2.pack(anchor="w")
        rb_fix = ttk.Radiobutton(r2, text=self.tr("rb_t2_fix_thk"), variable=self.t2_calc_mode, value="fixed")
        rb_fix.pack(side="left")
        self._register_i18n_widget(rb_fix, "rb_t2_fix_thk")
        e_fix = ttk.Entry(r2, textvariable=self.t2_fixed_thk, width=6)
        e_fix.pack(side="left")

        self.add_tooltip(rb_auto, "tip_t2_auto_thk")
        self.add_tooltip(e_mu, "tip_t2_mu")
        self.add_tooltip(btn_est, "tip_t2_mu_est")
        self.add_tooltip(rb_fix, "tip_t2_fix_thk")
        self.add_tooltip(e_fix, "tip_t2_fix_thk_val")
        self.add_tooltip(lbl_mu, "tip_t2_mu_label")
        
        # 3. Integration
        c3 = ttk.LabelFrame(top_frame, text=self.tr("lf_t2_integration"), style="Group.TLabelframe")
        c3.pack(side="left", fill="y", padx=5)
        self._register_i18n_widget(c3, "lf_t2_integration")
        self.add_hint(c3, "hint_t2_integration", wraplength=320)
        c3_grid = ttk.Frame(c3)
        c3_grid.pack(fill="x")

        cb_full = ttk.Checkbutton(c3_grid, text=self.tr("cb_t2_full_ring"), variable=self.t2_mode_full)
        cb_full.grid(row=0, column=0, sticky="w")
        self._register_i18n_widget(cb_full, "cb_t2_full_ring")
        f_sec = ttk.Frame(c3_grid); f_sec.grid(row=1, column=0, sticky="w")
        cb_sec = ttk.Checkbutton(f_sec, text=self.tr("cb_t2_sector"), variable=self.t2_mode_sector)
        cb_sec.pack(side="left")
        self._register_i18n_widget(cb_sec, "cb_t2_sector")
        ttk.Label(f_sec, text=" [").pack(side="left")
        e_sec_min = ttk.Entry(f_sec, textvariable=self.t2_sec_min, width=4)
        e_sec_min.pack(side="left")
        ttk.Label(f_sec, text=",").pack(side="left")
        e_sec_max = ttk.Entry(f_sec, textvariable=self.t2_sec_max, width=4)
        e_sec_max.pack(side="left")
        ttk.Label(f_sec, text="] deg").pack(side="left")
        btn_sec_preview = ttk.Button(f_sec, text=self.tr("btn_t2_iq_preview"), width=8, command=self.preview_iq_window_t2)
        btn_sec_preview.pack(side="left", padx=(4, 0))
        self._register_i18n_widget(btn_sec_preview, "btn_t2_iq_preview")

        f_sec_multi = ttk.Frame(c3_grid); f_sec_multi.grid(row=2, column=0, sticky="w")
        lbl_msec = ttk.Label(f_sec_multi, text=self.tr("lbl_t2_multi_sector"))
        lbl_msec.pack(side="left")
        self._register_i18n_widget(lbl_msec, "lbl_t2_multi_sector")
        e_sec_multi = ttk.Entry(f_sec_multi, textvariable=self.t2_sector_ranges_text, width=26)
        e_sec_multi.pack(side="left")
        lbl_sec_ex = ttk.Label(f_sec_multi, text=self.tr("lbl_t2_sector_example"))
        lbl_sec_ex.pack(side="left")
        self._register_i18n_widget(lbl_sec_ex, "lbl_t2_sector_example")
        cb_sec_each = ttk.Checkbutton(f_sec_multi, text=self.tr("cb_t2_sec_save_each"), variable=self.t2_sector_save_each)
        cb_sec_each.pack(side="left", padx=(6, 0))
        self._register_i18n_widget(cb_sec_each, "cb_t2_sec_save_each")
        cb_sec_sum = ttk.Checkbutton(f_sec_multi, text=self.tr("cb_t2_sec_save_sum"), variable=self.t2_sector_save_combined)
        cb_sec_sum.pack(side="left", padx=(4, 0))
        self._register_i18n_widget(cb_sec_sum, "cb_t2_sec_save_sum")

        f_tex = ttk.Frame(c3_grid); f_tex.grid(row=3, column=0, sticky="w")
        cb_tex = ttk.Checkbutton(f_tex, text=self.tr("cb_t2_texture"), variable=self.t2_mode_chi)
        cb_tex.pack(side="left")
        self._register_i18n_widget(cb_tex, "cb_t2_texture")
        ttk.Label(f_tex, text=" Q[").pack(side="left")
        e_qmin = ttk.Entry(f_tex, textvariable=self.t2_rad_qmin, width=4)
        e_qmin.pack(side="left")
        ttk.Label(f_tex, text=",").pack(side="left")
        e_qmax = ttk.Entry(f_tex, textvariable=self.t2_rad_qmax, width=4)
        e_qmax.pack(side="left")
        ttk.Label(f_tex, text="] Aâ»Â¹").pack(side="left")
        btn_chi_preview = ttk.Button(f_tex, text=self.tr("btn_t2_chi_preview"), width=10, command=self.preview_ichi_window_t2)
        btn_chi_preview.pack(side="left", padx=(4, 0))
        self._register_i18n_widget(btn_chi_preview, "btn_t2_chi_preview")

        self.add_tooltip(cb_full, "tip_t2_full")
        self.add_tooltip(cb_sec, "tip_t2_sector")
        self.add_tooltip(e_sec_min, "tip_t2_sec_min")
        self.add_tooltip(e_sec_max, "tip_t2_sec_max")
        self.add_tooltip(btn_sec_preview, "tip_t2_sec_preview")
        self.add_tooltip(e_sec_multi, "tip_t2_sec_multi")
        self.add_tooltip(cb_sec_each, "tip_t2_sec_each")
        self.add_tooltip(cb_sec_sum, "tip_t2_sec_sum")
        self.add_tooltip(cb_tex, "tip_t2_texture")
        self.add_tooltip(e_qmin, "tip_t2_qmin")
        self.add_tooltip(e_qmax, "tip_t2_qmax")
        self.add_tooltip(btn_chi_preview, "tip_t2_chi_preview")

        # 4. ä¿®æ­£ä¸æ‰§è¡Œç­–ç•¥
        adv_frame = ttk.Frame(p)
        adv_frame.pack(fill="x", padx=10, pady=(2, 4))

        c4 = ttk.LabelFrame(adv_frame, text=self.tr("lf_t2_correction"), style="Group.TLabelframe")
        c4.pack(side="left", fill="x", expand=True, padx=5)
        self._register_i18n_widget(c4, "lf_t2_correction")
        self.add_hint(c4, "hint_t2_correction", wraplength=480)

        c4_row1 = ttk.Frame(c4); c4_row1.pack(fill="x", pady=2)
        cb_solid = ttk.Checkbutton(c4_row1, text=self.tr("cb_t2_solid_angle"), variable=self.t2_apply_solid_angle)
        cb_solid.pack(side="left")
        self._register_i18n_widget(cb_solid, "cb_t2_solid_angle")
        lbl_err = ttk.Label(c4_row1, text=self.tr("lbl_t2_error_model"))
        lbl_err.pack(side="left", padx=(8, 2))
        self._register_i18n_widget(lbl_err, "lbl_t2_error_model")
        cb_err = ttk.Combobox(c4_row1, textvariable=self.t2_error_model, width=10, state="readonly")
        cb_err["values"] = ("azimuthal", "poisson", "none")
        cb_err.pack(side="left")
        ttk.Label(c4_row1, text="Polarization(-1~1):").pack(side="left", padx=(8, 2))
        e_pol = ttk.Entry(c4_row1, textvariable=self.t2_polarization, width=6)
        e_pol.pack(side="left")

        row_mask = self.add_file_row(c4, self.tr("lbl_t2_mask"), self.t2_mask_path, "*.tif *.tiff *.edf *.npy")
        row_flat = self.add_file_row(c4, self.tr("lbl_t2_flat"), self.t2_flat_path, "*.tif *.tiff *.edf *.npy")

        self.add_tooltip(cb_solid, "tip_t2_solid_angle")
        self.add_tooltip(cb_err, "tip_t2_error_model")
        self.add_tooltip(e_pol, "tip_t2_polarization")
        self.add_tooltip(row_mask["entry"], "tip_t2_mask")
        self.add_tooltip(row_flat["entry"], "tip_t2_flat")

        c5 = ttk.LabelFrame(adv_frame, text=self.tr("lf_t2_execution"), style="Group.TLabelframe")
        c5.pack(side="left", fill="x", expand=True, padx=5)
        self._register_i18n_widget(c5, "lf_t2_execution")
        self.add_hint(c5, "hint_t2_execution", wraplength=480)

        row_ref = ttk.Frame(c5); row_ref.pack(fill="x")
        rb_ref_fixed = ttk.Radiobutton(row_ref, text=self.tr("rb_t2_ref_fixed"), variable=self.t2_ref_mode, value="fixed")
        rb_ref_fixed.pack(side="left")
        self._register_i18n_widget(rb_ref_fixed, "rb_t2_ref_fixed")
        rb_ref_auto = ttk.Radiobutton(row_ref, text=self.tr("rb_t2_ref_auto"), variable=self.t2_ref_mode, value="auto")
        rb_ref_auto.pack(side="left", padx=(8, 0))
        self._register_i18n_widget(rb_ref_auto, "rb_t2_ref_auto")

        row_lib = ttk.Frame(c5); row_lib.pack(fill="x", pady=2)
        btn_bg_lib = ttk.Button(row_lib, text=self.tr("btn_t2_bg_lib"), command=self.add_bg_library_files)
        btn_bg_lib.pack(side="left")
        self._register_i18n_widget(btn_bg_lib, "btn_t2_bg_lib")
        btn_dark_lib = ttk.Button(row_lib, text=self.tr("btn_t2_dark_lib"), command=self.add_dark_library_files)
        btn_dark_lib.pack(side="left", padx=(5, 0))
        self._register_i18n_widget(btn_dark_lib, "btn_t2_dark_lib")
        btn_clear_lib = ttk.Button(row_lib, text=self.tr("btn_t2_clear_lib"), command=self.clear_reference_libraries)
        btn_clear_lib.pack(side="left", padx=(5, 0))
        self._register_i18n_widget(btn_clear_lib, "btn_t2_clear_lib")

        row_lib_info = ttk.Frame(c5); row_lib_info.pack(fill="x")
        ttk.Label(row_lib_info, textvariable=self.t2_bg_lib_info, style="Hint.TLabel").pack(side="left")
        ttk.Label(row_lib_info, textvariable=self.t2_dark_lib_info, style="Hint.TLabel").pack(side="left", padx=(10, 0))

        row_exec = ttk.Frame(c5); row_exec.pack(fill="x", pady=2)
        lbl_wk = ttk.Label(row_exec, text=self.tr("lbl_t2_workers"))
        lbl_wk.pack(side="left")
        self._register_i18n_widget(lbl_wk, "lbl_t2_workers")
        e_workers = ttk.Entry(row_exec, textvariable=self.t2_workers, width=4)
        e_workers.pack(side="left")
        cb_resume = ttk.Checkbutton(row_exec, text=self.tr("cb_t2_resume"), variable=self.t2_resume_enabled)
        cb_resume.pack(side="left", padx=(8, 0))
        self._register_i18n_widget(cb_resume, "cb_t2_resume")
        cb_overwrite = ttk.Checkbutton(row_exec, text=self.tr("cb_t2_overwrite"), variable=self.t2_overwrite)
        cb_overwrite.pack(side="left", padx=(8, 0))
        self._register_i18n_widget(cb_overwrite, "cb_t2_overwrite")

        row_strict = ttk.Frame(c5); row_strict.pack(fill="x")
        cb_strict = ttk.Checkbutton(row_strict, text=self.tr("cb_t2_strict"), variable=self.t2_strict_instrument)
        cb_strict.pack(side="left")
        self._register_i18n_widget(cb_strict, "cb_t2_strict")
        lbl_tol = ttk.Label(row_strict, text=self.tr("lbl_t2_tolerance"))
        lbl_tol.pack(side="left", padx=(8, 2))
        self._register_i18n_widget(lbl_tol, "lbl_t2_tolerance")
        e_tol = ttk.Entry(row_strict, textvariable=self.t2_instr_tol_pct, width=5)
        e_tol.pack(side="left")

        self.add_tooltip(rb_ref_fixed, "tip_t2_ref_fixed")
        self.add_tooltip(rb_ref_auto, "tip_t2_ref_auto")
        self.add_tooltip(btn_bg_lib, "tip_t2_bg_lib")
        self.add_tooltip(btn_dark_lib, "tip_t2_dark_lib")
        self.add_tooltip(btn_clear_lib, "tip_t2_clear_lib")
        self.add_tooltip(e_workers, "tip_t2_workers")
        self.add_tooltip(cb_resume, "tip_t2_resume")
        self.add_tooltip(cb_overwrite, "tip_t2_overwrite")
        self.add_tooltip(cb_strict, "tip_t2_strict")
        self.add_tooltip(e_tol, "tip_t2_tolerance")

        # --- Î±-scaling and output format row ---
        row_alpha_fmt = ttk.Frame(c5); row_alpha_fmt.pack(fill="x", pady=(4, 0))
        cb_alpha = ttk.Checkbutton(row_alpha_fmt, text=self.tr("cb_t2_buffer_enable"), variable=self.t2_alpha_enabled)
        cb_alpha.pack(side="left")
        self._register_i18n_widget(cb_alpha, "cb_t2_buffer_enable")
        lbl_a2 = ttk.Label(row_alpha_fmt, text=self.tr("lbl_t2_alpha"))
        lbl_a2.pack(side="left", padx=(8, 2))
        self._register_i18n_widget(lbl_a2, "lbl_t2_alpha")
        ttk.Entry(row_alpha_fmt, textvariable=self.t2_alpha, width=6).pack(side="left")

        row_fmt2 = ttk.Frame(c5); row_fmt2.pack(fill="x", pady=(2, 0))
        lbl_ofmt2 = ttk.Label(row_fmt2, text=self.tr("lbl_output_format"))
        lbl_ofmt2.pack(side="left")
        self._register_i18n_widget(lbl_ofmt2, "lbl_output_format")
        self.t2_fmt_combo = ttk.Combobox(
            row_fmt2,
            textvariable=self.t2_output_format,
            values=["tsv", "csv", "cansas_xml", "nxcansas_h5"],
            width=18,
            state="readonly",
        )
        self.t2_fmt_combo.current(0)
        self.t2_fmt_combo.pack(side="left", padx=5)

        # --- List ---
        mid_frame = ttk.LabelFrame(p, text=self.tr("t2_mid_title"), style="Group.TLabelframe")
        self._register_i18n_widget(mid_frame, "t2_mid_title")
        mid_frame.pack(fill="both", expand=True, padx=10, pady=5)
        self.add_hint(mid_frame, "hint_t2_queue")
        
        tb = ttk.Frame(mid_frame); tb.pack(fill="x")
        btn_add = ttk.Button(tb, text=self.tr("t2_add_btn"), command=self.add_batch_files)
        self._register_i18n_widget(btn_add, "t2_add_btn")
        btn_add.pack(side="left")
        btn_clear = ttk.Button(tb, text=self.tr("t2_clear_btn"), command=self.clear_batch_files)
        self._register_i18n_widget(btn_clear, "t2_clear_btn")
        btn_clear.pack(side="left")
        btn_check = ttk.Button(tb, text=self.tr("t2_check_btn"), command=self.dry_run, style="Accent.TButton")
        self._register_i18n_widget(btn_check, "t2_check_btn")
        btn_check.pack(side="right", padx=10)
        self.add_tooltip(btn_add, "tip_t2_add")
        self.add_tooltip(btn_clear, "tip_t2_clear")
        self.add_tooltip(btn_check, "tip_t2_check")

        self.t2_queue_info = tk.StringVar(value=self._fmt_queue_info(0, 0))
        lbl_queue = ttk.Label(mid_frame, textvariable=self.t2_queue_info, style="Hint.TLabel")
        lbl_queue.pack(anchor="w", padx=5, pady=(2, 0))

        self.lb_batch = tk.Listbox(mid_frame, height=8)
        self.lb_batch.pack(fill="both", expand=True, padx=5, pady=5)
        self._register_native_widget(self.lb_batch)
        self.add_tooltip(self.lb_batch, "tip_t2_listbox")

        # --- Action ---
        bot_frame = ttk.Frame(p)
        bot_frame.pack(fill="x", padx=10, pady=10)
        btn_run = ttk.Button(bot_frame, text=self.tr("t2_run_btn"), command=self.run_batch, style="Accent.TButton")
        self._register_i18n_widget(btn_run, "t2_run_btn")
        btn_run.pack(fill="x", ipady=5)
        self.prog_bar = ttk.Progressbar(bot_frame, mode="determinate")
        self.prog_bar.pack(fill="x", pady=5)
        row_out_dir = self.add_dir_row(bot_frame, self.tr("lbl_t2_outdir"), self.t2_output_root)
        self.add_tooltip(btn_run, "tip_t2_run")
        self.add_tooltip(self.prog_bar, "tip_t2_progress")
        self.add_tooltip(row_out_dir["entry"], "tip_t2_outdir")

        self.t2_out_hint_var = tk.StringVar(value=f"{self.tr('out_auto_prefix')}: processed_robust_1d_full")
        lbl_out = ttk.Label(bot_frame, textvariable=self.t2_out_hint_var, style="Hint.TLabel")
        lbl_out.pack(anchor="w")
        self.add_tooltip(lbl_out, "tip_t2_out_label")

        self.t2_mode_full.trace_add("write", lambda *_: self.refresh_queue_status())
        self.t2_mode_sector.trace_add("write", lambda *_: self.refresh_queue_status())
        self.t2_mode_chi.trace_add("write", lambda *_: self.refresh_queue_status())
        self.t2_sector_ranges_text.trace_add("write", lambda *_: self.refresh_queue_status())
        self.t2_sector_save_each.trace_add("write", lambda *_: self.refresh_queue_status())
        self.t2_sector_save_combined.trace_add("write", lambda *_: self.refresh_queue_status())
        self.t2_output_root.trace_add("write", lambda *_: self.refresh_queue_status())
        self.refresh_queue_status()

    # =========================================================================
    # TAB 3: External 1D -> Absolute Intensity
    # =========================================================================
    def init_tab3_external_1d(self):
        p = self._make_scrollable_frame(self.tab3)

        self.t3_files = []
        self.t3_pipeline_mode = tk.StringVar(value="scaled")
        self.t3_corr_mode = tk.StringVar(value="k_over_d")
        self.t3_fixed_thk = tk.DoubleVar(value=1.0)
        self.t3_x_mode = tk.StringVar(value="auto")
        self.t3_meta_csv_path = tk.StringVar()
        self.t3_bg1d_path = tk.StringVar()
        self.t3_dark1d_path = tk.StringVar()
        self.t3_output_root = tk.StringVar(value="")
        self.t3_use_meta_thk = tk.BooleanVar(value=True)
        self.t3_sample_exp = tk.DoubleVar(value=1.0)
        self.t3_sample_i0 = tk.DoubleVar(value=1.0)
        self.t3_sample_t = tk.DoubleVar(value=1.0)
        self.t3_bg_exp = tk.DoubleVar(value=1.0)
        self.t3_bg_i0 = tk.DoubleVar(value=1.0)
        self.t3_bg_t = tk.DoubleVar(value=1.0)
        self.t3_sync_bg_from_global = tk.BooleanVar(value=True)
        self.t3_bg_exp.set(self.global_vars["bg_exp"].get())
        self.t3_bg_i0.set(self.global_vars["bg_i0"].get())
        self.t3_bg_t.set(self.global_vars["bg_t"].get())
        self.t3_resume_enabled = tk.BooleanVar(value=True)
        self.t3_overwrite = tk.BooleanVar(value=False)
        self.t3_queue_info = tk.StringVar(value=self._fmt_queue_info(0, 0))
        self.t3_out_hint = tk.StringVar(value=f"{self.tr('out_auto_prefix')}: processed_external_1d_abs")

        f_guide = ttk.LabelFrame(p, text=self.tr("t3_guide_title"), style="Group.TLabelframe")
        self._register_i18n_widget(f_guide, "t3_guide_title")
        f_guide.pack(fill="x", padx=10, pady=(8, 3))
        guide = self.tr("t3_guide_text")
        lbl_guide = ttk.Label(f_guide, text=guide, justify="left", style="Hint.TLabel")
        self._register_i18n_widget(lbl_guide, "t3_guide_text")
        lbl_guide.pack(fill="x", padx=4, pady=3)
        self.add_tooltip(lbl_guide, "tip_t3_guide")

        top = ttk.Frame(p)
        top.pack(fill="x", padx=10, pady=5)

        c1 = ttk.LabelFrame(top, text=self.tr("lf_t3_global"), style="Group.TLabelframe")
        c1.pack(side="left", fill="y", padx=5)
        self._register_i18n_widget(c1, "lf_t3_global")
        self.add_hint(c1, "hint_t3_global", wraplength=380)

        c1_grid = ttk.Frame(c1)
        c1_grid.pack(fill="x")
        lbl_k3 = ttk.Label(c1_grid, text=self.tr("lbl_t3_k_factor"))
        lbl_k3.grid(row=0, column=0, sticky="e")
        self._register_i18n_widget(lbl_k3, "lbl_t3_k_factor")
        e_k = ttk.Entry(c1_grid, textvariable=self.global_vars["k_factor"], width=10)
        e_k.grid(row=0, column=1, padx=5, pady=1, sticky="w")
        lbl_pl = ttk.Label(c1_grid, text=self.tr("lbl_t3_pipeline"))
        lbl_pl.grid(row=1, column=0, sticky="e")
        self._register_i18n_widget(lbl_pl, "lbl_t3_pipeline")
        rb_scaled = ttk.Radiobutton(
            c1_grid, text=self.tr("rb_t3_scaled"), variable=self.t3_pipeline_mode, value="scaled"
        )
        rb_scaled.grid(row=1, column=1, sticky="w")
        self._register_i18n_widget(rb_scaled, "rb_t3_scaled")
        rb_raw = ttk.Radiobutton(
            c1_grid, text=self.tr("rb_t3_raw"), variable=self.t3_pipeline_mode, value="raw"
        )
        rb_raw.grid(row=2, column=1, sticky="w")
        self._register_i18n_widget(rb_raw, "rb_t3_raw")

        rb_kd = ttk.Radiobutton(
            c1_grid,
            text=self.tr("rb_t3_kd_formula"),
            variable=self.t3_corr_mode,
            value="k_over_d",
        )
        rb_kd.grid(row=3, column=0, columnspan=2, sticky="w", pady=(4, 1))
        self._register_i18n_widget(rb_kd, "rb_t3_kd_formula")
        lbl_thk = ttk.Label(c1_grid, text=self.tr("lbl_t3_thk"))
        lbl_thk.grid(row=4, column=0, sticky="e")
        self._register_i18n_widget(lbl_thk, "lbl_t3_thk")
        e_thk = ttk.Entry(c1_grid, textvariable=self.t3_fixed_thk, width=8)
        e_thk.grid(row=4, column=1, padx=5, pady=1, sticky="w")

        rb_k = ttk.Radiobutton(
            c1_grid,
            text=self.tr("rb_t3_k_formula"),
            variable=self.t3_corr_mode,
            value="k_only",
        )
        rb_k.grid(row=5, column=0, columnspan=2, sticky="w", pady=(4, 1))
        self._register_i18n_widget(rb_k, "rb_t3_k_formula")

        lbl_xt = ttk.Label(c1_grid, text=self.tr("lbl_t3_x_type"))
        lbl_xt.grid(row=6, column=0, sticky="e")
        self._register_i18n_widget(lbl_xt, "lbl_t3_x_type")
        cb_x = ttk.Combobox(c1_grid, textvariable=self.t3_x_mode, width=12, state="readonly")
        cb_x["values"] = ("auto", "q_A^-1", "chi_deg")
        cb_x.grid(row=6, column=1, padx=5, pady=1, sticky="w")
        lbl_i0_3 = ttk.Label(c1_grid, text=self.tr("lbl_t3_i0_semantic"), style="Hint.TLabel")
        lbl_i0_3.grid(row=7, column=0, sticky="e")
        self._register_i18n_widget(lbl_i0_3, "lbl_t3_i0_semantic")
        ttk.Label(c1_grid, textvariable=self.global_vars["monitor_mode"], style="Hint.TLabel").grid(row=7, column=1, sticky="w")

        self.add_tooltip(e_k, "tip_t3_k")
        self.add_tooltip(rb_scaled, "tip_t3_scaled")
        self.add_tooltip(rb_raw, "tip_t3_raw")
        self.add_tooltip(rb_kd, "tip_t3_kd")
        self.add_tooltip(e_thk, "tip_t3_thk")
        self.add_tooltip(rb_k, "tip_t3_k_only")
        self.add_tooltip(cb_x, "tip_t3_x_mode")

        c2 = ttk.LabelFrame(top, text=self.tr("lf_t3_execution"), style="Group.TLabelframe")
        c2.pack(side="left", fill="y", padx=5)
        self._register_i18n_widget(c2, "lf_t3_execution")
        self.add_hint(c2, "hint_t3_execution", wraplength=320)
        row_exec = ttk.Frame(c2)
        row_exec.pack(fill="x")
        cb_resume = ttk.Checkbutton(c2, text=self.tr("cb_t3_resume"), variable=self.t3_resume_enabled)
        cb_resume.pack(anchor="w")
        self._register_i18n_widget(cb_resume, "cb_t3_resume")
        cb_overwrite = ttk.Checkbutton(c2, text=self.tr("cb_t3_overwrite"), variable=self.t3_overwrite)
        cb_overwrite.pack(anchor="w")
        self._register_i18n_widget(cb_overwrite, "cb_t3_overwrite")
        lbl_fmt = ttk.Label(
            row_exec,
            text=self.tr("lbl_t3_formats"),
            style="Hint.TLabel",
            wraplength=320,
            justify="left",
        )
        lbl_fmt.pack(anchor="w")
        self._register_i18n_widget(lbl_fmt, "lbl_t3_formats")
        self.add_tooltip(cb_resume, "tip_t3_resume")
        self.add_tooltip(cb_overwrite, "tip_t3_overwrite")

        c3 = ttk.LabelFrame(top, text=self.tr("lf_t3_raw_params"), style="Group.TLabelframe")
        c3.pack(side="left", fill="y", padx=5)
        self._register_i18n_widget(c3, "lf_t3_raw_params")
        self.add_hint(c3, "hint_t3_raw", wraplength=420)

        row_meta = self.add_file_row(c3, "Metadata CSV:", self.t3_meta_csv_path, "*.csv")
        row_bg = self.add_file_row(c3, self.tr("lbl_t3_bg1d_file"), self.t3_bg1d_path, "*.dat *.txt *.chi *.csv")
        row_dark = self.add_file_row(c3, self.tr("lbl_t3_dark1d_file"), self.t3_dark1d_path, "*.dat *.txt *.chi *.csv")

        row_meta_ops = ttk.Frame(c3)
        row_meta_ops.pack(fill="x", pady=(1, 1))
        btn_meta_from_batch = ttk.Button(
            row_meta_ops,
            text=self.tr("btn_t3_meta_from_batch"),
            command=self.t3_make_meta_from_batch_report,
        )
        btn_meta_from_batch.pack(side="left", padx=(3, 0))
        self._register_i18n_widget(btn_meta_from_batch, "btn_t3_meta_from_batch")

        self.add_tooltip(row_meta["entry"], "tip_t3_meta")
        self.add_tooltip(row_bg["entry"], "tip_t3_bg1d")
        self.add_tooltip(row_dark["entry"], "tip_t3_dark1d")
        self.add_tooltip(btn_meta_from_batch, "tip_t3_meta_from_batch")

        cb_meta_thk = ttk.Checkbutton(c3, text=self.tr("cb_t3_meta_thk"), variable=self.t3_use_meta_thk)
        cb_meta_thk.pack(anchor="w", padx=3, pady=(2, 1))
        self._register_i18n_widget(cb_meta_thk, "cb_t3_meta_thk")
        self.add_tooltip(cb_meta_thk, "tip_t3_meta_thk")
        cb_sync_bg = ttk.Checkbutton(
            c3,
            text=self.tr("cb_t3_sync_bg"),
            variable=self.t3_sync_bg_from_global,
            command=self.on_t3_sync_bg_toggle,
        )
        cb_sync_bg.pack(anchor="w", padx=3, pady=(0, 1))
        self._register_i18n_widget(cb_sync_bg, "cb_t3_sync_bg")
        self.add_tooltip(cb_sync_bg, "tip_t3_sync_bg")

        f_sample = ttk.Frame(c3)
        f_sample.pack(fill="x", pady=(2, 1))
        lbl_sp = ttk.Label(f_sample, text=self.tr("lbl_t3_sample_params"), style="Hint.TLabel")
        lbl_sp.grid(row=0, column=0, columnspan=6, sticky="w")
        self._register_i18n_widget(lbl_sp, "lbl_t3_sample_params")
        ttk.Label(f_sample, text="exp").grid(row=1, column=0, sticky="e")
        ttk.Entry(f_sample, textvariable=self.t3_sample_exp, width=7).grid(row=1, column=1, padx=2)
        ttk.Label(f_sample, text="i0").grid(row=1, column=2, sticky="e")
        ttk.Entry(f_sample, textvariable=self.t3_sample_i0, width=7).grid(row=1, column=3, padx=2)
        ttk.Label(f_sample, text="T").grid(row=1, column=4, sticky="e")
        ttk.Entry(f_sample, textvariable=self.t3_sample_t, width=7).grid(row=1, column=5, padx=2)

        f_bg = ttk.Frame(c3)
        f_bg.pack(fill="x", pady=(2, 1))
        lbl_bp = ttk.Label(f_bg, text=self.tr("lbl_t3_bg_params"), style="Hint.TLabel")
        lbl_bp.grid(row=0, column=0, columnspan=6, sticky="w")
        self._register_i18n_widget(lbl_bp, "lbl_t3_bg_params")
        ttk.Label(f_bg, text="exp").grid(row=1, column=0, sticky="e")
        self.t3_bg_entry_exp = ttk.Entry(f_bg, textvariable=self.t3_bg_exp, width=7)
        self.t3_bg_entry_exp.grid(row=1, column=1, padx=2)
        ttk.Label(f_bg, text="i0").grid(row=1, column=2, sticky="e")
        self.t3_bg_entry_i0 = ttk.Entry(f_bg, textvariable=self.t3_bg_i0, width=7)
        self.t3_bg_entry_i0.grid(row=1, column=3, padx=2)
        ttk.Label(f_bg, text="T").grid(row=1, column=4, sticky="e")
        self.t3_bg_entry_t = ttk.Entry(f_bg, textvariable=self.t3_bg_t, width=7)
        self.t3_bg_entry_t.grid(row=1, column=5, padx=2)

        # ---- Buffer/Solvent subtraction panel ----
        self.t3_buffer_enabled = tk.BooleanVar(value=False)
        self.t3_buffer_path = tk.StringVar()
        self.t3_alpha = tk.DoubleVar(value=1.0)
        self.t3_buffer_status = tk.StringVar(value=self.tr("lbl_t3_buffer_status"))

        buf_frame = ttk.LabelFrame(top, text=self.tr("lf_t3_buffer"), style="Group.TLabelframe")
        buf_frame.pack(side="left", fill="y", padx=5)
        self._register_i18n_widget(buf_frame, "lf_t3_buffer")
        cb_buf = ttk.Checkbutton(buf_frame, text=self.tr("cb_t3_buffer_enable"), variable=self.t3_buffer_enabled)
        cb_buf.pack(anchor="w", padx=3, pady=2)
        self._register_i18n_widget(cb_buf, "cb_t3_buffer_enable")
        row_buf = self.add_file_row(buf_frame, self.tr("lbl_t3_buffer_file"), self.t3_buffer_path, "*.dat *.txt *.csv *.xml")
        row_alpha = ttk.Frame(buf_frame); row_alpha.pack(fill="x", pady=1)
        lbl_alpha = ttk.Label(row_alpha, text=self.tr("lbl_t3_alpha"), width=15, anchor="e")
        lbl_alpha.pack(side="left")
        self._register_i18n_widget(lbl_alpha, "lbl_t3_alpha")
        ttk.Entry(row_alpha, textvariable=self.t3_alpha, width=8).pack(side="left", padx=5)
        ttk.Label(buf_frame, textvariable=self.t3_buffer_status, style="Hint.TLabel").pack(anchor="w", padx=3)

        # ---- Output format selector ----
        self.t3_output_format = tk.StringVar(value="tsv")
        fmt_row = ttk.Frame(buf_frame); fmt_row.pack(fill="x", pady=(4, 2))
        lbl_ofmt = ttk.Label(fmt_row, text=self.tr("lbl_output_format"), width=15, anchor="e")
        lbl_ofmt.pack(side="left")
        self._register_i18n_widget(lbl_ofmt, "lbl_output_format")
        self.t3_fmt_combo = ttk.Combobox(
            fmt_row,
            textvariable=self.t3_output_format,
            values=["tsv", "csv", "cansas_xml", "nxcansas_h5"],
            width=18,
            state="readonly",
        )
        self.t3_fmt_combo.current(0)
        self.t3_fmt_combo.pack(side="left", padx=5)

        mid = ttk.LabelFrame(p, text=self.tr("t3_mid_title"), style="Group.TLabelframe")
        self._register_i18n_widget(mid, "t3_mid_title")
        mid.pack(fill="both", expand=True, padx=10, pady=5)
        self.add_hint(mid, "hint_t3_queue")

        tb = ttk.Frame(mid)
        tb.pack(fill="x")
        btn_add = ttk.Button(tb, text=self.tr("t3_add_btn"), command=self.add_external_1d_files)
        self._register_i18n_widget(btn_add, "t3_add_btn")
        btn_add.pack(side="left")
        btn_clear = ttk.Button(tb, text=self.tr("t3_clear_btn"), command=self.clear_external_1d_files)
        self._register_i18n_widget(btn_clear, "t3_clear_btn")
        btn_clear.pack(side="left", padx=(4, 0))
        btn_check = ttk.Button(tb, text=self.tr("t3_check_btn"), command=self.dry_run_external_1d)
        self._register_i18n_widget(btn_check, "t3_check_btn")
        btn_check.pack(side="right")
        self.add_tooltip(btn_add, "tip_t3_add")
        self.add_tooltip(btn_clear, "tip_t3_clear")
        self.add_tooltip(btn_check, "tip_t3_check")

        ttk.Label(mid, textvariable=self.t3_queue_info, style="Hint.TLabel").pack(anchor="w", padx=5, pady=(2, 0))
        self.lb_ext1d = tk.Listbox(mid, height=9)
        self.lb_ext1d.pack(fill="both", expand=True, padx=5, pady=5)
        self._register_native_widget(self.lb_ext1d)
        self.add_tooltip(self.lb_ext1d, "tip_t3_listbox")

        bot = ttk.Frame(p)
        bot.pack(fill="x", padx=10, pady=10)
        btn_run = ttk.Button(bot, text=self.tr("t3_run_btn"), command=self.run_external_1d_batch, style="Accent.TButton")
        self._register_i18n_widget(btn_run, "t3_run_btn")
        btn_run.pack(fill="x", ipady=5)
        self.t3_prog_bar = ttk.Progressbar(bot, mode="determinate")
        self.t3_prog_bar.pack(fill="x", pady=5)
        row_out_dir = self.add_dir_row(bot, self.tr("lbl_t3_outdir"), self.t3_output_root)
        ttk.Label(bot, textvariable=self.t3_out_hint, style="Hint.TLabel").pack(anchor="w")
        self.add_tooltip(btn_run, "tip_t3_run")
        self.add_tooltip(self.t3_prog_bar, "tip_t3_progress")
        self.add_tooltip(row_out_dir["entry"], "tip_t3_outdir")

        self.global_vars["bg_exp"].trace_add("write", self.on_global_bg_changed_for_t3)
        self.global_vars["bg_i0"].trace_add("write", self.on_global_bg_changed_for_t3)
        self.global_vars["bg_t"].trace_add("write", self.on_global_bg_changed_for_t3)
        self.t3_output_root.trace_add("write", lambda *_: self.refresh_external_1d_status())
        self.on_t3_sync_bg_toggle()
        self.refresh_external_1d_status()

    def add_external_1d_files(self):
        fs = filedialog.askopenfilenames(
            filetypes=[("1D Files", "*.dat *.txt *.chi *.csv"), ("All Files", "*.*")]
        )
        for f in fs:
            if f not in self.t3_files:
                self.t3_files.append(f)
                self.lb_ext1d.insert(tk.END, Path(f).name)
        self.refresh_external_1d_status()

    def clear_external_1d_files(self):
        self.t3_files = []
        self.lb_ext1d.delete(0, tk.END)
        self.refresh_external_1d_status()

    def refresh_external_1d_status(self):
        if hasattr(self, "t3_queue_info"):
            total = len(getattr(self, "t3_files", []))
            uniq = len(dict.fromkeys(getattr(self, "t3_files", [])))
            self.t3_queue_info.set(self._fmt_queue_info(total, uniq))

        if hasattr(self, "t3_out_hint"):
            custom_root = self.t3_output_root.get().strip() if hasattr(self, "t3_output_root") else ""
            if custom_root:
                self.t3_out_hint.set(
                    f"{self.tr('out_write_prefix')}: {custom_root}\\processed_external_1d_abs "
                    f"(æŠ¥å‘Š: {custom_root}\\processed_external_1d_reports)"
                )
            else:
                self.t3_out_hint.set(f"{self.tr('out_auto_prefix')}: processed_external_1d_abs")

    def sync_t3_bg_params_from_global(self):
        if not hasattr(self, "global_vars"):
            return
        try:
            self.t3_bg_exp.set(float(self.global_vars["bg_exp"].get()))
            self.t3_bg_i0.set(float(self.global_vars["bg_i0"].get()))
            self.t3_bg_t.set(float(self.global_vars["bg_t"].get()))
        except Exception:
            pass

    def on_global_bg_changed_for_t3(self, *_):
        if hasattr(self, "t3_sync_bg_from_global") and bool(self.t3_sync_bg_from_global.get()):
            self.sync_t3_bg_params_from_global()

    def on_t3_sync_bg_toggle(self):
        follow = bool(self.t3_sync_bg_from_global.get()) if hasattr(self, "t3_sync_bg_from_global") else False
        if follow:
            self.sync_t3_bg_params_from_global()
        state = "disabled" if follow else "normal"
        for w in [
            getattr(self, "t3_bg_entry_exp", None),
            getattr(self, "t3_bg_entry_i0", None),
            getattr(self, "t3_bg_entry_t", None),
        ]:
            if w is not None:
                try:
                    w.configure(state=state)
                except Exception:
                    pass

    def read_external_1d_profile(self, path):
        dfs = []
        errs = []
        read_trials = [
            {"sep": None, "engine": "python", "comment": "#"},
            {"sep": r"[,\s;]+", "engine": "python", "comment": "#"},
            {"sep": r"[,\s;]+", "engine": "python", "comment": "#", "header": None},
        ]

        for kw in read_trials:
            try:
                df = pd.read_csv(path, **kw)
                if df is not None and not df.empty and df.shape[1] >= 2:
                    dfs.append(df)
            except Exception as e:
                errs.append(str(e))

        if not dfs:
            raise ValueError(f"æ— æ³•è§£ææ–‡ä»¶: {Path(path).name} ({'; '.join(errs[:2])})")

        best = None
        best_pts = -1

        for df in dfs:
            numeric_cols = {}
            for col in df.columns:
                s = pd.to_numeric(df[col], errors="coerce")
                arr = s.to_numpy(dtype=np.float64, na_value=np.nan)
                cnt = int(np.isfinite(arr).sum())
                if cnt >= 3:
                    numeric_cols[col] = s

            if len(numeric_cols) < 2:
                continue

            cols = list(numeric_cols.keys())

            def pick(tokens, used):
                for c in cols:
                    if c in used:
                        continue
                    name = str(c).strip().lower().replace("_", "").replace(" ", "")
                    if any(t in name for t in tokens):
                        return c
                return None

            x_col = pick(["q", "chi", "radial", "2theta", "x"], set()) or cols[0]
            i_col = pick(["intensity", "irel", "iabs", "signal", "count", "i"], {x_col})
            if i_col is None:
                i_col = next((c for c in cols if c != x_col), None)
            if i_col is None:
                continue

            err_col = pick(["error", "sigma", "std", "unc"], {x_col, i_col})
            if err_col is None and len(cols) >= 3:
                err_col = next((c for c in cols if c not in {x_col, i_col}), None)

            x = pd.to_numeric(df[x_col], errors="coerce").to_numpy(dtype=np.float64, na_value=np.nan)
            i_rel = pd.to_numeric(df[i_col], errors="coerce").to_numpy(dtype=np.float64, na_value=np.nan)
            mask = np.isfinite(x) & np.isfinite(i_rel)
            if int(mask.sum()) < 3:
                continue

            x = x[mask]
            i_rel = i_rel[mask]
            if err_col is not None:
                err = pd.to_numeric(df[err_col], errors="coerce").to_numpy(dtype=np.float64, na_value=np.nan)[mask]
                err = np.where(np.isfinite(err), err, np.nan)
            else:
                err = np.full_like(i_rel, np.nan, dtype=np.float64)

            order = np.argsort(x)
            x = x[order]
            i_rel = i_rel[order]
            err = err[order]

            pts = int(x.size)
            if pts > best_pts:
                best_pts = pts
                best = {
                    "x": x,
                    "i_rel": i_rel,
                    "err_rel": err,
                    "x_col": str(x_col),
                    "i_col": str(i_col),
                    "err_col": str(err_col) if err_col is not None else "",
                }

        if best is None:
            raise ValueError(f"æ— æ³•ä» {Path(path).name} è¯†åˆ«æœ‰æ•ˆæ•°å€¼åˆ—ï¼ˆè‡³å°‘éœ€è¦ X å’Œ I ä¸¤åˆ—ï¼‰")
        return best

    def _regularize_xy_triplet(self, x, y, e=None, min_points=3, name="profile"):
        x = np.asarray(x, dtype=np.float64)
        y = np.asarray(y, dtype=np.float64)
        if e is None:
            e = np.full_like(y, np.nan, dtype=np.float64)
        else:
            e = np.asarray(e, dtype=np.float64)

        if x.shape != y.shape:
            raise ValueError(f"{name}: x/y å½¢çŠ¶ä¸ä¸€è‡´ã€‚")
        if e.shape != x.shape:
            e = np.full_like(y, np.nan, dtype=np.float64)

        mask = np.isfinite(x) & np.isfinite(y)
        x = x[mask]
        y = y[mask]
        e = e[mask]
        if x.size < min_points:
            raise ValueError(f"{name}: æœ‰æ•ˆç‚¹æ•°ä¸è¶³ï¼ˆ<{min_points}ï¼‰ã€‚")

        order = np.argsort(x)
        x = x[order]
        y = y[order]
        e = e[order]

        # Collapse duplicate x values by averaging to build a stable monotonic grid.
        ux, inv = np.unique(x, return_inverse=True)
        if ux.size != x.size:
            y_sum = np.zeros_like(ux, dtype=np.float64)
            cnt = np.zeros_like(ux, dtype=np.float64)
            e_sq_sum = np.zeros_like(ux, dtype=np.float64)
            e_cnt = np.zeros_like(ux, dtype=np.float64)
            for i, g in enumerate(inv):
                y_sum[g] += y[i]
                cnt[g] += 1.0
                if np.isfinite(e[i]):
                    e_sq_sum[g] += e[i] ** 2
                    e_cnt[g] += 1.0
            y = y_sum / np.clip(cnt, 1.0, None)
            # Proper error propagation for averaged duplicates:
            # sigma_avg = sqrt(sum(sigma_i^2)) / N
            e = np.where(
                e_cnt > 0,
                np.sqrt(e_sq_sum) / np.clip(e_cnt, 1.0, None),
                np.nan,
            )
            x = ux

        if x.size < min_points:
            raise ValueError(f"{name}: å»é‡åæœ‰æ•ˆç‚¹æ•°ä¸è¶³ï¼ˆ<{min_points}ï¼‰ã€‚")
        return x, y, e

    def infer_external_x_label(self, path, profile):
        mode = self.t3_x_mode.get().strip().lower()
        if mode == "q_a^-1":
            return "Q_A^-1"
        if mode == "chi_deg":
            return "Chi_deg"

        name = f"{profile.get('x_col', '')}".lower()
        fname = Path(path).name.lower()
        if ("chi" in name) or fname.endswith(".chi"):
            return "Chi_deg"
        return "Q_A^-1"

    def parse_mode_outputs(self, outputs_raw):
        if outputs_raw is None:
            return []
        if isinstance(outputs_raw, (int, float, np.number)) and not np.isfinite(outputs_raw):
            return []

        s = str(outputs_raw).strip()
        if not s or s.lower() in {"nan", "none", "null"}:
            return []

        out = []
        for part in s.split("|"):
            item = str(part).strip()
            if not item:
                continue
            m = re.match(
                r"^(1d_full|1d_sector(?:\[[^\]]+\])?|1d_sector_sum|radial_chi)\s*:\s*(.+)$",
                item,
                flags=re.IGNORECASE,
            )
            if m:
                item = m.group(2).strip()
            item = re.sub(r"\(existing\)\s*$", "", item, flags=re.IGNORECASE).strip()
            if item:
                out.append(item)
        return out

    def collect_external_meta_rows(self, df):
        if df is None or df.empty:
            return [], {}

        col_map = {}
        for c in df.columns:
            col_map[self._norm_key(c)] = c

        def pick(names):
            for n in names:
                if n in col_map:
                    return col_map[n]
            return None

        file_col = pick(["file", "filename", "name", "path", "sample", "samplename"])
        outputs_col = pick(["outputs", "output", "result", "results"])
        if file_col is None and outputs_col is None:
            raise ValueError("metadata CSV ç¼ºå°‘æ–‡ä»¶åˆ—ï¼ˆfile/filename/name/pathï¼‰æˆ–è¾“å‡ºåˆ—ï¼ˆoutputsï¼‰ã€‚")

        exp_col = pick(["exp", "exposure", "exposuretime", "exposures", "counttime", "time", "exposures"])
        mon_col = pick(["i0", "mon", "monitor", "beammonitor", "flux"])
        trans_col = pick(["trans", "transmission", "sampletransmission", "abs"])
        thk_mm_col = pick(["thkmm", "thicknessmm", "thickness", "dmm", "calcthkmm", "fixedthicknessmm"])
        thk_cm_col = pick(["thkcm", "thicknesscm", "dcm"])

        out_map = {}
        rows = []
        for _, row in df.iterrows():
            names = []

            if file_col is not None:
                raw_file = str(row.get(file_col, "")).strip()
                if raw_file:
                    names.append(raw_file)
            if outputs_col is not None:
                names.extend(self.parse_mode_outputs(row.get(outputs_col)))

            uniq_names = []
            seen = set()
            for nm in names:
                nm_s = str(nm).strip()
                if not nm_s:
                    continue
                nk = nm_s.lower()
                if nk in seen:
                    continue
                seen.add(nk)
                uniq_names.append(nm_s)

            if not uniq_names:
                continue

            raw_exp = row.get(exp_col) if exp_col is not None else None
            raw_mon = row.get(mon_col) if mon_col is not None else None
            raw_trans = row.get(trans_col) if trans_col is not None else None
            raw_thk_mm = row.get(thk_mm_col) if thk_mm_col is not None else None
            raw_thk_cm = row.get(thk_cm_col) if thk_cm_col is not None else None

            exp = self._extract_float(raw_exp)
            mon = self._extract_float(raw_mon)
            trans = self._extract_float(raw_trans)
            if trans is not None:
                trans = self._normalize_transmission(trans, raw=raw_trans, key=trans_col)

            thk_mm = self._extract_float(raw_thk_mm)
            if thk_mm is None:
                thk_cm = self._extract_float(raw_thk_cm)
                if thk_cm is not None:
                    thk_mm = thk_cm * 10.0

            meta = {"exp": exp, "mon": mon, "trans": trans, "thk_mm": thk_mm}
            for nm in uniq_names:
                p = Path(nm)
                aliases = {str(nm).lower(), p.name.lower(), p.stem.lower()}
                for a in aliases:
                    if a:
                        out_map[a] = meta
                rows.append({
                    "file": str(nm).strip(),
                    "exp": exp if exp is not None else np.nan,
                    "i0": mon if mon is not None else np.nan,
                    "trans": trans if trans is not None else np.nan,
                    "thk_mm": thk_mm if thk_mm is not None else np.nan,
                })

        if rows:
            df_rows = pd.DataFrame(rows)
            if "file" in df_rows.columns:
                df_rows["file"] = df_rows["file"].astype(str).str.strip()
                df_rows = df_rows[df_rows["file"] != ""]
                df_rows["_k"] = df_rows["file"].str.lower()
                df_rows = df_rows.drop_duplicates(subset=["_k"], keep="last").drop(columns=["_k"])
            rows = df_rows.to_dict("records")

        return rows, out_map

    def export_tab3_metadata_from_report(self, report_csv_path, stamp=None):
        report_path = Path(report_csv_path)
        if not report_path.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ°æŠ¥å‘Šæ–‡ä»¶: {report_path}")

        try:
            df = pd.read_csv(report_path, sep=None, engine="python")
        except Exception:
            df = pd.read_csv(report_path)

        rows, _ = self.collect_external_meta_rows(df)
        if not rows:
            raise ValueError("æœªä»æŠ¥å‘Šä¸­æå–åˆ°å¯ç”¨ metadata è¡Œã€‚")

        out_df = pd.DataFrame(rows)
        for c in ["file", "exp", "i0", "trans", "thk_mm"]:
            if c not in out_df.columns:
                out_df[c] = np.nan
        out_df = out_df[["file", "exp", "i0", "trans", "thk_mm"]]

        out_df["file"] = out_df["file"].astype(str).str.strip()
        out_df = out_df[out_df["file"] != ""]
        if out_df.empty:
            raise ValueError("metadata è¡Œä¸ºç©ºï¼šæœªè¯†åˆ«åˆ°æ–‡ä»¶åã€‚")

        out_df["_k"] = out_df["file"].str.lower()
        out_df = out_df.drop_duplicates(subset=["_k"], keep="last").drop(columns=["_k"])
        out_df = out_df.sort_values("file").reset_index(drop=True)

        if not stamp:
            stamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")

        out_dir = report_path.parent
        out_stamp = out_dir / f"metadata_for_tab3_{stamp}.csv"
        out_latest = out_dir / "metadata.csv"
        out_df.to_csv(out_stamp, index=False, encoding="utf-8-sig")
        out_df.to_csv(out_latest, index=False, encoding="utf-8-sig")
        return out_stamp, out_latest, int(len(out_df))

    def t3_make_meta_from_batch_report(self):
        try:
            report_path = filedialog.askopenfilename(
                filetypes=[("Batch Report", "batch_report_*.csv"), ("CSV", "*.csv"), ("All Files", "*.*")]
            )
            if not report_path:
                return
            out_stamp, out_latest, n_rows = self.export_tab3_metadata_from_report(report_path)
            self.t3_meta_csv_path.set(str(out_latest))
            messagebox.showinfo(
                "metadata å·²ç”Ÿæˆ",
                (
                    f"å·²ä»æŠ¥å‘Šç”Ÿæˆ metadataã€‚\n"
                    f"è¡Œæ•°: {n_rows}\n"
                    f"æ—¶é—´æˆ³æ–‡ä»¶: {out_stamp.name}\n"
                    f"é»˜è®¤æ–‡ä»¶: {out_latest.name}\n"
                    f"Tab3 å°†ä½¿ç”¨: {out_latest}"
                ),
            )
        except Exception as e:
            self.show_error("msg_input_error_title", f"{e}\n{traceback.format_exc()}")

    def load_external_meta_map(self, csv_path):
        if not csv_path:
            return {}

        try:
            df = pd.read_csv(csv_path, sep=None, engine="python")
        except Exception:
            df = pd.read_csv(csv_path)

        if df is None or df.empty:
            return {}
        _, out_map = self.collect_external_meta_rows(df)
        return out_map

    def get_external_meta_for_file(self, meta_map, file_path):
        if not meta_map:
            return None
        p = Path(file_path)

        def norm_path(s):
            return str(s).strip().replace("\\", "/").lower()

        full_key = norm_path(file_path)
        if full_key in meta_map:
            return meta_map[full_key]

        # å…¼å®¹ metadata ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ˆä¾‹å¦‚ sector_01/sample.datï¼‰ï¼Œè€Œå®é™…æ–‡ä»¶æ˜¯ç»å¯¹è·¯å¾„ã€‚
        suffix_hits = []
        for k in meta_map.keys():
            ks = norm_path(k)
            if "/" not in ks:
                continue
            if full_key.endswith("/" + ks) or full_key.endswith(ks):
                suffix_hits.append((len(ks), k))
        if suffix_hits:
            suffix_hits.sort(reverse=True)
            return meta_map[suffix_hits[0][1]]

        candidates = [p.name.lower(), p.stem.lower()]
        for c in candidates:
            if c in meta_map:
                return meta_map[c]
        return None

    def parse_external_1d_header_meta(self, file_path):
        meta = {}
        try:
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                for _ in range(200):
                    line = f.readline()
                    if not line:
                        break
                    s = line.strip()
                    if not s:
                        continue
                    if not s.startswith(("#", ";", "//")):
                        break
                    s = s.lstrip("#;/ ").strip()
                    if not s:
                        continue
                    if "=" in s:
                        k, v = s.split("=", 1)
                    elif ":" in s:
                        k, v = s.split(":", 1)
                    else:
                        parts = s.split(None, 1)
                        if len(parts) != 2:
                            continue
                        k, v = parts
                    nk = self._norm_key(k)
                    if nk:
                        meta[nk] = v.strip()
        except Exception:
            return {"exp": None, "mon": None, "trans": None, "thk_mm": None}

        exp_raw, exp_key = self.meta_get_raw(meta, ["exposuretime", "counttime", "acqtime", "exposure", "time", "exp"])
        mon_raw, _ = self.meta_get_raw(meta, ["monitor", "beammonitor", "ionchamber", "mon", "i0", "flux"])
        trans_raw, trans_key = self.meta_get_raw(meta, ["sampletransmission", "transmission", "trans", "abs"])
        thk_raw, _ = self.meta_get_raw(meta, ["thkmm", "thicknessmm", "thickness", "dmm"])

        exp = self._extract_float(exp_raw)
        if exp is not None:
            tag = f"{exp_key or ''} {exp_raw or ''}".lower()
            if "ms" in tag:
                exp /= 1000.0
            elif "us" in tag:
                exp /= 1_000_000.0
        mon = self._extract_float(mon_raw)
        trans = self._extract_float(trans_raw)
        if trans is not None:
            trans = self._normalize_transmission(trans, raw=trans_raw, key=trans_key)
        thk_mm = self._extract_float(thk_raw)

        return {"exp": exp, "mon": mon, "trans": trans, "thk_mm": thk_mm}

    def align_profile_to_x(self, x_target, ref_profile, name):
        x = np.asarray(x_target, dtype=np.float64)
        if not np.all(np.isfinite(x)):
            raise ValueError(f"{name} ç›®æ ‡ x ç½‘æ ¼åŒ…å«éæœ‰é™å€¼ã€‚")

        xr, yr, er = self._regularize_xy_triplet(
            ref_profile["x"],
            ref_profile["i_rel"],
            ref_profile.get("err_rel"),
            min_points=2,
            name=name,
        )

        if xr.size == x.size and np.allclose(xr, x, rtol=1e-7, atol=1e-9, equal_nan=False):
            y = yr
            e = er
        else:
            y = np.interp(x, xr, yr, left=np.nan, right=np.nan)
            finite_err = np.isfinite(er)
            if np.sum(finite_err) >= 2:
                e = np.interp(x, xr[finite_err], er[finite_err], left=np.nan, right=np.nan)
            else:
                e = np.full_like(y, np.nan)

        outside = int(np.sum(~np.isfinite(y)))
        return y, e, outside

    def resolve_external_sample_params(self, file_path, meta_map, monitor_mode):
        meta = self.get_external_meta_for_file(meta_map, file_path)
        hmeta = self.parse_external_1d_header_meta(file_path)

        exp = None
        mon = None
        trans = None
        thk_mm_meta = None
        source = "fixed"

        if meta is not None:
            if meta.get("exp") is not None:
                exp = meta["exp"]
            if meta.get("mon") is not None:
                mon = meta["mon"]
            if meta.get("trans") is not None:
                trans = meta["trans"]
            thk_mm_meta = meta.get("thk_mm")
            source = "meta"

        if hmeta is not None:
            if exp is None and hmeta.get("exp") is not None:
                exp = hmeta["exp"]
                if source != "meta":
                    source = "header"
            if mon is None and hmeta.get("mon") is not None:
                mon = hmeta["mon"]
                if source != "meta":
                    source = "header"
            if trans is None and hmeta.get("trans") is not None:
                trans = hmeta["trans"]
                if source != "meta":
                    source = "header"
            if thk_mm_meta is None and hmeta.get("thk_mm") is not None:
                thk_mm_meta = hmeta["thk_mm"]
                if source == "fixed":
                    source = "header"

        if exp is None:
            exp = self.t3_sample_exp.get()
        if mon is None:
            mon = self.t3_sample_i0.get()
        if trans is None:
            trans = self.t3_sample_t.get()

        norm = self.compute_norm_factor(exp, mon, trans, monitor_mode)
        return {
            "exp": exp,
            "mon": mon,
            "trans": trans,
            "norm": norm,
            "thk_mm_meta": thk_mm_meta,
            "source": source,
        }

    def dry_run_external_1d(self):
        if not self.t3_files:
            self.show_info("msg_preview_title", self.tr("msg_t3_queue_empty"))
            return

        rows = []
        files = list(dict.fromkeys(self.t3_files))
        failed_files = 0
        risky_files = 0
        pipeline_mode = self.t3_pipeline_mode.get().strip().lower()
        mode = self.t3_corr_mode.get()
        k = float(self.global_vars["k_factor"].get())
        thk_mm = float(self.t3_fixed_thk.get())
        monitor_mode = self.get_monitor_mode()
        warnings = []

        if k <= 0:
            warnings.append(self.tr("warn_k_le_zero"))
        if mode == "k_over_d" and thk_mm <= 0:
            warnings.append(self.tr("warn_kd_thk_le_zero"))

        meta_map = {}
        bg_prof = None
        dark_prof = None
        bg_norm = np.nan
        if pipeline_mode == "raw":
            meta_path = self.t3_meta_csv_path.get().strip()
            if meta_path:
                try:
                    meta_map = self.load_external_meta_map(meta_path)
                except Exception as e:
                    warnings.append(self.tr("warn_meta_read_fail").format(e=e))
            else:
                warnings.append(self.tr("warn_raw_no_meta"))

            bg_path = self.t3_bg1d_path.get().strip()
            if not bg_path:
                warnings.append(self.tr("warn_raw_no_bg1d"))
            else:
                try:
                    bg_prof = self.read_external_1d_profile(bg_path)
                except Exception as e:
                    warnings.append(self.tr("warn_bg1d_read_fail").format(e=e))

            dark_path = self.t3_dark1d_path.get().strip()
            if dark_path:
                try:
                    dark_prof = self.read_external_1d_profile(dark_path)
                except Exception as e:
                    warnings.append(self.tr("warn_dark1d_read_fail").format(e=e))

            bg_norm = self.compute_norm_factor(
                self.t3_bg_exp.get(), self.t3_bg_i0.get(), self.t3_bg_t.get(), monitor_mode
            )
            if (not np.isfinite(bg_norm) or bg_norm <= 0) and bg_path:
                bg_h = self.parse_external_1d_header_meta(bg_path)
                bg_norm = self.compute_norm_factor(bg_h.get("exp"), bg_h.get("mon"), bg_h.get("trans"), monitor_mode)
            if not np.isfinite(bg_norm) or bg_norm <= 0:
                warnings.append(self.tr("warn_bg_norm_invalid"))

        for fp in files:
            try:
                prof = self.read_external_1d_profile(fp)
                x_label = self.infer_external_x_label(fp, prof)
                status = self.tr("status_ok")
                reason = ""
                norm_s = np.nan
                thk_used = np.nan
                meta_src = "-"
                outside_bg = 0
                outside_dark = 0

                if pipeline_mode == "raw":
                    sp = self.resolve_external_sample_params(fp, meta_map, monitor_mode)
                    norm_s = sp["norm"]
                    meta_src = sp["source"]
                    if not np.isfinite(norm_s) or norm_s <= 0:
                        status = self.tr("status_fail")
                        reason = self.tr("reason_norm_invalid")
                    else:
                        if mode == "k_over_d":
                            thk_use_mm = thk_mm
                            if self.t3_use_meta_thk.get() and sp["thk_mm_meta"] is not None:
                                thk_use_mm = float(sp["thk_mm_meta"])
                            thk_used = thk_use_mm / 10.0 if np.isfinite(thk_use_mm) else np.nan
                            if not np.isfinite(thk_used) or thk_used <= 0:
                                status = self.tr("status_fail")
                                reason = self.tr("reason_thk_invalid")
                        else:
                            thk_used = np.nan

                        if status == self.tr("status_ok") and bg_prof is not None:
                            _, _, outside_bg = self.align_profile_to_x(prof["x"], bg_prof, "BG")
                            if outside_bg > 0:
                                risky_files += 1
                        if status == self.tr("status_ok") and dark_prof is not None:
                            _, _, outside_dark = self.align_profile_to_x(prof["x"], dark_prof, "Dark")
                            if outside_dark > 0:
                                risky_files += 1

                if status != self.tr("status_ok"):
                    failed_files += 1

                rows.append({
                    "File": Path(fp).name,
                    "Points": len(prof["x"]),
                    "XCol": prof.get("x_col", ""),
                    "ICol": prof.get("i_col", ""),
                    "ErrCol": prof.get("err_col", ""),
                    "XLabel": x_label,
                    "Norm_s": norm_s,
                    "Thk_cm": thk_used,
                    "MetaSrc": meta_src,
                    "BG_OutsidePts": outside_bg,
                    "Dark_OutsidePts": outside_dark,
                    "Status": status,
                    "Reason": reason,
                })
            except Exception as e:
                failed_files += 1
                rows.append({
                    "File": Path(fp).name,
                    "Points": 0,
                    "XCol": "",
                    "ICol": "",
                    "ErrCol": "",
                    "XLabel": "",
                    "Norm_s": np.nan,
                    "Thk_cm": np.nan,
                    "MetaSrc": "-",
                    "BG_OutsidePts": 0,
                    "Dark_OutsidePts": 0,
                    "Status": self.tr("status_fail"),
                    "Reason": str(e),
                })

        gate = self._evaluate_preflight_gate(
            total_files=len(files),
            failed_files=failed_files,
            warnings_count=len(warnings),
            risky_files=risky_files,
        )

        top = tk.Toplevel(self.root)
        top.title(self.tr("title_t3_dryrun"))
        txt = tk.Text(top, font=("Consolas", 9))
        txt.pack(fill="both", expand=True)
        self._register_native_widget(txt)
        txt.insert(tk.END, f"{self._preflight_label_text(gate)}\n")
        txt.insert(tk.END, f"{self.tr('pre_k_factor')} {k}\n")
        txt.insert(tk.END, f"{self.tr('pre_pipeline')} {pipeline_mode}\n")
        txt.insert(tk.END, f"{self.tr('pre_corr_mode')} {mode}\n")
        txt.insert(tk.END, f"{self.tr('pre_fixed_thk')} {thk_mm}\n")
        txt.insert(tk.END, f"{self.tr('pre_x_mode')} {self.t3_x_mode.get()}\n")
        if pipeline_mode == "raw":
            txt.insert(tk.END, f"{self.tr('pre_i0_semantic')} {monitor_mode} (norm={self.monitor_norm_formula(monitor_mode)})\n")
            txt.insert(tk.END, f"BG_Norm: {bg_norm if np.isfinite(bg_norm) else 'NaN'}\n")
        txt.insert(tk.END, "-" * 80 + "\n")
        if warnings:
            txt.insert(tk.END, f"{self.tr('pre_warning_header')}\n")
            for w in warnings:
                txt.insert(tk.END, f"- {w}\n")
            txt.insert(tk.END, "-" * 80 + "\n")
        else:
            txt.insert(tk.END, f"{self.tr('pre_pass_t3')}\n")
            txt.insert(tk.END, "-" * 80 + "\n")
        txt.insert(tk.END, pd.DataFrame(rows).to_string(index=False))

    def run_external_1d_batch(self):
        try:
            if not self.t3_files:
                raise ValueError("é˜Ÿåˆ—ä¸ºç©ºï¼šè¯·å…ˆæ·»åŠ å¤–éƒ¨1Dæ–‡ä»¶ã€‚")

            files = list(dict.fromkeys(self.t3_files))
            if len(files) < len(self.t3_files):
                self.t3_files = files
                self.lb_ext1d.delete(0, tk.END)
                for f in self.t3_files:
                    self.lb_ext1d.insert(tk.END, Path(f).name)
                self.refresh_external_1d_status()

            k = float(self.global_vars["k_factor"].get())
            if not np.isfinite(k) or k <= 0:
                raise ValueError("K å› å­æ— æ•ˆï¼ˆå¿…é¡» > 0ï¼‰ã€‚")

            pipeline_mode = self.t3_pipeline_mode.get().strip().lower()
            if pipeline_mode not in ("scaled", "raw"):
                raise ValueError(f"æœªçŸ¥æµç¨‹æ¨¡å¼: {pipeline_mode}")

            corr_mode = self.t3_corr_mode.get().strip().lower()
            if corr_mode not in ("k_over_d", "k_only"):
                raise ValueError(f"æœªçŸ¥æ ¡æ­£æ¨¡å¼: {corr_mode}")

            fixed_thk_mm = float(self.t3_fixed_thk.get())
            if corr_mode == "k_over_d" and fixed_thk_mm <= 0:
                raise ValueError("K/d æ¨¡å¼ä¸‹å›ºå®šåšåº¦å¿…é¡» > 0 mmã€‚")

            fixed_thk_cm = fixed_thk_mm / 10.0 if corr_mode == "k_over_d" else np.nan
            scale_factor_global = (k / fixed_thk_cm) if corr_mode == "k_over_d" else k
            monitor_mode = self.get_monitor_mode()

            meta_map = {}
            bg_prof = None
            dark_prof = None
            bg_norm = np.nan
            if pipeline_mode == "raw":
                meta_path = self.t3_meta_csv_path.get().strip()
                if meta_path:
                    meta_map = self.load_external_meta_map(meta_path)

                bg_path = self.t3_bg1d_path.get().strip()
                if not bg_path:
                    raise ValueError("rawæµç¨‹å¿…é¡»æä¾› BG 1D æ–‡ä»¶ã€‚")
                bg_prof = self.read_external_1d_profile(bg_path)

                dark_path = self.t3_dark1d_path.get().strip()
                if dark_path:
                    dark_prof = self.read_external_1d_profile(dark_path)

                bg_norm = self.compute_norm_factor(
                    self.t3_bg_exp.get(), self.t3_bg_i0.get(), self.t3_bg_t.get(), monitor_mode
                )
                if (not np.isfinite(bg_norm) or bg_norm <= 0) and bg_path:
                    bg_h = self.parse_external_1d_header_meta(bg_path)
                    bg_norm = self.compute_norm_factor(bg_h.get("exp"), bg_h.get("mon"), bg_h.get("trans"), monitor_mode)
                if not np.isfinite(bg_norm) or bg_norm <= 0:
                    raise ValueError("rawæµç¨‹ä¸‹ BG å½’ä¸€åŒ–å› å­æ— æ•ˆï¼Œè¯·æ£€æŸ¥ BG exp/i0/Tã€‚")

            custom_out_root = self.t3_output_root.get().strip() if hasattr(self, "t3_output_root") else ""
            if custom_out_root:
                out_root = Path(custom_out_root).expanduser()
                out_root.mkdir(parents=True, exist_ok=True)
            else:
                out_root = Path(files[0]).parent
            out_dir = out_root / "processed_external_1d_abs"
            report_dir = out_root / "processed_external_1d_reports"
            out_dir.mkdir(parents=True, exist_ok=True)
            report_dir.mkdir(parents=True, exist_ok=True)

            resume = bool(self.t3_resume_enabled.get())
            overwrite = bool(self.t3_overwrite.get())
            if parse_run_policy is not None:
                run_policy = parse_run_policy(resume_enabled=resume, overwrite_existing=overwrite)
            else:
                run_policy = SimpleNamespace(
                    resume_enabled=resume,
                    overwrite_existing=overwrite,
                    mode=("overwrite" if overwrite else ("resume-skip" if resume else "always-run")),
                    should_skip_existing=lambda exists: bool(exists) and resume and (not overwrite),
                )
            self.log(f"[é…ç½®] Tab3 Existing-output ç­–ç•¥: {run_policy.mode} (resume={resume}, overwrite={overwrite})")
            stem_map = self.build_output_stem_map(files)

            self.t3_prog_bar["maximum"] = len(files)
            self.t3_prog_bar["value"] = 0

            rows = []
            ok = 0
            skip = 0
            fail = 0
            processed = 0

            for idx, fp in enumerate(files):
                fname = Path(fp).name
                reason = ""
                outputs = ""
                points = 0
                x_label = ""
                scale_factor = scale_factor_global if pipeline_mode == "scaled" else np.nan
                thk_cm_used = fixed_thk_cm if pipeline_mode == "scaled" else np.nan
                norm_s = np.nan
                meta_source = "-"
                outside_bg = 0
                outside_dark = 0
                try:
                    prof = self.read_external_1d_profile(fp)
                    points = len(prof["x"])
                    x_label = self.infer_external_x_label(fp, prof)
                    ext = ".chi" if x_label == "Chi_deg" else ".dat"
                    out_path = out_dir / f"{stem_map[fp]}{ext}"

                    if run_policy.should_skip_existing(out_path.exists()):
                        status = "å·²è·³è¿‡"
                        reason = "è¾“å‡ºå·²å­˜åœ¨"
                        outputs = out_path.name
                        skip += 1
                    else:
                        if pipeline_mode == "scaled":
                            scale_factor = scale_factor_global
                            thk_cm_used = fixed_thk_cm
                            i_abs = np.asarray(prof["i_rel"], dtype=np.float64) * scale_factor
                            err_abs = np.asarray(prof["err_rel"], dtype=np.float64) * abs(scale_factor)
                        else:
                            sp = self.resolve_external_sample_params(fp, meta_map, monitor_mode)
                            norm_s = sp["norm"]
                            meta_source = sp["source"]
                            if not np.isfinite(norm_s) or norm_s <= 0:
                                raise ValueError("æ ·å“å½’ä¸€åŒ–å› å­æ— æ•ˆï¼ˆexp/i0/Tï¼‰")

                            if corr_mode == "k_over_d":
                                thk_use_mm = fixed_thk_mm
                                if self.t3_use_meta_thk.get() and sp["thk_mm_meta"] is not None:
                                    thk_use_mm = float(sp["thk_mm_meta"])
                                thk_cm_used = float(thk_use_mm) / 10.0
                                if not np.isfinite(thk_cm_used) or thk_cm_used <= 0:
                                    raise ValueError("åšåº¦æ— æ•ˆï¼ˆå›ºå®šåšåº¦æˆ–metadata thk_mmï¼‰")
                                scale_factor = k / thk_cm_used
                            else:
                                thk_cm_used = np.nan
                                scale_factor = k

                            s_i = np.asarray(prof["i_rel"], dtype=np.float64)
                            s_e = np.asarray(prof["err_rel"], dtype=np.float64)
                            x = np.asarray(prof["x"], dtype=np.float64)

                            bg_i, bg_e, outside_bg = self.align_profile_to_x(x, bg_prof, "BG")
                            if dark_prof is not None:
                                d_i, d_e, outside_dark = self.align_profile_to_x(x, dark_prof, "Dark")
                            else:
                                d_i = np.zeros_like(s_i)
                                d_e = np.full_like(s_i, np.nan)

                            net = (s_i - d_i) / norm_s - (bg_i - d_i) / bg_norm

                            if np.all(~np.isfinite(net)):
                                raise ValueError("å‡€ä¿¡å·å…¨éƒ¨ä¸ºæ— æ•ˆå€¼ï¼Œæ— æ³•è¾“å‡ºã€‚")

                            if np.any(np.isfinite(s_e)) or np.any(np.isfinite(bg_e)) or np.any(np.isfinite(d_e)):
                                s_term = (np.nan_to_num(s_e, nan=0.0) / norm_s) ** 2
                                bg_term = (np.nan_to_num(bg_e, nan=0.0) / bg_norm) ** 2
                                d_term = (np.nan_to_num(d_e, nan=0.0) * (1.0 / bg_norm - 1.0 / norm_s)) ** 2
                                net_err = np.sqrt(s_term + bg_term + d_term)
                                net_err[~np.isfinite(net)] = np.nan
                            else:
                                net_err = np.full_like(net, np.nan)

                            i_abs = net * scale_factor
                            err_abs = net_err * abs(scale_factor)

                            issue = self.profile_health_issue(i_abs)
                            if issue:
                                raise ValueError(issue)

                        # --- Buffer / solvent subtraction (post-calibration) ---
                        if (hasattr(self, "t3_buffer_enabled") and self.t3_buffer_enabled.get()
                                and self.t3_buffer_path.get().strip()):
                            if pipeline_mode == "raw":
                                raise ValueError(
                                    "raw æµç¨‹ä¸‹å¯ç”¨ buffer æ‰£é™¤è¦æ±‚ buffer æ›²çº¿å·²åœ¨ä¸æ ·å“ä¸€è‡´çš„ç»å¯¹æ ‡åº¦ï¼›"
                                    "å½“å‰ç‰ˆæœ¬ä¸ºé˜²æ­¢é‡çº²è¯¯ç”¨å·²ç¦æ­¢è¯¥ç»„åˆã€‚"
                                )
                            buf_path = self.t3_buffer_path.get().strip()
                            buf_prof = self.read_external_1d_profile(buf_path)
                            buf_alpha = float(self.t3_alpha.get()) if hasattr(self, "t3_alpha") else 1.0
                            if subtract_buffer is not None:
                                buf_x = np.asarray(buf_prof["x"], dtype=np.float64)
                                buf_i = np.asarray(buf_prof["i_rel"], dtype=np.float64)
                                buf_e = np.asarray(buf_prof["err_rel"], dtype=np.float64)
                                result_buf = subtract_buffer(
                                    np.asarray(prof["x"], dtype=np.float64),
                                    i_abs, err_abs,
                                    buf_x, buf_i, buf_e,
                                    alpha=buf_alpha,
                                )
                                i_abs = result_buf.i_subtracted
                                err_abs = result_buf.err_subtracted
                            else:
                                # Fallback without library: subtraction + error propagation
                                _x_s = np.asarray(prof["x"], dtype=np.float64)
                                _x_b = np.asarray(buf_prof["x"], dtype=np.float64)
                                buf_i_interp = np.interp(
                                    _x_s, _x_b,
                                    np.asarray(buf_prof["i_rel"], dtype=np.float64),
                                )
                                buf_e_interp = np.interp(
                                    _x_s, _x_b,
                                    np.asarray(buf_prof["err_rel"], dtype=np.float64),
                                )
                                i_abs = i_abs - buf_alpha * buf_i_interp
                                err_abs = np.sqrt(err_abs**2 + (buf_alpha * buf_e_interp)**2)

                        _ofmt = self.t3_output_format.get() if hasattr(self, "t3_output_format") else "tsv"
                        self.save_profile_table(out_path, prof["x"], i_abs, err_abs, x_label, output_format=_ofmt)
                        status = "æˆåŠŸ"
                        outputs = out_path.name
                        ok += 1

                except Exception as e:
                    status = "å¤±è´¥"
                    reason = str(e)
                    fail += 1

                rows.append({
                    "Index": idx,
                    "File": fname,
                    "Status": status,
                    "Reason": reason,
                    "Points": points,
                    "XLabel": x_label,
                    "PipelineMode": pipeline_mode,
                    "CorrMode": corr_mode,
                    "K": k,
                    "Thickness_cm": thk_cm_used if np.isfinite(thk_cm_used) else np.nan,
                    "Norm_s": norm_s if np.isfinite(norm_s) else np.nan,
                    "BG_Norm": bg_norm if np.isfinite(bg_norm) else np.nan,
                    "MetaSource": meta_source,
                    "BG_OutsidePts": outside_bg,
                    "Dark_OutsidePts": outside_dark,
                    "ScaleFactor": scale_factor,
                    "Output": outputs,
                })

                processed += 1
                self.t3_prog_bar["value"] = processed
                self.root.update_idletasks()

            rows.sort(key=lambda x: x.get("Index", 0))
            for r in rows:
                r.pop("Index", None)

            stamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")
            report_path = report_dir / f"external1d_report_{stamp}.csv"
            pd.DataFrame(rows).to_csv(report_path, index=False, encoding="utf-8-sig")

            meta = {
                "timestamp": stamp,
                "files_total": len(files),
                "k_factor": k,
                "pipeline_mode": pipeline_mode,
                "corr_mode": corr_mode,
                "scale_factor_global": scale_factor_global,
                "fixed_thickness_mm": fixed_thk_mm if corr_mode == "k_over_d" else None,
                "x_mode": self.t3_x_mode.get(),
                "monitor_mode": monitor_mode,
                "monitor_norm_formula": self.monitor_norm_formula(monitor_mode),
                "meta_csv": self.t3_meta_csv_path.get().strip(),
                "bg_1d_path": self.t3_bg1d_path.get().strip(),
                "dark_1d_path": self.t3_dark1d_path.get().strip(),
                "bg_norm": float(bg_norm) if np.isfinite(bg_norm) else None,
                "resume_enabled": resume,
                "overwrite": overwrite,
                "existing_output_policy": run_policy.mode,
                "output_root": str(out_root),
                "output_root_custom": bool(custom_out_root),
                "output_dir": str(out_dir),
                "report_csv": str(report_path),
                "summary": {"success": ok, "skipped": skip, "failed": fail},
            }
            meta_path = report_dir / f"external1d_meta_{stamp}.json"
            with open(meta_path, "w", encoding="utf-8") as f:
                json.dump(meta, f, indent=2, ensure_ascii=False)

            self.show_info(
                "msg_ext_done_title",
                self.tr("msg_ext_done_body").format(
                    ok=ok, skip=skip, fail=fail,
                    out_dir=out_dir, report=report_path.name, meta=meta_path.name,
                ),
            )

        except Exception as e:
            self.show_error("msg_ext_error_title", f"{e}\n{traceback.format_exc()}")

    def init_tab_help(self):
        p = self.tab_help

        head = ttk.LabelFrame(p, text=self.tr("help_panel_title"), style="Group.TLabelframe")
        self._register_i18n_widget(head, "help_panel_title")
        head.pack(fill="x", padx=10, pady=(8, 4))
        lbl_intro = ttk.Label(
            head,
            text=self.tr("help_panel_intro"),
            justify="left",
            style="Hint.TLabel",
        )
        self._register_i18n_widget(lbl_intro, "help_panel_intro")
        lbl_intro.pack(fill="x", padx=5, pady=4)

        bar = ttk.Frame(p)
        bar.pack(fill="x", padx=10, pady=(0, 4))
        lbl_scroll = ttk.Label(bar, text=self.tr("help_scroll_label"), style="Bold.TLabel")
        self._register_i18n_widget(lbl_scroll, "help_scroll_label")
        lbl_scroll.pack(side="left")

        text_wrap = ttk.Frame(p)
        text_wrap.pack(fill="both", expand=True, padx=10, pady=(0, 10))
        y_scroll = ttk.Scrollbar(text_wrap, orient="vertical")
        y_scroll.pack(side="right", fill="y")
        txt = tk.Text(
            text_wrap,
            font=("Consolas", 9),
            wrap="word",
            yscrollcommand=y_scroll.set,
            padx=8,
            pady=8,
        )
        self._register_native_widget(txt)
        txt.pack(side="left", fill="both", expand=True)
        y_scroll.config(command=txt.yview)

        help_text = """
==============================
BL19B2 SAXS Workstation ä½¿ç”¨å¸®åŠ©
==============================

[ä¸€] ç¨‹åºåšä»€ä¹ˆ
1. Tab1ï¼šç”¨æ ‡å‡†æ ·ï¼ˆæ¨è GCï¼‰åš K å› å­æ ‡å®šã€‚
2. Tab2ï¼šæŠŠ 2D å›¾åƒæ‰¹å¤„ç†æˆç»å¯¹å¼ºåº¦ 1D ç»“æœï¼ˆå«è¯¯å·®åˆ—ï¼‰ã€‚
3. Tab3ï¼šæŠŠå¤–éƒ¨è½¯ä»¶ç§¯åˆ†åçš„ 1D ç›¸å¯¹å¼ºåº¦æ‰¹é‡è½¬æ¢ä¸ºç»å¯¹å¼ºåº¦ã€‚
4. è¾“å‡ºåŒ…å«æŠ¥å‘Šæ–‡ä»¶ï¼Œä¾¿äºå¤ç°å®éªŒæµç¨‹ã€‚

----------------------------------------
[äºŒ] ç¬¬ä¸€æ¬¡ä½¿ç”¨çš„æœ€çŸ­è·¯å¾„ï¼ˆå»ºè®®æŒ‰é¡ºåºï¼‰
----------------------------------------
Step 1. å…ˆåš Tab1 æ ‡å®šï¼ˆåªéœ€ä¸€ç»„ Std/BG/Dark/poniï¼‰
1) é€‰æ‹©æ–‡ä»¶ï¼šæ ‡å‡†æ ·ã€èƒŒæ™¯ã€æš—åœºã€poniã€‚
2) æ£€æŸ¥ Time/I0/T æ˜¯å¦è‡ªåŠ¨å¸¦å…¥æ­£ç¡®ï¼ˆå¿…è¦æ—¶æ‰‹å·¥æ”¹ï¼‰ã€‚
3) é€‰æ‹© I0 è¯­ä¹‰ï¼š
   - rateï¼šI0 æ˜¯æ¯ç§’è®¡æ•°ç‡ï¼Œå½’ä¸€åŒ–ç”¨ exp * I0 * T
   - integratedï¼šI0 æ˜¯ç§¯åˆ†è®¡æ•°ï¼Œå½’ä¸€åŒ–ç”¨ I0 * T
4) å¡«æ ‡å‡†æ ·åšåº¦(mm)ï¼Œç‚¹å‡»â€œè¿è¡Œ K å› å­æ ‡å®šâ€ã€‚
5) é‡ç‚¹çœ‹æŠ¥å‘Šä¸­çš„ï¼š
   - Points Usedï¼ˆè¶Šå¤šè¶Šç¨³ï¼‰
   - Std Devï¼ˆè¶Šå°è¶Šç¨³ï¼‰
   - Q overlapï¼ˆè¦æœ‰è¶³å¤Ÿé‡å åŒºé—´ï¼‰
6) æ ‡å®šæˆåŠŸåï¼ŒK ä¼šè‡ªåŠ¨å†™å…¥å…¨å±€å¹¶ä¿å­˜å†å²ã€‚

Step 2. å†åš Tab2 æ‰¹å¤„ç†
1) ç¡®è®¤ K å› å­ > 0ï¼›BG/Dark/poni è·¯å¾„æ­£ç¡®ã€‚
2) é€‰æ‹©åšåº¦ç­–ç•¥ï¼š
   - è‡ªåŠ¨åšåº¦ï¼šd = -ln(T)/mu
   - å›ºå®šåšåº¦ï¼šæ‰€æœ‰æ ·å“åŒä¸€åšåº¦
3) é€‰æ‹©ç§¯åˆ†æ¨¡å¼ï¼ˆå¯å¤šé€‰ï¼‰ï¼š
   - I-Q å…¨ç¯
   - I-Q æ‰‡åŒºï¼ˆæ”¯æŒå¤šæ‰‡åŒºï¼šå¦‚ -25~25;45~65ï¼‰
   - I-chi ç»‡æ„ï¼ˆq åŒºé—´ï¼‰
4) é€‰æ‹©ä¿®æ­£é¡¹ï¼ˆæ¨èï¼‰ï¼š
   - å¼€å¯ Solid Angle
   - è¯¯å·®æ¨¡å‹é€‰ azimuthalï¼ˆå¸¸ç”¨ï¼‰
   - æœ‰æ©è†œå°±åŠ è½½ Mask
   - æ³¨æ„ï¼šTab2 çš„ Solid Angle å¿…é¡»ä¸ Tab1 æ ‡å®šæ—¶ä¸€è‡´ï¼Œå¦åˆ™ K å› å­ä¸å¯ç›´æ¥ä½¿ç”¨
5) å‚è€ƒæ¨¡å¼ï¼š
   - å›ºå®š BG/Darkï¼ˆæ–°æ‰‹æ¨èï¼Œæœ€ç¨³å®šï¼‰
   - è‡ªåŠ¨åŒ¹é… BG/Darkï¼ˆé«˜çº§ç”¨æ³•ï¼‰
6) å…ˆç‚¹â€œé¢„æ£€æŸ¥â€ï¼Œç¡®è®¤æ²¡æœ‰å…³é”®è­¦å‘Šã€‚
7) å¦‚éœ€é›†ä¸­ç®¡ç†ç»“æœï¼Œå¯åœ¨åº•éƒ¨â€œè¾“å‡ºæ ¹ç›®å½•â€æŒ‡å®šè‡ªå®šä¹‰è·¯å¾„ã€‚
8) ç‚¹å‡»â€œå¼€å§‹ç¨³å¥æ‰¹å¤„ç†â€ã€‚

Step 3. å¦‚æœä½ å·²åœ¨å¤–éƒ¨è½¯ä»¶å®Œæˆç§¯åˆ†ï¼ˆå¯é€‰ï¼‰
1) è¿›å…¥ Tab3ï¼Œå¯¼å…¥å¤–éƒ¨ 1D æ–‡ä»¶ï¼ˆ.dat/.txt/.chi/.csvï¼‰ã€‚
2) é€‰æ‹©æµç¨‹ï¼š
   - ä»…æ¯”ä¾‹ç¼©æ”¾ï¼šå¤–éƒ¨1Då·²å®Œæˆæœ¬åº•/å½’ä¸€åŒ–
   - åŸå§‹1Då®Œæ•´æ ¡æ­£ï¼šå¤–éƒ¨1Dæ˜¯åŸå§‹ç§¯åˆ†ç»“æœï¼Œéœ€è¦æä¾› BG1D/Dark1D å’Œ exp/I0/T
   - metadata æ¥æºä¼˜å…ˆçº§ï¼šmetadata.csv > æ–‡ä»¶æ³¨é‡Šå¤´ > Tab3 å›ºå®šå‚æ•°
   - BGå›ºå®šå‚æ•°é»˜è®¤è·Ÿéš Tab1 å…¨å±€ï¼›å¯å–æ¶ˆâ€œBGå‚æ•°è·Ÿéšâ€åæ‰‹åŠ¨è¦†ç›–
   - metadata.csv å¯ä»¥ç›´æ¥ç”¨ Tab2 çš„ batch_report.csvï¼Œæˆ–ç‚¹â€œç”± Tab2 æŠ¥å‘Šç”Ÿæˆ metadataâ€
3) é€‰æ‹©å…¬å¼ï¼š
   - K/dï¼šå¤–éƒ¨ 1D è¿˜æœªé™¤åšåº¦
   - Kï¼šå¤–éƒ¨ 1D å·²é™¤åšåº¦
4) å…ˆé¢„æ£€æŸ¥ï¼Œå†æ‰¹é‡è¿è¡Œã€‚
5) å¦‚éœ€é›†ä¸­ç®¡ç†ç»“æœï¼Œå¯åœ¨åº•éƒ¨â€œè¾“å‡ºæ ¹ç›®å½•â€æŒ‡å®šè‡ªå®šä¹‰è·¯å¾„ã€‚

----------------------------------------
[ä¸‰] æ ¸å¿ƒå‚æ•°è§£é‡Šï¼ˆæ–°æ‰‹å¿…çœ‹ï¼‰
----------------------------------------
1) Time(s)
   æ›å…‰æ—¶é—´ã€‚è‹¥ I0 è¯­ä¹‰æ˜¯ rateï¼ŒTime ä¼šå‚ä¸å½’ä¸€åŒ–ï¼›è‹¥æ˜¯ integratedï¼Œä¸å‚ä¸ã€‚

2) I0(Mon)
   å…¥å°„å¼ºåº¦ç›‘æµ‹å€¼ã€‚è¯·ç¡®è®¤æ˜¯â€œè®¡æ•°ç‡â€è¿˜æ˜¯â€œç§¯åˆ†è®¡æ•°â€ï¼Œå¹¶ä¸ I0 è¯­ä¹‰ä¸€è‡´ã€‚

3) Trans(T)
   é€è¿‡ç‡ï¼Œæ¨èèŒƒå›´ (0, 1]ã€‚
   ç¨‹åºä¼šå¯¹ 1~2 çš„å€¼åšä¿æŠ¤å¤„ç†ï¼ˆè§†ä¸ºæ¼‚ç§»å¹¶å¤¹åˆ° 1.0ï¼‰ï¼Œ
   ä»…å¯¹æ˜ç¡®ç™¾åˆ†å·æˆ–æ˜æ˜¾ç™¾åˆ†æ•°å­—é¢é‡ï¼ˆ>2ï¼‰æ‰æŒ‰ç™¾åˆ†æ•°æ¢ç®—ã€‚

4) muï¼ˆè‡ªåŠ¨åšåº¦æ¨¡å¼ï¼‰
   å•ä½ cm^-1ã€‚mu é”™ä¼šå¯¼è‡´åšåº¦å’Œç»å¯¹å¼ºåº¦æ•´ä½“åå·®ã€‚

5) Polarization
   èŒƒå›´ [-1, 1]ã€‚ä¸ç¡®å®šæ—¶å…ˆç”¨ 0ã€‚

6) æ‰‡åŒºè§’åº¦ï¼ˆTab2 azimuth_rangeï¼‰
   ç¨‹åºä½¿ç”¨ pyFAI chi å®šä¹‰ï¼š
   - 0Â° å‘å³
   - +90Â° å‘ä¸‹
   - -90Â° å‘ä¸Š
   - Â±180Â° å‘å·¦
   æ”¯æŒè·¨ Â±180Â° æ‰‡åŒºï¼Œä¾‹å¦‚ sec_min=170, sec_max=-170ã€‚
   å¤šæ‰‡åŒºå¯åœ¨â€œå¤šæ‰‡åŒºâ€ä¸­å†™ä¸º `-25~25;45~65`ï¼ˆç•™ç©ºåˆ™ä½¿ç”¨å•æ‰‡åŒºè¾“å…¥æ¡†ï¼‰ã€‚
   å¯ç‚¹å‡»â€œé¢„è§ˆI-Qâ€åœ¨2Då›¾ä¸Šç¡®è®¤å…¨ç¯/å¤šæ‰‡åŒºç§¯åˆ†åŒºåŸŸã€‚

----------------------------------------
[å››] ç¨‹åºå†…ç½®çš„é˜²é”™æœºåˆ¶ï¼ˆä½ ä¼šçœ‹åˆ°çš„å‘Šè­¦ï¼‰
----------------------------------------
1) BG_Norm ä¸æ ·å“ Norm_s é‡çº§å¼‚å¸¸
   è‹¥å·®å¼‚è¿‡å¤§ï¼Œå›ºå®š BG æ¨¡å¼ä¼šç›´æ¥é˜»æ–­ï¼Œé¿å…â€œè¿‡æ‰£èƒŒæ™¯å¯¼è‡´å…¨è´Ÿå€¼â€ã€‚

2) ç§¯åˆ†ç»“æœå¥åº·æ£€æŸ¥
   è‹¥æŸæ¡è¾“å‡ºå‡ ä¹å…¨ä¸ºéæ­£å€¼ï¼Œæ¨¡å¼ä¼šè¢«åˆ¤å¤±è´¥å¹¶æç¤ºæ£€æŸ¥å½’ä¸€åŒ–/BGã€‚

3) ä»ªå™¨ä¸€è‡´æ€§æ£€æŸ¥
   å¯æ£€æŸ¥èƒ½é‡ã€æ³¢é•¿ã€è·ç¦»ã€åƒç´ ã€å°ºå¯¸æ˜¯å¦ä¸€è‡´ã€‚

----------------------------------------
[äº”] å¸¸è§é—®é¢˜ä¸å¤„ç†
----------------------------------------
Q1ï¼šæ•´æ¡æ›²çº¿å‡ ä¹å…¨è´Ÿï¼Ÿ
A1ï¼š
  - å…ˆçœ‹ batch_report é‡Œçš„ Norm_s å’Œ BG_Norm æ˜¯å¦åŒé‡çº§ã€‚
  - æ£€æŸ¥ BG çš„ Time/I0/T æ˜¯å¦å¡«å†™æ­£ç¡®ã€‚
  - æ£€æŸ¥ I0 è¯­ä¹‰ï¼ˆrate/integratedï¼‰æ˜¯å¦é€‰é”™ã€‚
  - ç”¨â€œå›ºå®š BG/Dark + é¢„æ£€æŸ¥â€å…ˆè·‘é€šã€‚

Q2ï¼šä¸ºä»€ä¹ˆç¨‹åºæç¤ºç¼ºå°‘ exp/mon/transï¼Ÿ
A2ï¼š
  - å¤´å­—æ®µæ²¡è¯»åˆ°æˆ–å‘½åä¸æ ‡å‡†ã€‚
  - å¯æ‰‹å·¥åœ¨ç•Œé¢å¡«å…¥å‚æ•°ï¼ˆå°¤å…¶æ˜¯ Tab1ï¼‰ã€‚
  - å»ºè®®å…ˆç”¨å°‘é‡æ ·å“ dry_run éªŒè¯ã€‚

Q3ï¼šI-chi ç»“æœçœ‹èµ·æ¥ä¸å¯¹ï¼Ÿ
A3ï¼š
  - æ£€æŸ¥ qmin/qmax æ˜¯å¦åˆç†ã€‚
  - ç¨‹åºå·²å¯¹ radial q å•ä½åšå…¼å®¹å¤„ç†ï¼Œä½†ä»éœ€ç¡®è®¤ q åŒºé—´ä¸ç‰©ç†é¢„æœŸä¸€è‡´ã€‚
  - å¯ç‚¹å‡»â€œé¢„è§ˆI-chiâ€åœ¨2Då›¾ä¸Šæ ¸å¯¹ q ç¯å¸¦èŒƒå›´ã€‚

Q4ï¼šOrigin å¯¼å…¥ä¸æ–¹ä¾¿ï¼Ÿ
A4ï¼š
  - å½“å‰è¾“å‡ºæ˜¯è¡¨å¤´+åˆ¶è¡¨ç¬¦æ ¼å¼ï¼ˆTSVé£æ ¼ï¼‰ï¼Œåˆ—ååŒ…å«åæ ‡ã€I_absã€Errorï¼Œç›´æ¥æŒ‰åˆ—å¯¼å…¥ã€‚

Q5ï¼špyFAI å¯¼å‡ºçš„ 1D æ–‡ä»¶èƒ½ç›´æ¥è¯»å‡º exp/I0/T å—ï¼Ÿ
A5ï¼š
  - å¤šæ•°æƒ…å†µä¸‹åªèƒ½ç¨³å®šè¯»å‡º X/I/(å¯é€‰Error) åˆ—ã€‚
  - exp/I0/T æ˜¯å¦å¯è¯»ï¼Œå–å†³äºæ–‡ä»¶æ³¨é‡Šå¤´æ˜¯å¦å†™å…¥äº†è¿™äº›å­—æ®µã€‚
  - ç¨‹åºä¼šå°è¯•ä»æ³¨é‡Šå¤´è¯»å–ï¼›è‹¥è¯»ä¸åˆ°ï¼Œè¯·æä¾› metadata CSV æˆ–å›ºå®šå‚æ•°ã€‚

Q6ï¼šmetadata.csv ä»å“ªæ¥ï¼Ÿ
A6ï¼š
  - æ¨èç›´æ¥ä½¿ç”¨ Tab2 è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤æ ·å“ç›®å½•ï¼Œæˆ–ä½ è®¾ç½®çš„è‡ªå®šä¹‰è¾“å‡ºæ ¹ç›®å½•ï¼‰`processed_robust_reports` ä¸­è‡ªåŠ¨ç”Ÿæˆçš„ï¼š
    `metadata_for_tab3_*.csv` æˆ– `metadata.csv`ã€‚
  - ä¹Ÿå¯åœ¨ Tab3 ç‚¹â€œç”± Tab2 æŠ¥å‘Šç”Ÿæˆ metadataâ€ï¼Œä» `batch_report_*.csv` ä¸€é”®ç”Ÿæˆã€‚

Q7ï¼šTab2 æ‰‡åŒºè§’åº¦ä¸ç¡®å®šæ€ä¹ˆåŠï¼Ÿ
A7ï¼š
  - åœ¨ Tab2 æ‰‡åŒºè¾“å…¥æ¡†æ—ç‚¹å‡»â€œé¢„è§ˆI-Qâ€ã€‚
  - å¼¹çª—ä¼šå åŠ å•æ‰‡åŒº/å¤šæ‰‡åŒºæ©è†œä¸è¾¹ç•Œçº¿ï¼Œå¹¶æ˜¾ç¤ºè§’åº¦å®šä¹‰ï¼ˆ0Â°å³ã€+90Â°ä¸‹ï¼‰ã€‚

----------------------------------------
[å…­] è¾“å‡ºæ–‡ä»¶è¯´æ˜
----------------------------------------
1) Tab1 è¾“å‡º
   - calibration_check.csvï¼šæ ‡å®šåçš„å‚è€ƒæ›²çº¿ï¼ˆå«è¯¯å·®åˆ—ï¼‰
   - k_factor_history.csvï¼šK å†å²ä¸å…³é”®å‚æ•°

2) Tab2 è¾“å‡º
   ï¼ˆæ ¹ç›®å½•é»˜è®¤åœ¨æ ·å“ç›®å½•ï¼Œä¹Ÿå¯åœ¨ Tab2 åº•éƒ¨è‡ªå®šä¹‰ï¼‰
   - processed_robust_1d_full/*.dat
   - processed_robust_1d_sector/*.datï¼ˆå•æ‰‡åŒºï¼‰
   - processed_robust_1d_sector/sector_*/*.datï¼ˆå¤šæ‰‡åŒºåˆ†åˆ«ä¿å­˜ï¼‰
   - processed_robust_1d_sector_combined/*.datï¼ˆæ‰‡åŒºåˆå¹¶ä¿å­˜ï¼Œè‹¥å‹¾é€‰ï¼‰
   - processed_robust_radial_chi/*.chi
   æ¯ä¸ªæ–‡ä»¶å‡ä¸ºï¼šåæ ‡åˆ— + I_abs_cm^-1 + Error_cm^-1
   - processed_robust_reports/batch_report_*.csv
   - processed_robust_reports/metadata_for_tab3_*.csv
   - processed_robust_reports/metadata.csv
   - processed_robust_reports/run_meta_*.json

3) Tab3 è¾“å‡º
   ï¼ˆæ ¹ç›®å½•é»˜è®¤åœ¨é¦–ä¸ªè¾“å…¥æ–‡ä»¶ç›®å½•ï¼Œä¹Ÿå¯åœ¨ Tab3 åº•éƒ¨è‡ªå®šä¹‰ï¼‰
   - processed_external_1d_abs/*.dat æˆ– *.chi
   - processed_external_1d_reports/external1d_report_*.csv
   - processed_external_1d_reports/external1d_meta_*.json

----------------------------------------
[ä¸ƒ] æ–°æ‰‹æ‰§è¡Œæ£€æŸ¥æ¸…å•ï¼ˆæ¯æ¬¡å¼€è·‘å‰ï¼‰
----------------------------------------
[ ] K å› å­æ¥è‡ªæœ€è¿‘ä¸€æ¬¡å¯ä¿¡æ ‡å®šï¼ˆTab1ï¼‰
[ ] I0 è¯­ä¹‰ç¡®è®¤æ— è¯¯ï¼ˆrate æˆ– integratedï¼‰
[ ] BG/Dark/poni æ¥è‡ªåŒä¸€å®éªŒæ¡ä»¶
[ ] å…ˆåšé¢„æ£€æŸ¥ï¼ˆdry_runï¼‰å†æ­£å¼æ‰¹å¤„ç†
[ ] çœ‹ batch_reportï¼šæˆåŠŸ/å¤±è´¥åŸå› æ˜¯å¦åˆç†

----------------------------------------
[å…«] æ¨èå·¥ä½œä¹ æƒ¯ï¼ˆå‡å°‘è¿”å·¥ï¼‰
----------------------------------------
1) å…ˆç”¨ 3~5 ä¸ªæ ·å“è¯•è·‘ï¼Œç¡®è®¤æµç¨‹æ­£ç¡®å†å…¨é‡è·‘ã€‚
2) æ‰¹å¤„ç†æ—¶ä¼˜å…ˆå¼€å¯æ–­ç‚¹ç»­è·‘ï¼Œé¿å…ä¸­æ–­åé‡ç®—å…¨éƒ¨ã€‚
3) æ¯æ‰¹æ¬¡ä¿ç•™ run_meta ä¸ batch_reportï¼Œæ–¹ä¾¿è¿½æº¯ä¸å®¡ç¨¿è¯´æ˜ã€‚

ï¼ˆå¸®åŠ©é¡µç‰ˆæœ¬ï¼šv2ï¼Œé€‚é… Tab2->Tab3 ç›´è¿ metadata æµç¨‹ï¼‰
"""

        help_text_zh = help_text.strip() + "\n"

        if self.language == "en":
            help_text = """
==============================
SAXSAbs Workbench User Guide
==============================

[1] What this program does
1. Tab1: estimate K factor using a standard sample (GC recommended).
2. Tab2: batch-process 2D images into absolute-intensity 1D outputs with error columns.
3. Tab3: convert external 1D relative intensities into absolute intensities.
4. Export reports for reproducibility and audit.

[2] Minimal first-use workflow
1) Run Tab1 calibration with Std/BG/Dark/poni.
2) Verify Time/I0/T and monitor mode (rate or integrated).
3) Run robust K calibration and check Points Used, Std Dev, and Q overlap.
4) Go to Tab2 for batch processing; run dry-check before full run.
5) Use Tab3 only when external 1D conversion is needed.

[3] Critical checks before batch runs
- K factor is valid and recent.
- BG/Dark/poni are from compatible conditions.
- Dry-check reports no critical warnings.
- Monitor mode matches beamline data semantics.

[4] Outputs
- Tab1: calibration_check.csv, k_factor_history.csv
- Tab2: processed_robust_* and batch_report/metadata/run_meta
- Tab3: processed_external_1d_abs and external1d_report/meta

For advanced details, keep the Chinese help mode or refer to repository docs.
"""

        self.help_text_widget = txt
        self.help_text_content_zh = help_text_zh
        self.help_text_content = help_text.strip() + "\n"
        txt.insert(tk.END, self.help_text_content)
        txt.config(state="disabled")

        def copy_help():
            self.root.clipboard_clear()
            self.root.clipboard_append(self.help_text_content)
            self.root.update()
            self.show_info("msg_help_title", self.tr("msg_help_copied"))

        btn_copy = ttk.Button(bar, text=self.tr("help_copy_btn"), command=copy_help)
        self._register_i18n_widget(btn_copy, "help_copy_btn")
        btn_copy.pack(side="right")
        self.add_tooltip(btn_copy, self.tr("help_copy_tooltip"))

    def refresh_help_text(self):
        txt = getattr(self, "help_text_widget", None)
        if txt is None:
            return
        if self.language == "en":
            content = """
==============================
SAXSAbs Workbench User Guide
==============================

[1] What this program does
1. Tab1: estimate K factor using a standard sample (GC recommended).
2. Tab2: batch-process 2D images into absolute-intensity 1D outputs with error columns.
3. Tab3: convert external 1D relative intensities into absolute intensities.
4. Export reports for reproducibility and audit.

[2] Minimal first-use workflow
1) Run Tab1 calibration with Std/BG/Dark/poni.
2) Verify Time/I0/T and monitor mode (rate or integrated).
3) Run robust K calibration and check Points Used, Std Dev, and Q overlap.
4) Go to Tab2 for batch processing; run dry-check before full run.
5) Use Tab3 only when external 1D conversion is needed.

[3] Critical checks before batch runs
- K factor is valid and recent.
- BG/Dark/poni are from compatible conditions.
- Dry-check reports no critical warnings.
- Monitor mode matches beamline data semantics.

[4] Outputs
- Tab1: calibration_check.csv, k_factor_history.csv
- Tab2: processed_robust_* and batch_report/metadata/run_meta
- Tab3: processed_external_1d_abs and external1d_report/meta

For advanced details, keep the Chinese help mode or refer to repository docs.
""".strip() + "\n"
        else:
            content = getattr(self, "help_text_content_zh", "")
        txt.config(state="normal")
        txt.delete("1.0", tk.END)
        txt.insert(tk.END, content)
        txt.config(state="disabled")
        self.help_text_content = content

    # =========================================================================
    # Logic: K-Calibration (ROBUST + Error)
    # =========================================================================
    def run_calibration(self):
        try:
            files = {k: v.get() for k, v in self.t1_files.items()}
            if not all(files.values()): raise ValueError("æ–‡ä»¶ä¸å®Œæ•´ï¼šè¯·å…ˆé€‰æ‹©æ ‡å‡†æ ·ã€èƒŒæ™¯ã€æš—åœºå’Œ poniã€‚")
            p = {k: v.get() for k, v in self.t1_params.items()}
            if p["std_thk"] <= 0: raise ValueError("æ ‡å‡†æ ·åšåº¦å¿…é¡» > 0 mmã€‚")
            monitor_mode = self.get_monitor_mode()
            apply_solid_angle = bool(self.global_vars["apply_solid_angle"].get())

            self.report(self.tr("rpt_start_calib"))
            self.report(self.tr("rpt_i0_norm_mode").format(mode=monitor_mode, formula=self.monitor_norm_formula(monitor_mode)))
            self.report(self.tr("rpt_solid_angle").format(state='ON' if apply_solid_angle else 'OFF'))
            
            ai = pyFAI.load(files["poni"])
            d_std = fabio.open(files["std"]).data.astype(np.float64)
            d_dark = fabio.open(files["dark"]).data.astype(np.float64)
            self._assert_same_shape(d_std, d_dark, "std", "dark")

            bg_paths = self.split_path_list(files["bg"])
            if not bg_paths:
                raise ValueError("æœªæä¾›èƒŒæ™¯å›¾åƒã€‚")

            # --- 2D Subtraction (Physics Correct) ---
            norm_std = self.compute_norm_factor(
                p["std_exp"], p["std_i0"], p["std_t"], monitor_mode
            )
            bg_net, bg_norms, bg_used_paths = self.build_composite_bg_net(
                bg_paths=bg_paths,
                d_dark=d_dark,
                monitor_mode=monitor_mode,
                fallback_triplet=(p["bg_exp"], p["bg_i0"], p["bg_t"]),
                ref_shape=d_std.shape,
            )
            norm_bg = float(np.nanmedian(np.asarray(bg_norms, dtype=np.float64)))
            
            if norm_std <= 0 or norm_bg <= 0: raise ValueError("å½’ä¸€åŒ–å› å­ <= 0ï¼Œè¯·æ£€æŸ¥ Time/I0/Tã€‚")
            norm_ratio = norm_bg / max(norm_std, 1e-12)
            if norm_ratio < 0.01 or norm_ratio > 100.0:
                self.report(
                    f"[è­¦å‘Š] æ ‡å®šä¸­ BG_Norm ä¸ Std_Norm é‡çº§å·®å¼‚è¿‡å¤§ "
                    f"(BG/Std={norm_ratio:.3g})ï¼Œè¯·å¤æ ¸ BG çš„ Time/I0/T ä¸ I0 è¯­ä¹‰ã€‚"
                )
            
            # Net Signal 2D (Intensity/sec/unit_flux)
            img_net = (d_std - d_dark)/norm_std - bg_net
            
            # Integrate (Enable Error Propagation via Azimuthal Variance)
            # error_model="azimuthal" computes the sigma (std dev) of pixels in bin
            res = ai.integrate1d(
                img_net,
                1000,
                unit="q_A^-1",
                error_model="azimuthal",
                correctSolidAngle=apply_solid_angle,
            )

            q = np.asarray(res.radial, dtype=np.float64)
            i_1d = np.asarray(res.intensity, dtype=np.float64)
            if q.size < 3:
                raise ValueError("ç§¯åˆ†ç»“æœç‚¹æ•°è¿‡å°‘ï¼Œæ— æ³•å®Œæˆæ ‡å®šã€‚")

            thk_cm = p["std_thk"] / 10.0
            i_net_vol = i_1d / thk_cm

            # Extract Error (Azimuthal StdDev scaled by thickness)
            if getattr(res, "sigma", None) is None:
                sigma_net_vol = np.full_like(i_net_vol, np.nan)
            else:
                sigma_net_vol = np.asarray(res.sigma, dtype=np.float64) / thk_cm
            
            q_ref, i_ref = self._get_std_reference_data()
            std_key = self.t1_std_type.get()
            is_water = (std_key == "Water_20C")

            if is_water:
                # Water: flat signal â€” use median in q_window
                q_lo_w, q_hi_w = 0.01, 0.2
                win_mask = (q >= q_lo_w) & (q <= q_hi_w) & np.isfinite(i_net_vol) & (i_net_vol > 1e-9)
                if win_mask.sum() < 3:
                    raise ValueError("q çª—å£å†…æµ‹é‡ä¿¡å·ä¸è¶³ï¼Œæ— æ³•ç”¨æ°´æ ‡å‡†æ ‡å®šã€‚")
                water_dsdw_val = float(i_ref[0])  # flat value
                ratios = water_dsdw_val / np.asarray(i_net_vol[win_mask], dtype=np.float64)
                ratios = ratios[np.isfinite(ratios) & (ratios > 0)]
                if ratios.size < 3:
                    raise ValueError("æ°´æ ‡å‡†æœ‰æ•ˆæ¯”å€¼ç‚¹æ•°ä¸è¶³ï¼Œæ— æ³•ç¨³å¥ä¼°è®¡ Kã€‚")
                r_med = float(np.nanmedian(ratios))
                r_mad = float(np.nanmedian(np.abs(ratios - r_med)))
                ratios_used = ratios
                if np.isfinite(r_mad) and r_mad > 0:
                    robust_sigma = 1.4826 * r_mad
                    inlier = np.abs(ratios - r_med) <= 3.0 * robust_sigma
                    if int(np.sum(inlier)) >= 3:
                        ratios_used = ratios[inlier]
                k_val = float(np.nanmedian(ratios_used))
                k_std = float(np.nanstd(ratios_used))
                q_min = float(q[win_mask][0])
                q_max = float(q[win_mask][-1])
                points_total = int(win_mask.sum())
            else:
                # Normal q-I curve standard (SRM3600, Lupolen, Custom)
                mask_w = (q_ref >= 0.01) & (q_ref <= 0.2)
                q_ref_w = q_ref[mask_w] if mask_w.any() else q_ref
                i_ref_w = i_ref[mask_w] if mask_w.any() else i_ref
                q_min = max(np.nanmin(q), np.nanmin(q_ref_w))
                q_max = min(np.nanmax(q), np.nanmax(q_ref_w))
                q_mask = (q_ref_w >= q_min) & (q_ref_w <= q_max)
                q_ref_used = q_ref_w[q_mask]
                i_ref_used = i_ref_w[q_mask]
                if q_ref_used.size < 3:
                    raise ValueError("ä¸å‚è€ƒæ›²çº¿çš„ q é‡å åŒºé—´ä¸è¶³ï¼Œæ— æ³•å¯é æ ‡å®šã€‚")

                if estimate_k_factor_robust is not None:
                    k_res = estimate_k_factor_robust(
                        q_meas=q,
                        i_meas_per_cm=i_net_vol,
                        q_ref=q_ref_used,
                        i_ref=i_ref_used,
                        q_window=(float(np.nanmin(q_ref_used)), float(np.nanmax(q_ref_used))),
                        positive_floor=1e-9,
                        min_points=3,
                    )
                    k_val = float(k_res.k_factor)
                    k_std = float(k_res.k_std)
                    q_min = float(k_res.q_min_overlap)
                    q_max = float(k_res.q_max_overlap)
                    ratios_used = np.asarray(k_res.ratios_used, dtype=np.float64)
                    points_total = int(k_res.points_total)
                else:
                    i_meas_interp = np.interp(q_ref_used, q, i_net_vol)
                    valid_idx = np.isfinite(i_meas_interp) & (i_meas_interp > 1e-9)
                    if np.sum(valid_idx) < 3:
                        raise ValueError("æ‰£èƒŒæ™¯åä¿¡å·è¿‡å¼±æˆ–ä¸ºè´Ÿï¼Œæ— æ³•æ ‡å®šã€‚")
                    ratios = i_ref_used[valid_idx] / i_meas_interp[valid_idx]
                    ratios = ratios[np.isfinite(ratios) & (ratios > 0)]
                    if ratios.size < 3:
                        raise ValueError("æœ‰æ•ˆæ¯”å€¼ç‚¹æ•°ä¸è¶³ï¼Œæ— æ³•ç¨³å¥ä¼°è®¡ Kã€‚")
                    r_med = np.nanmedian(ratios)
                    r_mad = np.nanmedian(np.abs(ratios - r_med))
                    ratios_used = ratios
                    if np.isfinite(r_mad) and r_mad > 0:
                        robust_sigma = 1.4826 * r_mad
                        inlier = np.abs(ratios - r_med) <= 3.0 * robust_sigma
                        if np.sum(inlier) >= 3:
                            ratios_used = ratios[inlier]
                    k_val = np.nanmedian(ratios_used)
                    k_std = np.nanstd(ratios_used)
                    points_total = len(q_ref_used)

            if k_val <= 0: raise ValueError(f"è®¡ç®—å¾—åˆ°çš„ K <= 0 ({k_val})ï¼Œè¯·æ£€æŸ¥æœ¬åº•ç¼©æ”¾å’Œå‚æ•°ã€‚")

            self.global_vars["k_factor"].set(k_val)
            self.global_vars["k_solid_angle"].set("on" if apply_solid_angle else "off")
            
            # Report
            self.report("-" * 30)
            self.report(self.tr("rpt_calib_ok"))
            self.report(f"K-Factor: {k_val:.4f}")
            self.report(f"Q overlap : {q_min:.4f} to {q_max:.4f} A^-1")
            self.report(f"Points Used: {len(ratios_used)}/{points_total}")
            self.report(f"BG files used: {len(bg_used_paths)}")
            rel_std = (k_std / k_val * 100) if k_val != 0 else np.nan
            self.report(f"Std Dev : {k_std:.4f} ({rel_std:.1f}%)")
            self.report("-" * 30)
            
            # Plot
            self.ax1.clear()
            self.ax1.loglog(q, i_net_vol, 'k--', alpha=0.4, label="Measured Net")
            self.ax1.loglog(q, i_net_vol * k_val, 'b-', label="Corrected")
            std_label = STANDARD_REGISTRY[std_key].name if (STANDARD_REGISTRY and std_key in STANDARD_REGISTRY) else std_key
            if not is_water:
                self.ax1.loglog(q_ref, i_ref, 'ro', mfc='none', label=std_label)
            else:
                self.ax1.axhline(float(i_ref[0]), color='r', ls='--', alpha=0.6, label=std_label)
            self.ax1.set_xlabel("q ($A^{-1}$)")
            self.ax1.set_ylabel("Absolute Intensity ($cm^{-1}$)")
            self.ax1.set_title(f"K={k_val:.2f}")
            self.ax1.legend()
            self.canvas1.draw()
            
            # Save Check File with Error
            save_path = Path(files["std"]).parent / "calibration_check.csv"
            # We save the full profile with error bars
            df = pd.DataFrame({
                "Q": q,
                "I_Abs": i_net_vol * k_val,
                "Error": sigma_net_vol * k_val
            })
            df.to_csv(save_path, index=False)
            self.report(f"Saved profile: {save_path.name}")

            self.append_k_history(
                files=files,
                params=p,
                monitor_mode=monitor_mode,
                apply_solid_angle=apply_solid_angle,
                k_val=k_val,
                k_std=k_std,
                points_used=len(ratios_used),
                q_min=q_min,
                q_max=q_max,
            )
            self.report("K history updated.")
            
        except Exception as e:
            self.show_error("msg_calib_error_title", str(e))
            self.report(f"[ERROR] {str(e)}")

    def append_k_history(self, files, params, monitor_mode, apply_solid_angle, k_val, k_std, points_used, q_min, q_max):
        hist_path = Path(__file__).resolve().parent / "k_factor_history.csv"
        std_norm = self.compute_norm_factor(
            params.get("std_exp", np.nan),
            params.get("std_i0", np.nan),
            params.get("std_t", np.nan),
            monitor_mode,
        )
        bg_norm = self.compute_norm_factor(
            params.get("bg_exp", np.nan),
            params.get("bg_i0", np.nan),
            params.get("bg_t", np.nan),
            monitor_mode,
        )
        row = {
            "Timestamp": datetime.datetime.now().isoformat(timespec="seconds"),
            "Norm_Mode": monitor_mode,
            "Norm_Formula": self.monitor_norm_formula(monitor_mode),
            "SolidAngle_On": bool(apply_solid_angle),
            "K_Factor": float(k_val),
            "K_Std": float(k_std),
            "RelStd_pct": float((k_std / k_val * 100) if k_val else np.nan),
            "PointsUsed": int(points_used),
            "Q_Min": float(q_min),
            "Q_Max": float(q_max),
            "Std_File": files.get("std", ""),
            "BG_File": files.get("bg", ""),
            "Dark_File": files.get("dark", ""),
            "Poni_File": files.get("poni", ""),
            "Std_Thk_mm": float(params.get("std_thk", np.nan)),
            "Std_Norm": float(std_norm) if np.isfinite(std_norm) else np.nan,
            "BG_Norm": float(bg_norm) if np.isfinite(bg_norm) else np.nan,
        }
        df_row = pd.DataFrame([row])
        if hist_path.exists():
            try:
                old = pd.read_csv(hist_path)
                out = pd.concat([old, df_row], ignore_index=True)
            except Exception:
                out = df_row
        else:
            out = df_row
        out.to_csv(hist_path, index=False, encoding="utf-8-sig")

    def open_k_history(self):
        hist_path = Path(__file__).resolve().parent / "k_factor_history.csv"
        if not hist_path.exists():
            self.show_info("msg_k_history_title", self.tr("msg_k_history_empty"))
            return

        try:
            df = pd.read_csv(hist_path)
            if df.empty:
                self.show_info("msg_k_history_title", self.tr("msg_k_history_file_empty"))
                return
        except Exception as e:
            self.show_error("msg_k_history_title", self.tr("msg_k_history_read_error").format(e=e))
            return

        top = tk.Toplevel(self.root)
        top.title(self.tr("title_k_history"))
        top.geometry("980x640")

        upper = ttk.Frame(top)
        upper.pack(fill="both", expand=True)
        lower = ttk.Frame(top)
        lower.pack(fill="both", expand=True)

        fig = Figure(figsize=(7.2, 3.4), dpi=100)
        ax = fig.add_subplot(111)
        x = np.arange(len(df))
        y = pd.to_numeric(df["K_Factor"], errors="coerce").to_numpy(dtype=np.float64)
        e = pd.to_numeric(df.get("K_Std", np.nan), errors="coerce").to_numpy(dtype=np.float64)

        if np.any(np.isfinite(e)):
            ax.errorbar(x, y, yerr=e, fmt="o-", capsize=3, label="K Â± Std")
        else:
            ax.plot(x, y, "o-", label="K")
        ax.set_xlabel("Run Index")
        ax.set_ylabel("K Factor")
        ax.set_title("K Drift Monitor")
        ax.grid(alpha=0.3)
        ax.legend()

        canvas = FigureCanvasTkAgg(fig, master=upper)
        canvas.get_tk_widget().pack(fill="both", expand=True)
        canvas.draw()

        txt = tk.Text(lower, font=("Consolas", 9))
        txt.pack(fill="both", expand=True)
        self._register_native_widget(txt)
        show_cols = [c for c in ["Timestamp", "Norm_Mode", "SolidAngle_On", "K_Factor", "K_Std", "RelStd_pct", "PointsUsed", "Q_Min", "Q_Max"] if c in df.columns]
        txt.insert(tk.END, df[show_cols].to_string(index=False))

    def report(self, msg):
        if hasattr(self, "txt_report"):
            line = self._localize_runtime_text(msg)
            # Semantic tag highlighting in report text widget
            tag = None
            msg_lower = msg.lower()
            if any(kw in msg_lower for kw in ("error", "fail", "å¤±è´¥", "é”™è¯¯", "blocked")):
                tag = "error"
            elif any(kw in msg_lower for kw in ("success", "done", "å®Œæˆ", "æˆåŠŸ", "ready")):
                tag = "success"
            elif any(kw in msg_lower for kw in ("warning", "caution", "æ³¨æ„", "è­¦å‘Š")):
                tag = "warning"
            start_idx = self.txt_report.index(tk.END)
            self.txt_report.insert(tk.END, line + "\n")
            if tag:
                end_idx = self.txt_report.index(tk.END)
                self.txt_report.tag_add(tag, start_idx, end_idx)
            self.txt_report.see(tk.END)
        # Mirror last message to status bar with semantic colour
        if hasattr(self, "_status_bar"):
            short = msg.strip()[:120]
            self._status_var.set(short)
            msg_lower = msg.lower()
            if any(kw in msg_lower for kw in ("error", "fail", "å¤±è´¥", "é”™è¯¯", "blocked")):
                self._status_bar.configure(foreground="#dc2626")
            elif any(kw in msg_lower for kw in ("success", "done", "å®Œæˆ", "æˆåŠŸ", "ready")):
                self._status_bar.configure(foreground="#16a34a")
            elif any(kw in msg_lower for kw in ("warning", "caution", "æ³¨æ„", "è­¦å‘Š")):
                self._status_bar.configure(foreground="#d97706")
            else:
                try:
                    import sv_ttk as _sv
                    _hint_fg = "#9ca3af" if _sv.get_theme() == "dark" else "#6b7280"
                except Exception:
                    _hint_fg = "#6b7280"
                self._status_bar.configure(foreground=_hint_fg)

    def log(self, msg):
        print(msg)
        self.report(msg)

    def get_selected_modes(self):
        modes = []
        if hasattr(self, "t2_mode_full") and self.t2_mode_full.get():
            modes.append("1d_full")
        if hasattr(self, "t2_mode_sector") and self.t2_mode_sector.get():
            modes.append("1d_sector")
        if hasattr(self, "t2_mode_chi") and self.t2_mode_chi.get():
            modes.append("radial_chi")
        return modes

    def add_bg_library_files(self):
        fs = filedialog.askopenfilenames(filetypes=[("Image", "*.tif *.tiff *.edf *.cbf")])
        for f in fs:
            if f not in self.t2_bg_candidates:
                self.t2_bg_candidates.append(f)
        self.t2_bg_lib_info.set(self.tr("var_bg_lib").format(n=len(self.t2_bg_candidates)))

    def add_dark_library_files(self):
        fs = filedialog.askopenfilenames(filetypes=[("Image", "*.tif *.tiff *.edf *.cbf")])
        for f in fs:
            if f not in self.t2_dark_candidates:
                self.t2_dark_candidates.append(f)
        self.t2_dark_lib_info.set(self.tr("var_dark_lib").format(n=len(self.t2_dark_candidates)))

    def clear_reference_libraries(self):
        self.t2_bg_candidates = []
        self.t2_dark_candidates = []
        self.t2_bg_lib_info.set(self.tr("var_bg_lib").format(n=0))
        self.t2_dark_lib_info.set(self.tr("var_dark_lib").format(n=0))

    def process_sample_task(self, idx, fpath, out_stem, context):
        logs = []
        mode_stats = {m: {"ok": 0, "fail": 0, "skip": 0} for m in context["selected_modes"]}

        def log_line(msg):
            logs.append(msg)

        def load_data(path):
            if context["parallel"]:
                return fabio.open(path).data.astype(np.float64)
            with context["cache_lock"]:
                if path in context["image_cache"]:
                    return context["image_cache"][path]
            d = fabio.open(path).data.astype(np.float64)
            with context["cache_lock"]:
                context["image_cache"][path] = d
            return d

        fname = Path(fpath).name
        exp = np.nan
        mon = np.nan
        trans = np.nan
        thk_cm = np.nan
        norm_s = np.nan
        bg_norm_used = np.nan
        bg_path_used = ""
        dark_path_used = ""
        bg_score = np.nan
        dark_score = np.nan
        outputs = []
        mode_errors = []
        status = "å¤±è´¥"
        reason = ""

        try:
            run_policy = context.get("run_policy")
            if run_policy is None:
                run_policy = SimpleNamespace(
                    resume_enabled=bool(context.get("resume", False)),
                    overwrite_existing=bool(context.get("overwrite", False)),
                    mode=(
                        "overwrite"
                        if bool(context.get("overwrite", False))
                        else ("resume-skip" if bool(context.get("resume", False)) else "always-run")
                    ),
                    should_skip_existing=lambda exists: bool(exists)
                    and bool(context.get("resume", False))
                    and (not bool(context.get("overwrite", False))),
                )

            expected_targets = self.build_sample_output_targets(context, out_stem)
            if expected_targets and should_skip_all_existing(
                [p.exists() for _, p in expected_targets],
                run_policy,
            ):
                    for mode_tag, p in expected_targets:
                        mode_key = "1d_sector" if mode_tag.startswith("1d_sector") else mode_tag
                        mode_stats[mode_key]["skip"] += 1
                        outputs.append(f"{mode_tag}:{p.name}(existing)")
                    status = "å·²è·³è¿‡"
                    reason = "æ‰€æœ‰æ¨¡å¼è¾“å‡ºå·²å­˜åœ¨"
                    log_line(f"[è·³è¿‡] {fname}: æ‰€æœ‰è¾“å‡ºå·²å­˜åœ¨")
                    row = {
                        "Index": idx,
                        "File": fname,
                        "Status": status,
                        "Reason": reason,
                        "Norm_Mode": context["monitor_mode"],
                        "Exposure_s": exp,
                        "Monitor": mon,
                        "Trans": trans,
                        "Thk_cm": thk_cm,
                        "Norm_s": norm_s,
                        "BG_Norm": bg_norm_used,
                        "BG_Used": bg_path_used,
                        "Dark_Used": dark_path_used,
                        "BG_Score": bg_score,
                        "Dark_Score": dark_score,
                        "ModesSelected": ",".join(context["selected_modes"]),
                        "Outputs": " | ".join(outputs),
                    }
                    return {"row": row, "logs": logs, "mode_stats": mode_stats}

            ai = context["ai_shared"] if not context["parallel"] else pyFAI.load(context["poni_path"])
            sample = fabio.open(fpath)
            d_s = sample.data.astype(np.float64)
            sample_header = getattr(sample, "header", {})

            exp, mon, trans = self.parse_header(fpath, header_dict=sample_header)
            monitor_mode = context["monitor_mode"]
            missing = []
            if mon is None:
                missing.append("mon")
            if trans is None:
                missing.append("trans")
            if monitor_mode == "rate" and exp is None:
                missing.append("exp")
            if missing:
                raise ValueError(f"æ–‡ä»¶å¤´ç¼ºå°‘å…³é”®å­—æ®µ: {', '.join(missing)}")

            exp = float(exp) if exp is not None else np.nan
            mon = float(mon)
            trans = float(trans)
            if not (np.isfinite(mon) and np.isfinite(trans) and (np.isfinite(exp) or monitor_mode == "integrated")):
                raise ValueError("æ–‡ä»¶å¤´å‚æ•°å­˜åœ¨éæ³•å€¼ï¼ˆéæœ‰é™æ•°ï¼‰")
            if monitor_mode == "rate" and exp <= 0:
                raise ValueError(f"æ›å…‰æ—¶é—´éæ³•: exp={exp}")
            if mon <= 0:
                raise ValueError(f"I0 éæ³•: mon={mon}")
            if not (0 < trans <= 1):
                raise ValueError(f"é€è¿‡ç‡è¶…èŒƒå›´ (0,1]: {trans}")

            sample_meta = {
                "exp": exp if np.isfinite(exp) else None,
                "mon": mon,
                "trans": trans,
                "mtime": Path(fpath).stat().st_mtime if Path(fpath).exists() else None,
                "shape": tuple(d_s.shape),
            }

            if context["ref_mode"] == "fixed":
                d_dark = context["fixed_dark_data"]
                bg_norm = context["fixed_bg_norm"]
                img_bg_net = context["fixed_bg_net"]
                bg_path_used = context["fixed_bg_path"]
                dark_path_used = context["fixed_dark_path"]
            else:
                bg_ref, bg_score = self.select_best_reference(sample_meta, context["bg_library"], kind="bg")
                dark_ref, dark_score = self.select_best_reference(sample_meta, context["dark_library"], kind="dark")
                if bg_ref is None or dark_ref is None:
                    raise ValueError("è‡ªåŠ¨åŒ¹é…å¤±è´¥ï¼šBG/Dark åº“ä¸ºç©ºæˆ–ä¸å…¼å®¹")

                bg_path_used = bg_ref["path"]
                dark_path_used = dark_ref["path"]
                d_bg = load_data(bg_path_used)
                d_dark = load_data(dark_path_used)
                bg_norm = self.compute_norm_factor(
                    bg_ref.get("exp"),
                    bg_ref.get("mon"),
                    bg_ref.get("trans"),
                    monitor_mode,
                )
                if not np.isfinite(bg_norm) or bg_norm <= 0:
                    bg_norm = context["fixed_bg_norm"]
                    log_line(f"[è­¦å‘Š] {fname}: åŒ¹é…åˆ°çš„ BG å¤´å‚æ•°ä¸å®Œæ•´ï¼Œå›é€€å…¨å±€ BG å½’ä¸€åŒ–å› å­")
                img_bg_net = (d_bg - d_dark) / bg_norm

            self._assert_same_shape(d_s, d_dark, "sample", "dark")
            self._assert_same_shape(d_s, img_bg_net, "sample", "bg_net")
            bg_norm_used = bg_norm

            mask_arr = context["mask_arr"]
            flat_arr = context["flat_arr"]
            if mask_arr is not None and tuple(mask_arr.shape) != tuple(d_s.shape):
                raise ValueError(f"Mask å°ºå¯¸ä¸åŒ¹é…: {mask_arr.shape} vs {d_s.shape}")
            if flat_arr is not None and tuple(flat_arr.shape) != tuple(d_s.shape):
                raise ValueError(f"Flat å°ºå¯¸ä¸åŒ¹é…: {flat_arr.shape} vs {d_s.shape}")

            # --- Thickness Logic ---
            if context["calc_mode"] == "auto":
                if trans >= 0.999 or trans <= 0.001:
                    raise ValueError(f"é€è¿‡ç‡ä¸é€‚åˆè‡ªåŠ¨åšåº¦è®¡ç®—: {trans}")
                thk_cm = -math.log(trans) / context["mu"]
            else:
                thk_cm = context["fixed_thk_cm"]
            if not np.isfinite(thk_cm) or thk_cm <= 0:
                raise ValueError(f"åšåº¦è®¡ç®—ç»“æœéæ³•: {thk_cm}")

            norm_s = self.compute_norm_factor(exp if np.isfinite(exp) else None, mon, trans, monitor_mode)
            if not np.isfinite(norm_s) or norm_s <= 0:
                raise ValueError(f"æ ·å“å½’ä¸€åŒ–å› å­éæ³•: {norm_s}")

            img_net = (d_s - d_dark) / norm_s - context.get("bg_alpha", 1.0) * img_bg_net

            integ_kwargs_common = {
                "correctSolidAngle": context["apply_solid_angle"],
            }
            if context["error_model"] != "none":
                integ_kwargs_common["error_model"] = context["error_model"]
            if mask_arr is not None:
                integ_kwargs_common["mask"] = mask_arr
            if flat_arr is not None:
                integ_kwargs_common["flat"] = flat_arr
            if context["polarization"] is not None:
                integ_kwargs_common["polarization_factor"] = context["polarization"]

            mode_success = 0
            mode_skip = 0
            scale_factor = context["k_factor"] / thk_cm
            expected_total = len(self.build_sample_output_targets(context, out_stem))
            if expected_total <= 0:
                expected_total = len(context["selected_modes"])

            for mode in context["selected_modes"]:
                out_path = self.mode_output_path(context["save_dirs"], mode, out_stem)
                try:
                    if mode != "1d_sector" and run_policy.should_skip_existing(out_path.exists()):
                        outputs.append(f"{mode}:{out_path.name}(existing)")
                        mode_stats[mode]["skip"] += 1
                        mode_skip += 1
                        continue

                    if mode == "1d_full":
                        res = ai.integrate1d(
                            img_net,
                            1000,
                            unit="q_A^-1",
                            **integ_kwargs_common,
                        )
                        i_abs = np.asarray(res.intensity, dtype=np.float64) * scale_factor
                        if getattr(res, "sigma", None) is None:
                            i_err = np.full_like(i_abs, np.nan)
                        else:
                            i_err = np.asarray(res.sigma, dtype=np.float64) * scale_factor
                        issue = self.profile_health_issue(i_abs)
                        if issue:
                            raise ValueError(issue)
                        self.save_profile_table(out_path, res.radial, i_abs, i_err, "Q_A^-1", output_format=context.get("output_format", "tsv"))
                        outputs.append(f"{mode}:{out_path.name}")
                        mode_stats[mode]["ok"] += 1
                        mode_success += 1

                    elif mode == "1d_sector":
                        sector_specs = context["sector_specs"]
                        save_each = bool(context.get("sector_save_each", True))
                        save_sum = bool(context.get("sector_save_combined", False))
                        sector_results = {}
                        multi_sector = len(sector_specs) > 1

                        sum_out_path = None
                        sum_need_write = False
                        if save_sum:
                            sum_out_path = context["sector_combined_dir"] / f"{out_stem}.dat"
                            if run_policy.should_skip_existing(sum_out_path.exists()):
                                outputs.append(f"1d_sector_sum:{sum_out_path.name}(existing)")
                                mode_stats[mode]["skip"] += 1
                                mode_skip += 1
                            else:
                                sum_need_write = True

                        for spec in sector_specs:
                            spec_tag = f"1d_sector{spec['label']}"
                            each_out_path = None
                            need_each_write = False
                            if save_each:
                                each_dir = context["sector_save_dirs"].get(spec["key"])
                                if each_dir is None:
                                    mode_stats[mode]["fail"] += 1
                                    mode_errors.append(f"{spec_tag}: ç¼ºå°‘è¾“å‡ºç›®å½•æ˜ å°„")
                                    continue
                                each_out_path = each_dir / f"{out_stem}.dat"
                                each_disp = (
                                    f"{each_out_path.parent.name}/{each_out_path.name}"
                                    if multi_sector else each_out_path.name
                                )
                                if run_policy.should_skip_existing(each_out_path.exists()):
                                    outputs.append(f"{spec_tag}:{each_disp}(existing)")
                                    mode_stats[mode]["skip"] += 1
                                    mode_skip += 1
                                else:
                                    need_each_write = True

                            need_result = need_each_write or sum_need_write
                            if not need_result:
                                continue

                            try:
                                res, sec_min_n, sec_max_n, sec_wrap = self.integrate1d_sector(
                                    ai,
                                    img_net,
                                    1000,
                                    spec["sec_min"],
                                    spec["sec_max"],
                                    **integ_kwargs_common,
                                )
                                sector_results[spec["key"]] = res

                                if need_each_write and each_out_path is not None:
                                    i_abs = np.asarray(res.intensity, dtype=np.float64) * scale_factor
                                    if getattr(res, "sigma", None) is None:
                                        i_err = np.full_like(i_abs, np.nan)
                                    else:
                                        i_err = np.asarray(res.sigma, dtype=np.float64) * scale_factor
                                    issue = self.profile_health_issue(i_abs)
                                    if issue:
                                        raise ValueError(issue)
                                    self.save_profile_table(each_out_path, res.radial, i_abs, i_err, "Q_A^-1", output_format=context.get("output_format", "tsv"))
                                    outputs.append(f"{spec_tag}:{each_disp}")
                                    mode_stats[mode]["ok"] += 1
                                    mode_success += 1

                                if sec_wrap:
                                    log_line(
                                        f"[æç¤º] {fname} {spec['label']}: è·¨Â±180Â°ï¼ŒæŒ‰ [{sec_min_n:.2f},180] ä¸ [-180,{sec_max_n:.2f}] åˆå¹¶ç§¯åˆ†"
                                    )
                            except Exception as sector_err:
                                mode_stats[mode]["fail"] += 1
                                mode_errors.append(f"{spec_tag}: {sector_err}")

                        if sum_need_write and sum_out_path is not None:
                            missing = [s for s in sector_specs if s["key"] not in sector_results]
                            if missing:
                                miss_lbl = ",".join([m["label"] for m in missing[:3]])
                                if len(missing) > 3:
                                    miss_lbl += ",..."
                                mode_stats[mode]["fail"] += 1
                                mode_errors.append(f"1d_sector_sum: æ‰‡åŒºç»“æœä¸å®Œæ•´ï¼Œæ— æ³•åˆå¹¶ ({miss_lbl})")
                            else:
                                try:
                                    merge = self.merge_integrate1d_results(
                                        [sector_results[s["key"]] for s in sector_specs]
                                    )
                                    i_abs = np.asarray(merge.intensity, dtype=np.float64) * scale_factor
                                    if getattr(merge, "sigma", None) is None:
                                        i_err = np.full_like(i_abs, np.nan)
                                    else:
                                        i_err = np.asarray(merge.sigma, dtype=np.float64) * scale_factor
                                    issue = self.profile_health_issue(i_abs)
                                    if issue:
                                        raise ValueError(issue)
                                    self.save_profile_table(sum_out_path, merge.radial, i_abs, i_err, "Q_A^-1", output_format=context.get("output_format", "tsv"))
                                    outputs.append(f"1d_sector_sum:{sum_out_path.name}")
                                    mode_stats[mode]["ok"] += 1
                                    mode_success += 1
                                except Exception as sum_err:
                                    mode_stats[mode]["fail"] += 1
                                    mode_errors.append(f"1d_sector_sum: {sum_err}")

                    elif mode == "radial_chi":
                        qmin = context["qmin"]
                        qmax = context["qmax"]
                        try:
                            res = ai.integrate_radial(
                                img_net,
                                360,
                                unit="chi_deg",
                                radial_unit="q_A^-1",
                                radial_range=(qmin, qmax),
                                **integ_kwargs_common,
                            )
                        except TypeError as radial_err:
                            if "radial_unit" not in str(radial_err):
                                raise
                            # å…¼å®¹æ—§ç‰ˆ pyFAI: é»˜è®¤ radial_range å•ä½æ˜¯ q_nm^-1
                            res = ai.integrate_radial(
                                img_net,
                                360,
                                unit="chi_deg",
                                radial_range=(qmin * 10.0, qmax * 10.0),
                                **integ_kwargs_common,
                            )
                            log_line(f"[è­¦å‘Š] {fname}: pyFAI ä¸æ”¯æŒ radial_unitï¼Œq åŒºé—´å·²æŒ‰ A^-1->nm^-1 è½¬æ¢")
                        i_abs = np.asarray(res.intensity, dtype=np.float64) * scale_factor
                        if getattr(res, "sigma", None) is None:
                            i_err = np.full_like(i_abs, np.nan)
                        else:
                            i_err = np.asarray(res.sigma, dtype=np.float64) * scale_factor
                        issue = self.profile_health_issue(i_abs)
                        if issue:
                            raise ValueError(issue)
                        self.save_profile_table(out_path, res.radial, i_abs, i_err, "Chi_deg", output_format=context.get("output_format", "tsv"))
                        outputs.append(f"{mode}:{out_path.name}")
                        mode_stats[mode]["ok"] += 1
                        mode_success += 1

                    else:
                        raise ValueError(f"ä¸æ”¯æŒçš„ç§¯åˆ†æ¨¡å¼: {mode}")

                except Exception as mode_err:
                    mode_stats[mode]["fail"] += 1
                    mode_errors.append(f"{mode}: {mode_err}")

            if mode_skip == expected_total and mode_success == 0 and not mode_errors:
                status = "å·²è·³è¿‡"
                reason = "æ‰€æœ‰æ¨¡å¼è¾“å‡ºå·²å­˜åœ¨"
                log_line(f"[è·³è¿‡] {fname}: æ‰€æœ‰è¾“å‡ºå·²å­˜åœ¨")
            elif mode_success > 0 and not mode_errors:
                status = "æˆåŠŸ"
                log_line(f"[æˆåŠŸ] {fname} -> {', '.join(outputs)}")
            elif mode_success > 0:
                status = "éƒ¨åˆ†æˆåŠŸ"
                reason = " | ".join(mode_errors)
                log_line(f"[éƒ¨åˆ†æˆåŠŸ] {fname} -> {', '.join(outputs)}")
                log_line(f"[æ¨¡å¼å¤±è´¥] {fname}: {reason}")
            else:
                status = "å¤±è´¥"
                reason = " | ".join(mode_errors) if mode_errors else "æ— è¾“å‡º"
                log_line(f"[å¤±è´¥] {fname}: {reason}")

        except Exception as file_err:
            status = "å¤±è´¥"
            reason = str(file_err)
            log_line(f"[å¤±è´¥] {fname}: {reason}")

        row = {
            "Index": idx,
            "File": fname,
            "Status": status,
            "Reason": reason,
            "Norm_Mode": context["monitor_mode"],
            "Exposure_s": exp,
            "Monitor": mon,
            "Trans": trans,
            "Thk_cm": thk_cm,
            "Norm_s": norm_s,
            "BG_Norm": bg_norm_used,
            "BG_Used": bg_path_used,
            "Dark_Used": dark_path_used,
            "BG_Score": bg_score,
            "Dark_Score": dark_score,
            "ModesSelected": ",".join(context["selected_modes"]),
            "Outputs": " | ".join(outputs),
        }
        return {"row": row, "logs": logs, "mode_stats": mode_stats}

    # =========================================================================
    # Logic: Batch (2D Subtraction Kernel + Error)
    # =========================================================================
    def run_batch(self):
        try:
            if not self.t2_files: raise ValueError("é˜Ÿåˆ—ä¸ºç©ºï¼šè¯·å…ˆæ·»åŠ æ ·å“æ–‡ä»¶ã€‚")
            k = float(self.global_vars["k_factor"].get())
            bg_p = self.global_vars["bg_path"].get()
            dk_p = self.global_vars["dark_path"].get()
            poni = self.global_vars["poni_path"].get()
            
            if k <= 0: raise ValueError("K å› å­æ— æ•ˆï¼ˆå¿…é¡» > 0ï¼‰ã€‚")
            if not all([bg_p, dk_p, poni]): raise ValueError("ç¼ºå°‘èƒŒæ™¯/æš—åœº/poni æ–‡ä»¶ã€‚")
            monitor_mode = self.get_monitor_mode()
            self.log(f"[é…ç½®] I0 å½’ä¸€åŒ–æ¨¡å¼: {monitor_mode} (norm={self.monitor_norm_formula(monitor_mode)})")
            self.log(f"[é…ç½®] SolidAngle ä¿®æ­£: {'ON' if bool(self.t2_apply_solid_angle.get()) else 'OFF'}")

            files = list(dict.fromkeys(self.t2_files))
            if len(files) < len(self.t2_files):
                self.log(f"[æç¤º] é˜Ÿåˆ—å»é‡ï¼šç§»é™¤é‡å¤æ–‡ä»¶ {len(self.t2_files) - len(files)} ä¸ª")
                self.t2_files = files
                self.lb_batch.delete(0, tk.END)
                for f in self.t2_files:
                    self.lb_batch.insert(tk.END, Path(f).name)
                self.refresh_queue_status()

            selected_modes = self.get_selected_modes()
            if not selected_modes:
                raise ValueError("æœªé€‰æ‹©ç§¯åˆ†æ¨¡å¼ï¼šè¯·è‡³å°‘å‹¾é€‰ä¸€ç§ï¼ˆå…¨ç¯/æ‰‡åŒº/ç»‡æ„ï¼‰ã€‚")

            apply_solid_angle = bool(self.t2_apply_solid_angle.get())
            k_solid_state = str(self.global_vars["k_solid_angle"].get()).strip().lower()
            if k_solid_state in ("on", "off"):
                k_solid_bool = (k_solid_state == "on")
                if apply_solid_angle != k_solid_bool:
                    raise ValueError(
                        "SolidAngle è®¾ç½®ä¸ K å› å­æ ‡å®šçŠ¶æ€ä¸ä¸€è‡´ï¼š"
                        f"K ä½¿ç”¨ {'ON' if k_solid_bool else 'OFF'}ï¼Œå½“å‰æ‰¹å¤„ç†ä¸º {'ON' if apply_solid_angle else 'OFF'}ã€‚"
                        "è¯·åˆ‡æ¢ä¸ºä¸€è‡´è®¾ç½®ï¼Œæˆ–é‡æ–°è¿è¡Œ Tab1 æ ‡å®šã€‚"
                    )
            else:
                self.log("[è­¦å‘Š] å½“å‰ K å› å­ç¼ºå°‘ SolidAngle çŠ¶æ€ä¿¡æ¯ï¼Œæ— æ³•è‡ªåŠ¨æ ¡éªŒä¸€è‡´æ€§ã€‚å»ºè®®é‡æ–°æ ‡å®š Kã€‚")

            ai = pyFAI.load(poni)
            if "radial_chi" in selected_modes and not hasattr(ai, "integrate_radial"):
                raise RuntimeError("å½“å‰ pyFAI ä¸æ”¯æŒ integrate_radialï¼Œè¯·å–æ¶ˆç»‡æ„æ¨¡å¼æˆ–å‡çº§ pyFAIã€‚")
            sector_specs = []
            sector_save_each = bool(self.t2_sector_save_each.get())
            sector_save_combined = bool(self.t2_sector_save_combined.get())
            if "1d_sector" in selected_modes:
                sector_specs = self.get_t2_sector_specs()
                if not sector_save_each and not sector_save_combined:
                    raise ValueError("å·²å¯ç”¨æ‰‡åŒºæ¨¡å¼ï¼Œä½†æœªé€‰æ‹©ä»»ä½•æ‰‡åŒºè¾“å‡ºï¼ˆè¯·å‹¾é€‰â€œåˆ†æ‰‡åŒºåˆ†åˆ«ä¿å­˜â€æˆ–â€œæ‰‡åŒºåˆå¹¶ä¿å­˜â€ï¼‰ã€‚")
                sec_brief = "; ".join([f"{s['index']}:{s['label']}" for s in sector_specs[:6]])
                if len(sector_specs) > 6:
                    sec_brief += "; ..."
                self.log(f"[é…ç½®] æ‰‡åŒºåˆ—è¡¨({len(sector_specs)}): {sec_brief}")
            if "radial_chi" in selected_modes and self.t2_rad_qmin.get() >= self.t2_rad_qmax.get():
                raise ValueError("ç»‡æ„ q èŒƒå›´æ— æ•ˆï¼šqmin å¿…é¡» < qmaxã€‚")

            fixed_dark_data = fabio.open(dk_p).data.astype(np.float64)
            bg_paths = self.split_path_list(bg_p)
            if not bg_paths:
                raise ValueError("ç¼ºå°‘èƒŒæ™¯æ–‡ä»¶ã€‚")
            fixed_bg_net, bg_norm_list, bg_used_paths = self.build_composite_bg_net(
                bg_paths=bg_paths,
                d_dark=fixed_dark_data,
                monitor_mode=monitor_mode,
                fallback_triplet=(
                    self.global_vars["bg_exp"].get(),
                    self.global_vars["bg_i0"].get(),
                    self.global_vars["bg_t"].get(),
                ),
                ref_shape=fixed_dark_data.shape,
            )
            fixed_bg_norm = float(np.nanmedian(np.asarray(bg_norm_list, dtype=np.float64)))
            if not np.isfinite(fixed_bg_norm) or fixed_bg_norm <= 0:
                raise ValueError("èƒŒæ™¯å½’ä¸€åŒ–å› å­ <= 0ï¼Œè¯·æ£€æŸ¥ BG çš„ Time/I0/Tã€‚")

            ref_mode = self.t2_ref_mode.get()
            if ref_mode not in ("fixed", "auto"):
                raise ValueError(f"æœªçŸ¥å‚è€ƒæ¨¡å¼: {ref_mode}")

            # é˜²æ­¢ BG å½’ä¸€åŒ–å› å­é‡çº§å¼‚å¸¸å¯¼è‡´è¿‡æ‰£èƒŒæ™¯ï¼ˆä¾‹å¦‚ T è¢«è¯¯åˆ¤æˆç™¾åˆ†æ•°ï¼‰
            probe_norms = []
            for fp in files[: min(20, len(files))]:
                try:
                    e, m, t = self.parse_header(fp)
                    n = self.compute_norm_factor(e, m, t, monitor_mode)
                    if np.isfinite(n) and n > 0:
                        probe_norms.append(float(n))
                except Exception:
                    continue
            if probe_norms:
                med_sample_norm = float(np.nanmedian(np.asarray(probe_norms, dtype=np.float64)))
                if np.isfinite(med_sample_norm) and med_sample_norm > 0:
                    bg_ratio = fixed_bg_norm / med_sample_norm
                    if bg_ratio < 0.01 or bg_ratio > 100.0:
                        msg = (
                            "BG_Norm ä¸æ ·å“ Norm_s é‡çº§å·®å¼‚è¿‡å¤§ "
                            f"(BG/æ ·å“ä¸­ä½={bg_ratio:.3g}, BG_Norm={fixed_bg_norm:.6g}, "
                            f"SampleMed={med_sample_norm:.6g})ï¼Œè¯·æ£€æŸ¥ BG çš„ Time/I0/Tã€I0 è¯­ä¹‰æˆ–å¤´å­—æ®µæ˜ å°„ã€‚"
                        )
                        if ref_mode == "fixed":
                            raise ValueError(msg)
                        self.log(f"[è­¦å‘Š] {msg}")

            bg_library = self.build_reference_library(self.t2_bg_candidates)
            dark_library = self.build_reference_library(self.t2_dark_candidates)
            if ref_mode == "auto":
                if not bg_library:
                    raise ValueError("è‡ªåŠ¨åŒ¹é…æ¨¡å¼ä¸‹ BG åº“ä¸ºç©ºã€‚")
                if not dark_library:
                    raise ValueError("è‡ªåŠ¨åŒ¹é…æ¨¡å¼ä¸‹ Dark åº“ä¸ºç©ºã€‚")

            if self.t2_strict_instrument.get():
                tol_pct = self.t2_instr_tol_pct.get()
                issues = self.check_instrument_consistency(files, poni_path=poni, tol_pct=tol_pct)
                if issues:
                    preview = "\n".join(issues[:10])
                    tail = "\n..." if len(issues) > 10 else ""
                    raise ValueError(f"ä»ªå™¨ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥ï¼ˆå‰10é¡¹ï¼‰:\n{preview}{tail}")

            mask_arr = self.load_optional_array(self.t2_mask_path.get().strip(), "Mask")
            if mask_arr is not None:
                mask_arr = np.asarray(mask_arr) != 0
            flat_arr = self.load_optional_array(self.t2_flat_path.get().strip(), "Flat")
            if flat_arr is not None:
                flat_arr = np.asarray(flat_arr, dtype=np.float64)

            pol = self.t2_polarization.get()
            if not np.isfinite(pol) or pol < -1.0 or pol > 1.0:
                raise ValueError("Polarization å› å­å¿…é¡»åœ¨ [-1, 1]ã€‚")
            error_model = self.t2_error_model.get().strip().lower()
            if error_model not in ("azimuthal", "poisson", "none"):
                raise ValueError("è¯¯å·®æ¨¡å‹ä»…æ”¯æŒ azimuthal / poisson / noneã€‚")

            custom_out_root = self.t2_output_root.get().strip() if hasattr(self, "t2_output_root") else ""
            if custom_out_root:
                out_root = Path(custom_out_root).expanduser()
                out_root.mkdir(parents=True, exist_ok=True)
                self.log(f"[é…ç½®] è¾“å‡ºæ ¹ç›®å½•(è‡ªå®šä¹‰): {out_root}")
            else:
                out_root = Path(files[0]).parent
                self.log(f"[é…ç½®] è¾“å‡ºæ ¹ç›®å½•(é»˜è®¤æ ·å“ç›®å½•): {out_root}")
            save_dirs = {}
            sector_save_dirs = {}
            sector_combined_dir = None
            for mode in selected_modes:
                if mode == "1d_sector":
                    base = out_root / "processed_robust_1d_sector"
                    base.mkdir(exist_ok=True)
                    save_dirs[mode] = base
                    if sector_save_each:
                        multi = len(sector_specs) > 1
                        for spec in sector_specs:
                            d = base / spec["key"] if multi else base
                            d.mkdir(exist_ok=True)
                            sector_save_dirs[spec["key"]] = d
                    if sector_save_combined:
                        sector_combined_dir = out_root / "processed_robust_1d_sector_combined"
                        sector_combined_dir.mkdir(exist_ok=True)
                else:
                    d = out_root / f"processed_robust_{mode}"
                    d.mkdir(exist_ok=True)
                    save_dirs[mode] = d
            report_dir = out_root / "processed_robust_reports"
            report_dir.mkdir(exist_ok=True)
            stem_map = self.build_output_stem_map(files)

            self.prog_bar["maximum"] = len(files)
            self.prog_bar["value"] = 0
            mu = self.t2_mu.get()
            if self.t2_calc_mode.get() == "auto" and mu <= 0:
                raise ValueError("è‡ªåŠ¨åšåº¦æ¨¡å¼è¦æ±‚ mu > 0ã€‚")
            if self.t2_calc_mode.get() == "fixed" and self.t2_fixed_thk.get() <= 0:
                raise ValueError("å›ºå®šåšåº¦å¿…é¡» > 0 mmã€‚")
            fixed_thk_cm = self.t2_fixed_thk.get() / 10.0

            try:
                workers = max(1, int(self.t2_workers.get()))
            except Exception:
                raise ValueError("å¹¶è¡Œçº¿ç¨‹æ•°å¿…é¡»ä¸ºæ­£æ•´æ•°ã€‚")
            overwrite = bool(self.t2_overwrite.get())
            resume = bool(self.t2_resume_enabled.get())
            if parse_run_policy is not None:
                run_policy = parse_run_policy(resume_enabled=resume, overwrite_existing=overwrite)
            else:
                run_policy = SimpleNamespace(
                    resume_enabled=resume,
                    overwrite_existing=overwrite,
                    mode=("overwrite" if overwrite else ("resume-skip" if resume else "always-run")),
                    should_skip_existing=lambda exists: bool(exists) and resume and (not overwrite),
                )
            self.log(f"[é…ç½®] Existing-output ç­–ç•¥: {run_policy.mode} (resume={resume}, overwrite={overwrite})")

            context = {
                "selected_modes": selected_modes,
                "save_dirs": save_dirs,
                "poni_path": poni,
                "ai_shared": ai,
                "parallel": workers > 1,
                "cache_lock": threading.Lock(),
                "image_cache": {},
                "k_factor": k,
                "monitor_mode": monitor_mode,
                "calc_mode": self.t2_calc_mode.get(),
                "mu": mu,
                "fixed_thk_cm": fixed_thk_cm,
                "fixed_bg_net": fixed_bg_net,
                "fixed_dark_data": fixed_dark_data,
                "fixed_bg_norm": fixed_bg_norm,
                "fixed_bg_path": ";".join(bg_used_paths),
                "fixed_dark_path": dk_p,
                "ref_mode": ref_mode,
                "bg_library": bg_library,
                "dark_library": dark_library,
                "mask_arr": mask_arr,
                "flat_arr": flat_arr,
                "error_model": error_model,
                "apply_solid_angle": bool(self.t2_apply_solid_angle.get()),
                "polarization": float(pol),
                "sector_specs": sector_specs,
                "sector_save_each": sector_save_each,
                "sector_save_combined": sector_save_combined,
                "sector_save_dirs": sector_save_dirs,
                "sector_combined_dir": sector_combined_dir,
                "qmin": float(self.t2_rad_qmin.get()),
                "qmax": float(self.t2_rad_qmax.get()),
                "overwrite": overwrite,
                "resume": resume,
                "run_policy": run_policy,
                "bg_alpha": float(self.t2_alpha.get()) if self.t2_alpha_enabled.get() else 1.0,
                "output_format": self.t2_output_format.get() if hasattr(self, "t2_output_format") else "tsv",
            }

            rows = []
            sample_success = 0
            sample_partial = 0
            sample_fail = 0
            sample_skip = 0
            mode_ok_count = {m: 0 for m in selected_modes}
            mode_fail_count = {m: 0 for m in selected_modes}
            mode_skip_count = {m: 0 for m in selected_modes}

            tasks = [(idx, fpath, stem_map[fpath]) for idx, fpath in enumerate(files)]
            processed = 0

            if workers == 1:
                for idx, fpath, out_stem in tasks:
                    result = self.process_sample_task(idx, fpath, out_stem, context)
                    rows.append(result["row"])
                    for line in result["logs"]:
                        self.log(line)

                    for m in selected_modes:
                        mode_ok_count[m] += result["mode_stats"][m]["ok"]
                        mode_fail_count[m] += result["mode_stats"][m]["fail"]
                        mode_skip_count[m] += result["mode_stats"][m]["skip"]

                    st = result["row"]["Status"]
                    if st == "æˆåŠŸ":
                        sample_success += 1
                    elif st == "éƒ¨åˆ†æˆåŠŸ":
                        sample_partial += 1
                    elif st == "å·²è·³è¿‡":
                        sample_skip += 1
                    else:
                        sample_fail += 1

                    processed += 1
                    self.prog_bar["value"] = processed
                    self.root.update_idletasks()
            else:
                with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as ex:
                    futures = {
                        ex.submit(self.process_sample_task, idx, fpath, out_stem, context): (idx, fpath)
                        for idx, fpath, out_stem in tasks
                    }
                    for fut in concurrent.futures.as_completed(futures):
                        result = fut.result()
                        rows.append(result["row"])
                        for line in result["logs"]:
                            self.log(line)

                        for m in selected_modes:
                            mode_ok_count[m] += result["mode_stats"][m]["ok"]
                            mode_fail_count[m] += result["mode_stats"][m]["fail"]
                            mode_skip_count[m] += result["mode_stats"][m]["skip"]

                        st = result["row"]["Status"]
                        if st == "æˆåŠŸ":
                            sample_success += 1
                        elif st == "éƒ¨åˆ†æˆåŠŸ":
                            sample_partial += 1
                        elif st == "å·²è·³è¿‡":
                            sample_skip += 1
                        else:
                            sample_fail += 1

                        processed += 1
                        self.prog_bar["value"] = processed
                        self.root.update_idletasks()

            rows.sort(key=lambda x: x.get("Index", 0))
            for r in rows:
                r.pop("Index", None)

            stamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")
            report_path = report_dir / f"batch_report_{stamp}.csv"
            pd.DataFrame(rows).to_csv(report_path, index=False, encoding="utf-8-sig")

            tab3_meta_stamp = None
            tab3_meta_latest = None
            tab3_meta_rows = 0
            try:
                tab3_meta_stamp, tab3_meta_latest, tab3_meta_rows = self.export_tab3_metadata_from_report(
                    report_path,
                    stamp=stamp,
                )
            except Exception as e:
                self.log(f"[è­¦å‘Š] è‡ªåŠ¨å¯¼å‡º Tab3 metadata å¤±è´¥: {e}")

            meta_path = report_dir / f"run_meta_{stamp}.json"
            output_dirs_meta = {}
            for m in selected_modes:
                if m != "1d_sector":
                    output_dirs_meta[m] = str(save_dirs[m])
                    continue
                output_dirs_meta["1d_sector_base"] = str(save_dirs[m])
                if sector_save_each:
                    output_dirs_meta["1d_sector_each"] = {
                        spec["label"]: str(sector_save_dirs.get(spec["key"], save_dirs[m]))
                        for spec in sector_specs
                    }
                if sector_save_combined and sector_combined_dir is not None:
                    output_dirs_meta["1d_sector_sum"] = str(sector_combined_dir)

            meta = {
                "timestamp": stamp,
                "selected_modes": selected_modes,
                "files_total": len(files),
                "workers": workers,
                "k_factor": k,
                "monitor_mode": monitor_mode,
                "norm_formula": self.monitor_norm_formula(monitor_mode),
                "calc_mode": self.t2_calc_mode.get(),
                "mu_cm^-1": mu,
                "fixed_thickness_mm": self.t2_fixed_thk.get(),
                "reference_mode": ref_mode,
                "fixed_bg_path": bg_p,
                "fixed_dark_path": dk_p,
                "bg_library_count": len(bg_library),
                "dark_library_count": len(dark_library),
                "error_model": error_model,
                "correct_solid_angle": bool(self.t2_apply_solid_angle.get()),
                "k_solid_angle_state": str(self.global_vars["k_solid_angle"].get()),
                "polarization_factor": pol,
                "mask_path": self.t2_mask_path.get().strip(),
                "flat_path": self.t2_flat_path.get().strip(),
                "resume_enabled": resume,
                "overwrite": overwrite,
                "existing_output_policy": run_policy.mode,
                "strict_instrument": bool(self.t2_strict_instrument.get()),
                "instrument_tol_pct": float(self.t2_instr_tol_pct.get()),
                "sector_specs": sector_specs,
                "sector_save_each": sector_save_each,
                "sector_save_combined": sector_save_combined,
                "output_root": str(out_root),
                "output_root_custom": bool(custom_out_root),
                "output_dirs": output_dirs_meta,
                "report_csv": str(report_path),
                "tab3_metadata_csv": str(tab3_meta_stamp) if tab3_meta_stamp else None,
                "tab3_metadata_latest": str(tab3_meta_latest) if tab3_meta_latest else None,
                "tab3_metadata_rows": int(tab3_meta_rows),
                "sample_summary": {
                    "success": sample_success,
                    "partial": sample_partial,
                    "skipped": sample_skip,
                    "failed": sample_fail,
                },
                "mode_summary": {
                    m: {"ok": mode_ok_count[m], "skip": mode_skip_count[m], "fail": mode_fail_count[m]}
                    for m in selected_modes
                },
                "versions": {
                    "numpy": np.__version__,
                    "pandas": pd.__version__,
                    "pyFAI": getattr(pyFAI, "__version__", "unknown"),
                    "fabio": getattr(fabio, "__version__", "unknown"),
                },
            }
            with open(meta_path, "w", encoding="utf-8") as f:
                json.dump(meta, f, indent=2, ensure_ascii=False)

            mode_summary = "\n".join(
                [f"{m}: æˆåŠŸ{mode_ok_count[m]} / è·³è¿‡{mode_skip_count[m]} / å¤±è´¥{mode_fail_count[m]}" for m in selected_modes]
            )
            dir_lines = []
            for m in selected_modes:
                if m != "1d_sector":
                    dir_lines.append(f"{m} -> {save_dirs[m]}")
                    continue
                if sector_save_each:
                    if len(sector_specs) > 1:
                        dir_lines.append(f"1d_sector(each) -> {save_dirs[m]}/sector_*")
                    else:
                        dir_lines.append(f"1d_sector(each) -> {save_dirs[m]}")
                if sector_save_combined and sector_combined_dir is not None:
                    dir_lines.append(f"1d_sector_sum -> {sector_combined_dir}")
            dir_summary = "\n".join(dir_lines)

            messagebox.showinfo(
                "æ‰¹å¤„ç†å®Œæˆ",
                (
                    "ç¨³å¥æ‰¹å¤„ç†å®Œæˆã€‚\n"
                    f"æ ·å“æˆåŠŸ: {sample_success}\n"
                    f"æ ·å“éƒ¨åˆ†æˆåŠŸ: {sample_partial}\n"
                    f"æ ·å“å·²è·³è¿‡: {sample_skip}\n"
                    f"æ ·å“å¤±è´¥: {sample_fail}\n"
                    f"æ¨¡å¼ç»Ÿè®¡:\n{mode_summary}\n"
                    f"è¾“å‡ºç›®å½•:\n{dir_summary}\n"
                    f"æŠ¥å‘Š: {report_path.name}\n"
                    f"Tab3 metadata: {tab3_meta_stamp.name if tab3_meta_stamp else 'å¯¼å‡ºå¤±è´¥'}\n"
                    f"å…ƒæ•°æ®: {meta_path.name}"
                ),
            )

        except Exception as e:
            self.show_error("msg_batch_error_title", f"{e}\n{traceback.format_exc()}")

    # --- Helpers ---
    def refresh_queue_status(self):
        if hasattr(self, "t2_queue_info"):
            total = len(getattr(self, "t2_files", []))
            uniq = len(dict.fromkeys(getattr(self, "t2_files", [])))
            self.t2_queue_info.set(self._fmt_queue_info(total, uniq))

        if hasattr(self, "t2_out_hint_var"):
            modes = self.get_selected_modes()
            if not modes:
                self.t2_out_hint_var.set(self.tr("out_none_mode"))
            else:
                dirs = []
                for m in modes:
                    if m != "1d_sector":
                        dirs.append(f"processed_robust_{m}")
                        continue
                    dirs.append("processed_robust_1d_sector")
                    if hasattr(self, "t2_sector_save_combined") and self.t2_sector_save_combined.get():
                        dirs.append("processed_robust_1d_sector_combined")
                sec_note = ""
                if "1d_sector" in modes:
                    try:
                        n_sec = len(self.get_t2_sector_specs())
                        sec_note = f"ï¼ˆæ‰‡åŒºæ•°={n_sec}ï¼‰"
                    except Exception:
                        sec_note = "ï¼ˆæ‰‡åŒºé…ç½®å¾…ç¡®è®¤ï¼‰"
                custom_root = self.t2_output_root.get().strip() if hasattr(self, "t2_output_root") else ""
                if custom_root:
                    self.t2_out_hint_var.set(
                        f"{self.tr('out_write_prefix')} {custom_root}: {', '.join(dirs)}{sec_note}"
                    )
                else:
                    self.t2_out_hint_var.set(f"{self.tr('out_auto_prefix')}: {', '.join(dirs)}{sec_note}")

    def _evaluate_preflight_gate(self, total_files, failed_files, warnings_count, risky_files=0):
        if evaluate_preflight_gate is not None:
            return evaluate_preflight_gate(
                total_files=total_files,
                failed_files=failed_files,
                warning_count=warnings_count,
                risky_files=risky_files,
            )

        score = int(failed_files) * 5 + int(risky_files) * 2 + int(warnings_count)
        if int(total_files) <= 0 or int(failed_files) > 0:
            level = "BLOCKED"
        elif score > 0:
            level = "CAUTION"
        else:
            level = "READY"
        return SimpleNamespace(
            level=level,
            score=score,
            total_files=int(total_files),
            failed_files=int(failed_files),
            warning_count=int(warnings_count),
            risky_files=int(risky_files),
        )

    def _preflight_label_text(self, gate):
        if self.language == "en":
            return (
                f"Preflight Gate: {gate.level} | score={gate.score} | "
                f"files={gate.total_files}, failed={gate.failed_files}, "
                f"warnings={gate.warning_count}, risky={gate.risky_files}"
            )
        return (
            f"é¢„æ£€å…³å¡: {gate.level} | score={gate.score} | "
            f"æ–‡ä»¶={gate.total_files}, å¤±è´¥={gate.failed_files}, "
            f"è­¦å‘Š={gate.warning_count}, é£é™©={gate.risky_files}"
        )

    def dry_run(self):
        if not self.t2_files: return
        files = list(dict.fromkeys(self.t2_files))
        rows = []
        failed_files = 0
        risky_files = 0
        mu = self.t2_mu.get()
        monitor_mode = self.get_monitor_mode()
        mode = self.t2_calc_mode.get()
        selected_modes = self.get_selected_modes()
        warnings = []
        inst_issues = []
        sample_norms = []
        bg_norm = self.compute_norm_factor(
            self.global_vars["bg_exp"].get(),
            self.global_vars["bg_i0"].get(),
            self.global_vars["bg_t"].get(),
            monitor_mode,
        )

        if not selected_modes:
            warnings.append(self.tr("warn_no_integ_mode"))
        sector_specs = []
        if "1d_sector" in selected_modes:
            try:
                sector_specs = self.get_t2_sector_specs()
                if not self.t2_sector_save_each.get() and not self.t2_sector_save_combined.get():
                    warnings.append(self.tr("warn_sector_no_output"))
            except Exception as e:
                warnings.append(self.tr("warn_sector_angle_invalid").format(e=e))
        if "radial_chi" in selected_modes and self.t2_rad_qmin.get() >= self.t2_rad_qmax.get():
            warnings.append(self.tr("warn_texture_q_invalid"))
        if mode == "auto" and mu <= 0:
            warnings.append(self.tr("warn_auto_thk_mu"))
        if self.t2_calc_mode.get() == "fixed" and self.t2_fixed_thk.get() <= 0:
            warnings.append(self.tr("warn_fix_thk_le_zero"))
        if self.t2_ref_mode.get() == "auto":
            if not self.t2_bg_candidates:
                warnings.append(self.tr("warn_auto_bg_empty"))
            if not self.t2_dark_candidates:
                warnings.append(self.tr("warn_auto_dark_empty"))
        if self.t2_strict_instrument.get():
            inst_issues = self.check_instrument_consistency(
                files,
                poni_path=self.global_vars["poni_path"].get(),
                tol_pct=self.t2_instr_tol_pct.get(),
            )
            if inst_issues:
                warnings.append(self.tr("warn_inst_issues").format(n=len(inst_issues)))

        bg_library = self.build_reference_library(self.t2_bg_candidates) if self.t2_ref_mode.get() == "auto" else []
        dark_library = self.build_reference_library(self.t2_dark_candidates) if self.t2_ref_mode.get() == "auto" else []

        for fp in files:
            e, m, t = self.parse_header(fp)
            stat = self.tr("status_ok")
            d_mm = np.nan
            bg_match = "-"
            dark_match = "-"

            missing = []
            if m is None:
                missing.append("MON")
            if t is None:
                missing.append("T")
            if monitor_mode == "rate" and e is None:
                missing.append("EXP")

            if missing:
                stat = f"Missing header fields: {','.join(missing)}" if self.language == "en" else f"ç¼ºå°‘æ–‡ä»¶å¤´å­—æ®µ: {','.join(missing)}"
            else:
                if e is not None:
                    e = float(e)
                m = float(m)
                t = float(t)
                n = self.compute_norm_factor(e if e is not None else None, m, t, monitor_mode)
                if np.isfinite(n) and n > 0:
                    sample_norms.append(float(n))
                if monitor_mode == "rate" and e <= 0:
                    stat = "Error: EXP <= 0" if self.language == "en" else "é”™è¯¯: EXP <= 0"
                elif m <= 0:
                    stat = "Error: MON <= 0" if self.language == "en" else "é”™è¯¯: MON <= 0"
                elif not (0 < t <= 1):
                    stat = "Error: T outside (0,1]" if self.language == "en" else "é”™è¯¯: T è¶…å‡º (0,1]"
                elif mode == "auto":
                    if mu <= 0:
                        stat = "Error: MU <= 0" if self.language == "en" else "é”™è¯¯: MU <= 0"
                    elif t >= 0.999 or t <= 0.001:
                        stat = "Error: T unsuitable for auto-thickness" if self.language == "en" else "é”™è¯¯: T ä¸é€‚åˆè‡ªåŠ¨åšåº¦"
                    else:
                        d_mm = (-math.log(t) / mu) * 10.0
                else:
                    d_mm = self.t2_fixed_thk.get()

            if self.t2_ref_mode.get() == "auto":
                try:
                    img = fabio.open(fp)
                    smeta = {
                        "exp": e if (e is not None and np.isfinite(e)) else None,
                        "mon": m if m is not None else None,
                        "trans": t if t is not None else None,
                        "mtime": Path(fp).stat().st_mtime if Path(fp).exists() else None,
                        "shape": tuple(img.data.shape),
                    }
                    bg_ref, _ = self.select_best_reference(smeta, bg_library, kind="bg")
                    dk_ref, _ = self.select_best_reference(smeta, dark_library, kind="dark")
                    bg_match = Path(bg_ref["path"]).name if bg_ref else self.tr("status_no_match")
                    dark_match = Path(dk_ref["path"]).name if dk_ref else self.tr("status_no_match")
                    if bg_ref is None or dk_ref is None:
                        risky_files += 1
                except Exception:
                    bg_match = self.tr("status_match_fail")
                    dark_match = self.tr("status_match_fail")
                    risky_files += 1

            if stat != self.tr("status_ok"):
                failed_files += 1

            rows.append({
                "File": Path(fp).name,
                "Exp_s": e if e is not None else np.nan,
                "Mon": m if m is not None else np.nan,
                "Trans": t if t is not None else np.nan,
                "CalcThk_mm": round(d_mm, 4) if np.isfinite(d_mm) else np.nan,
                "BG_Match": bg_match,
                "Dark_Match": dark_match,
                "Status": stat,
            })

        if np.isfinite(bg_norm) and bg_norm > 0 and sample_norms:
            med_sample_norm = float(np.nanmedian(np.asarray(sample_norms, dtype=np.float64)))
            if np.isfinite(med_sample_norm) and med_sample_norm > 0:
                ratio = bg_norm / med_sample_norm
                if ratio < 0.01 or ratio > 100.0:
                    warnings.append(
                        self.tr("warn_bg_norm_mismatch").format(
                            ratio=ratio, bg_norm=bg_norm, med=med_sample_norm,
                        )
                    )

        gate = self._evaluate_preflight_gate(
            total_files=len(files),
            failed_files=failed_files,
            warnings_count=len(warnings),
            risky_files=risky_files,
        )
        
        top = tk.Toplevel(self.root)
        top.title(self.tr("title_t2_dryrun"))
        txt = tk.Text(top, font=("Consolas",9)); txt.pack(fill="both", expand=True)
        self._register_native_widget(txt)
        txt.insert(tk.END, f"{self._preflight_label_text(gate)}\n")
        txt.insert(tk.END, f"{self.tr('pre_i0_norm')} {monitor_mode} (norm={self.monitor_norm_formula(monitor_mode)})\n")
        txt.insert(tk.END, f"{self.tr('pre_integ_mode')} {','.join(selected_modes) if selected_modes else self.tr('pre_integ_none')}\n")
        if "1d_sector" in selected_modes:
            txt.insert(
                tk.END,
                f"{self.tr('pre_sector_output')} each={'ON' if self.t2_sector_save_each.get() else 'OFF'}, "
                f"sum={'ON' if self.t2_sector_save_combined.get() else 'OFF'}\n",
            )
            if sector_specs:
                sec_short = "; ".join([f"{s['index']}:{s['label']}" for s in sector_specs[:8]])
                if len(sector_specs) > 8:
                    sec_short += "; ..."
                txt.insert(tk.END, f"{self.tr('pre_sector_list')} {sec_short}\n")
        txt.insert(tk.END, f"{self.tr('pre_ref_mode')} {self.t2_ref_mode.get()}\n")
        txt.insert(tk.END, f"{self.tr('pre_error_model')} {self.t2_error_model.get()}\n")
        txt.insert(tk.END, f"{self.tr('pre_workers')} {self.t2_workers.get()}\n")
        txt.insert(tk.END, "-"*80 + "\n")
        if warnings:
            txt.insert(tk.END, f"{self.tr('pre_warning_header')}\n")
            for w in warnings:
                txt.insert(tk.END, f"- {w}\n")
            if inst_issues:
                for issue in inst_issues[:20]:
                    txt.insert(tk.END, f"  * {issue}\n")
                if len(inst_issues) > 20:
                    txt.insert(tk.END, "  * ...\n")
        else:
            txt.insert(tk.END, f"{self.tr('pre_pass_t2')}\n")
        txt.insert(tk.END, "-"*80 + "\n")
        txt.insert(tk.END, pd.DataFrame(rows).to_string(index=False))

    def get_t2_preview_sample_path(self):
        # ä¼˜å…ˆä½¿ç”¨åˆ—è¡¨å½“å‰é€‰ä¸­é¡¹ï¼›æœªé€‰ä¸­æ—¶ä½¿ç”¨é˜Ÿåˆ—ç¬¬ä¸€ä¸ªï¼›ä»ä¸ºç©ºåˆ™å¼¹æ–‡ä»¶é€‰æ‹©ã€‚
        try:
            sel = self.lb_batch.curselection() if hasattr(self, "lb_batch") else ()
            if sel:
                idx = int(sel[0])
                if 0 <= idx < len(self.t2_files):
                    return self.t2_files[idx]
        except Exception:
            pass

        if getattr(self, "t2_files", None):
            fs = list(dict.fromkeys(self.t2_files))
            if fs:
                return fs[0]

        return filedialog.askopenfilename(
            filetypes=[("Image", "*.tif *.tiff *.edf *.cbf"), ("All Files", "*.*")]
        )

    def _compute_t2_chi_map_deg(self, ai, shape):
        # ä¸ pyFAI azimuth_range å®šä¹‰ä¸€è‡´ï¼š0Â°å³ã€+90Â°ä¸‹ã€-90Â°ä¸Šã€Â±180Â°å·¦
        try:
            chi_rad = np.asarray(ai.center_array(shape, unit="chi_rad"), dtype=np.float64)
        except Exception:
            chi_rad = np.asarray(ai.chiArray(shape), dtype=np.float64)
        chi_deg = np.rad2deg(chi_rad)
        chi_deg = ((chi_deg + 180.0) % 360.0) - 180.0
        return chi_deg

    def _compute_t2_q_map_a_inv(self, ai, shape):
        # ä¼˜å…ˆæ˜¾å¼ A^-1ï¼›æ—§ç‰ˆå…¼å®¹é€€å› qArray(nm^-1) å† /10ã€‚
        try:
            q_map = np.asarray(ai.center_array(shape, unit="q_A^-1"), dtype=np.float64)
            return q_map, "q_A^-1"
        except Exception:
            q_map = np.asarray(ai.qArray(shape), dtype=np.float64) / 10.0
            return q_map, "q_nm^-1/10"

    def _get_t2_preview_context(self):
        sample_path = self.get_t2_preview_sample_path()
        if not sample_path:
            return None

        poni_path = self.global_vars["poni_path"].get().strip()
        if not poni_path:
            raise ValueError("è¯·å…ˆåœ¨ Tab1/Tab2 è®¾ç½® poni æ–‡ä»¶ã€‚")

        ai = pyFAI.load(poni_path)
        data = fabio.open(sample_path).data.astype(np.float64)
        if data.ndim != 2:
            raise ValueError(f"æ ·å“å›¾åƒç»´åº¦é”™è¯¯: {data.shape}")

        valid_mask = np.isfinite(data)
        mask_path = self.t2_mask_path.get().strip() if hasattr(self, "t2_mask_path") else ""
        if mask_path:
            mask_arr = np.asarray(self.load_optional_array(mask_path, "Mask")) != 0
            if mask_arr.shape != data.shape:
                raise ValueError(f"Mask å°ºå¯¸ä¸åŒ¹é…: mask{mask_arr.shape} vs image{data.shape}")
            valid_mask &= ~mask_arr

        finite = data[valid_mask]
        if finite.size == 0:
            raise ValueError("å¯ç”¨å›¾åƒåƒç´ ä¸ºç©ºï¼ˆå¯èƒ½è¢« mask å…¨éƒ¨å±è”½ï¼‰ã€‚")

        lo = float(np.nanpercentile(finite, 1.0))
        hi = float(np.nanpercentile(finite, 99.5))
        if not np.isfinite(lo) or not np.isfinite(hi) or hi <= lo:
            lo = float(np.nanmin(finite))
            hi = float(np.nanmax(finite))
            if hi <= lo:
                hi = lo + 1.0
        show_img = np.clip(data, lo, hi)
        show_img = np.where(np.isfinite(show_img), show_img, lo)

        try:
            cy = float(ai.poni1 / ai.pixel1)
            cx = float(ai.poni2 / ai.pixel2)
            if not (np.isfinite(cy) and np.isfinite(cx)):
                raise ValueError("center invalid")
        except Exception:
            cy = (data.shape[0] - 1) / 2.0
            cx = (data.shape[1] - 1) / 2.0

        return {
            "sample_path": sample_path,
            "ai": ai,
            "data": data,
            "valid_mask": valid_mask,
            "show_img": show_img,
            "cx": cx,
            "cy": cy,
        }

    def preview_iq_window_t2(self):
        try:
            ctx = self._get_t2_preview_context()
            if ctx is None:
                return

            use_sector = bool(self.t2_mode_sector.get())
            sector_specs = []
            chi_deg = None

            if use_sector:
                sector_specs = self.get_t2_sector_specs()
                chi_deg = self._compute_t2_chi_map_deg(ctx["ai"], ctx["data"].shape)
                iq_mask = np.zeros_like(ctx["valid_mask"], dtype=bool)
                for spec in sector_specs:
                    m, _, _, _ = self.build_sector_mask(chi_deg, spec["sec_min"], spec["sec_max"])
                    iq_mask |= m
                iq_mask = iq_mask & ctx["valid_mask"]
                sec_desc = "; ".join([f"S{s['index']}{s['label']}" for s in sector_specs[:6]])
                if len(sector_specs) > 6:
                    sec_desc += "; ..."
                mode_desc = self.tr("info_iq_sector").format(n=len(sector_specs), desc=sec_desc)
            else:
                iq_mask = np.asarray(ctx["valid_mask"], dtype=bool)
                mode_desc = self.tr("info_iq_full")

            if not np.any(iq_mask):
                raise ValueError("I-Q é¢„è§ˆåŒºåŸŸä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ‰‡åŒºèŒƒå›´æˆ– maskã€‚")

            top = tk.Toplevel(self.root)
            top.title(self.tr("title_iq_preview").format(name=Path(ctx['sample_path']).name))
            info = ttk.Label(
                top,
                text=(
                    self.tr("info_iq_line1").format(name=Path(ctx['sample_path']).name, mode=mode_desc, pct=np.mean(iq_mask)*100) + "\n"
                    + self.tr("info_iq_line2")
                ),
                justify="left",
                style="Hint.TLabel",
            )
            info.pack(fill="x", padx=8, pady=(8, 4))

            fig = Figure(figsize=(7.2, 6.0), dpi=100)
            ax = fig.add_subplot(111)
            im = ax.imshow(ctx["show_img"], cmap="gray", origin="upper", interpolation="nearest")
            ov = np.ma.masked_where(~iq_mask, np.ones_like(ctx["show_img"]))
            ax.imshow(ov, cmap="autumn", origin="upper", interpolation="nearest", alpha=0.28, vmin=0.0, vmax=1.0)

            ax.plot(ctx["cx"], ctx["cy"], marker="+", color="cyan", ms=12, mew=2, label="Beam center")
            if use_sector:
                ray_len = float(max(ctx["data"].shape) * 0.75)
                palette = [
                    "#00d1ff", "#ff4d4d", "#3cb371", "#ff8c00", "#9370db",
                    "#ffd700", "#20b2aa", "#dc143c", "#1e90ff", "#8b4513",
                ]
                for i, spec in enumerate(sector_specs):
                    color = palette[i % len(palette)]
                    for j, ang_deg in enumerate([spec["sec_min"], spec["sec_max"]]):
                        ang = math.radians(float(ang_deg))
                        x2 = ctx["cx"] + math.cos(ang) * ray_len
                        y2 = ctx["cy"] + math.sin(ang) * ray_len
                        lbl = None
                        if j == 0 and i < 8:
                            lbl = f"S{spec['index']} {spec['label']}"
                        ax.plot(
                            [ctx["cx"], x2],
                            [ctx["cy"], y2],
                            color=color,
                            lw=1.5,
                            ls="-" if j == 0 else "--",
                            label=lbl,
                        )

            ax.set_title(self.tr("info_iq_title"))
            ax.set_xlabel("Pixel X")
            ax.set_ylabel("Pixel Y")
            ax.legend(loc="upper right", fontsize=8)

            cb = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
            cb.set_label("Intensity (clipped)")

            canvas = FigureCanvasTkAgg(fig, master=top)
            canvas.get_tk_widget().pack(fill="both", expand=True, padx=8, pady=6)
            canvas.draw()
            toolbar = NavigationToolbar2Tk(canvas, top)
            toolbar.update()

        except Exception as e:
            self.show_error("msg_iq_preview_error_title", f"{e}\n{traceback.format_exc()}")

    def preview_ichi_window_t2(self):
        try:
            ctx = self._get_t2_preview_context()
            if ctx is None:
                return

            qmin = float(self.t2_rad_qmin.get())
            qmax = float(self.t2_rad_qmax.get())
            if not (np.isfinite(qmin) and np.isfinite(qmax) and qmin < qmax):
                raise ValueError("I-chi é¢„è§ˆ q èŒƒå›´æ— æ•ˆï¼šqmin å¿…é¡» < qmaxã€‚")

            q_map, q_src = self._compute_t2_q_map_a_inv(ctx["ai"], ctx["data"].shape)
            q_mask = np.isfinite(q_map) & (q_map >= qmin) & (q_map <= qmax) & ctx["valid_mask"]
            if not np.any(q_mask):
                raise ValueError("I-chi q ç¯å¸¦ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ q èŒƒå›´ã€poni æˆ– maskã€‚")

            top = tk.Toplevel(self.root)
            top.title(self.tr("title_ichi_preview").format(name=Path(ctx['sample_path']).name))
            info = ttk.Label(
                top,
                text=(
                    self.tr("info_ichi_line1").format(name=Path(ctx['sample_path']).name, qmin=qmin, qmax=qmax, pct=np.mean(q_mask)*100) + "\n"
                    + self.tr("info_ichi_line2").format(src=q_src)
                ),
                justify="left",
                style="Hint.TLabel",
            )
            info.pack(fill="x", padx=8, pady=(8, 4))

            fig = Figure(figsize=(7.2, 6.0), dpi=100)
            ax = fig.add_subplot(111)
            im = ax.imshow(ctx["show_img"], cmap="gray", origin="upper", interpolation="nearest")
            ov = np.ma.masked_where(~q_mask, np.ones_like(ctx["show_img"]))
            ax.imshow(ov, cmap="spring", origin="upper", interpolation="nearest", alpha=0.30, vmin=0.0, vmax=1.0)

            ax.plot(ctx["cx"], ctx["cy"], marker="+", color="cyan", ms=12, mew=2, label="Beam center")
            try:
                contours = ax.contour(
                    q_map,
                    levels=[qmin, qmax],
                    colors=["#00d1ff", "#ff4d4d"],
                    linewidths=1.2,
                )
                if contours is not None:
                    ax.clabel(contours, inline=True, fontsize=8, fmt=lambda v: f"{v:.3g} A^-1")
            except Exception:
                pass

            ax.set_title(self.tr("info_ichi_title"))
            ax.set_xlabel("Pixel X")
            ax.set_ylabel("Pixel Y")
            ax.legend(loc="upper right", fontsize=8)

            cb = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
            cb.set_label("Intensity (clipped)")

            canvas = FigureCanvasTkAgg(fig, master=top)
            canvas.get_tk_widget().pack(fill="both", expand=True, padx=8, pady=6)
            canvas.draw()
            toolbar = NavigationToolbar2Tk(canvas, top)
            toolbar.update()

        except Exception as e:
            self.show_error("msg_ichi_preview_error_title", f"{e}\n{traceback.format_exc()}")

    def preview_sector_window_t2(self):
        # å…¼å®¹æ—§æŒ‰é’®/æ—§è°ƒç”¨å…¥å£ï¼šè½¬åˆ° I-Q é¢„è§ˆ
        self.preview_iq_window_t2()

    def open_mu_tool(self):
        top = tk.Toplevel(self.root)
        top.title(self.tr("title_mu_tool"))
        top.geometry("520x480")

        # --- Energy / wavelength ---
        frm_energy = ttk.LabelFrame(top, text=self.tr("lbl_mu_energy"))
        frm_energy.pack(fill="x", padx=8, pady=4)

        energy_var = tk.DoubleVar(value=30.0)
        wl_var = tk.DoubleVar(value=round(HC_KEV_A / 30.0, 4))

        def _sync_wl(*_a):
            try:
                e = energy_var.get()
                if e > 0:
                    wl_var.set(round(HC_KEV_A / e, 4))
            except Exception:
                pass

        def _sync_energy(*_a):
            try:
                w = wl_var.get()
                if w > 0:
                    energy_var.set(round(HC_KEV_A / w, 4))
            except Exception:
                pass

        row_e = ttk.Frame(frm_energy); row_e.pack(fill="x", pady=2)
        ttk.Label(row_e, text="E (keV):").pack(side="left", padx=4)
        e_energy = ttk.Entry(row_e, textvariable=energy_var, width=10)
        e_energy.pack(side="left")
        e_energy.bind("<FocusOut>", _sync_wl)
        ttk.Label(row_e, text=self.tr("lbl_mu_energy_or_wl")).pack(side="left", padx=(12, 4))
        e_wl = ttk.Entry(row_e, textvariable=wl_var, width=10)
        e_wl.pack(side="left")
        e_wl.bind("<FocusOut>", _sync_energy)

        # Try to auto-fill from PONI wavelength
        try:
            poni_path = self.global_vars["poni_path"].get()
            if poni_path:
                ai = pyFAI.load(poni_path)
                wl_m = ai.wavelength  # metres
                wl_A = wl_m * 1e10
                e_keV = HC_KEV_A / wl_A
                energy_var.set(round(e_keV, 4))
                wl_var.set(round(wl_A, 4))
        except Exception:
            pass

        # --- Material preset ---
        frm_mat = ttk.LabelFrame(top, text=self.tr("lbl_mu_preset"))
        frm_mat.pack(fill="x", padx=8, pady=4)

        preset_keys = list(MATERIAL_PRESETS.keys()) if MATERIAL_PRESETS else []
        preset_names = [MATERIAL_PRESETS[k][0] for k in preset_keys] if MATERIAL_PRESETS else []
        preset_var = tk.StringVar(value=preset_names[0] if preset_names else "")
        cb_preset = ttk.Combobox(frm_mat, values=preset_names, textvariable=preset_var, width=30, state="readonly")
        cb_preset.pack(side="left", padx=4, pady=4)
        if preset_names:
            cb_preset.current(0)

        # --- Density ---
        rho_var = tk.DoubleVar(value=4.43)
        row_rho = ttk.Frame(frm_mat); row_rho.pack(fill="x", pady=2)
        ttk.Label(row_rho, text=self.tr("lbl_mu_density")).pack(side="left", padx=4)
        e_rho = ttk.Entry(row_rho, textvariable=rho_var, width=8)
        e_rho.pack(side="left")

        # --- Custom composition ---
        frm_comp = ttk.LabelFrame(top, text=self.tr("lbl_mu_custom_comp"))
        frm_comp.pack(fill="x", padx=8, pady=4)

        comp_var = tk.StringVar(value="")
        ttk.Label(frm_comp, text="e.g. Fe:0.69, Cr:0.19, Ni:0.10").pack(anchor="w", padx=4)
        e_comp = ttk.Entry(frm_comp, textvariable=comp_var, width=50)
        e_comp.pack(fill="x", padx=4, pady=2)

        def _fill_from_preset(*_a):
            sel = preset_var.get()
            for k in preset_keys:
                if MATERIAL_PRESETS[k][0] == sel:
                    comp_dict = MATERIAL_PRESETS[k][1]
                    rho_var.set(MATERIAL_PRESETS[k][2])
                    comp_var.set(", ".join(f"{el}:{w}" for el, w in comp_dict.items()))
                    break
        cb_preset.bind("<<ComboboxSelected>>", _fill_from_preset)
        _fill_from_preset()  # initialize

        # --- Result display ---
        frm_res = ttk.LabelFrame(top, text=self.tr("lbl_mu_contrib"))
        frm_res.pack(fill="both", expand=True, padx=8, pady=4)

        result_text = tk.Text(frm_res, height=8, width=55, state="disabled", font=("Consolas", 9))
        result_text.pack(fill="both", expand=True, padx=4, pady=4)
        self._register_native_widget(result_text)

        def do_calc():
            try:
                e_keV = energy_var.get()
                rho = rho_var.get()
                comp_str = comp_var.get().strip()
                if not comp_str:
                    raise ValueError("è¯·è¾“å…¥æˆåˆ†æˆ–é€‰æ‹©é¢„è®¾ææ–™ã€‚")
                if calculate_mu is None:
                    raise ImportError("xraydb æœªå®‰è£…ï¼Œæ— æ³•è®¡ç®—ã€‚")

                comp = parse_composition_string(comp_str)
                res = calculate_mu(comp, rho, e_keV)

                result_text.config(state="normal")
                result_text.delete("1.0", "end")
                result_text.insert("end", f"Energy: {e_keV:.2f} keV  |  Ï = {rho:.3f} g/cmÂ³\n")
                result_text.insert("end", f"Î¼/Ï(mix) = {res.mu_rho_cm2_g:.4f} cmÂ²/g\n")
                result_text.insert("end", f"Î¼_linear = {res.mu_linear_cm_inv:.4f} cmâ»Â¹\n")
                result_text.insert("end", "-" * 40 + "\n")
                result_text.insert("end", f"{'Element':<8} {'wt-frac':<10} {'Î¼/Ï':<12} {'Contrib.':<12}\n")
                for el, contrib in res.element_contributions.items():
                    wf = res.composition.get(el, 0)
                    murho_i = contrib / wf if wf > 0 else 0
                    result_text.insert("end", f"{el:<8} {wf:<10.4f} {murho_i:<12.4f} {contrib:<12.4f}\n")
                result_text.config(state="disabled")

                self.t2_mu.set(round(res.mu_linear_cm_inv, 2))
            except Exception as exc:
                self.show_error("msg_input_error_title", self.tr("msg_mu_fail").format(e=exc))

        ttk.Button(top, text=self.tr("btn_mu_apply"), command=do_calc).pack(pady=8)

    def add_file_row(self, p, l, v, pat, cmd=None):
        f = ttk.Frame(p); f.pack(fill="x", pady=3)
        lbl = ttk.Label(f, text=l, width=16, anchor="e")
        lbl.pack(side="left", padx=(0, 6))
        ent = ttk.Entry(f, textvariable=v)
        ent.pack(side="left", fill="x", expand=True, padx=(0, 4))
        def b():
            fp = filedialog.askopenfilename(filetypes=[("File", pat)])
            if fp: v.set(fp); cmd(fp) if cmd else None
        btn = ttk.Button(f, text="...", width=3, command=b)
        btn.pack(side="left")
        return {"frame": f, "label": lbl, "entry": ent, "button": btn}

    def add_dir_row(self, p, l, v):
        f = ttk.Frame(p); f.pack(fill="x", pady=3)
        lbl = ttk.Label(f, text=l, width=16, anchor="e")
        lbl.pack(side="left", padx=(0, 6))
        ent = ttk.Entry(f, textvariable=v)
        ent.pack(side="left", fill="x", expand=True, padx=(0, 4))
        def b():
            dp = filedialog.askdirectory()
            if dp:
                v.set(dp)
        btn = ttk.Button(f, text="...", width=3, command=b)
        btn.pack(side="left")
        return {"frame": f, "label": lbl, "entry": ent, "button": btn}

    def add_grid_entry(self, p, v, r, c):
        e = ttk.Entry(p, textvariable=v, width=8, justify="center")
        e.grid(row=r, column=c, padx=3, pady=3)
        return e

    def _on_std_type_changed(self, event=None):
        """Show/hide water temp and ref-curve rows based on standard selection."""
        sel_text = self.t1_std_combo.get()
        key = self._t1_std_option_map.get(sel_text, "SRM3600")
        self.t1_std_type.set(key)

        # Hide both conditional rows first
        self.t1_water_row.pack_forget()
        self.t1_ref_row["frame"].pack_forget()

        if key == "Water_20C":
            # Show water temperature entry, hide standard file row
            self.t1_water_row.pack(fill="x", pady=1, before=self.t1_ref_row["frame"])
        elif key in ("Lupolen", "Custom"):
            # Show reference curve file row
            self.t1_ref_row["frame"].pack(fill="x", pady=1)

    def _get_std_reference_data(self):
        """Return (q_ref, i_ref) based on the current standard selection.

        For SRM3600: built-in 15-point curve.
        For Water: flat curve at user-specified temperature.
        For Lupolen/Custom: load from user-supplied file.
        """
        key = self.t1_std_type.get()

        if get_reference_data is not None:
            if key in ("Lupolen", "Custom"):
                ref_path = self.t1_std_ref_path.get()
                if not ref_path:
                    raise ValueError("è¯·é€‰æ‹©æ ‡å‡†å‚è€ƒæ›²çº¿æ–‡ä»¶ã€‚")
                from saxsabs.io.parsers import read_external_1d_profile
                prof = read_external_1d_profile(ref_path)
                q_user = prof["x"]
                i_user = prof["i_rel"]
                return get_reference_data(key, q_user=q_user, i_user=i_user)
            elif key == "Water_20C":
                temp_c = self.t1_water_temp.get()
                return get_reference_data(key, temperature_C=temp_c)
            else:
                return get_reference_data(key)
        else:
            # Fallback: only SRM3600 available
            return NIST_SRM3600_DATA[:, 0], NIST_SRM3600_DATA[:, 1]

    def on_load_std_t1(self, fp):
        e, m, t = self.parse_header(fp)
        if e is not None: self.t1_params["std_exp"].set(e)
        if m is not None: self.t1_params["std_i0"].set(m)
        if t is not None: self.t1_params["std_t"].set(t)
    def on_load_bg_t1(self, fp):
        e, m, t = self.parse_header(fp)
        if e is not None: self.t1_params["bg_exp"].set(e)
        if m is not None: self.t1_params["bg_i0"].set(m)
        if t is not None: self.t1_params["bg_t"].set(t)

    def select_multi_bg_t1(self):
        fs = filedialog.askopenfilenames(filetypes=[("Image", "*.tif *.tiff *.edf *.cbf")])
        if not fs:
            return
        self.global_vars["bg_path"].set(";".join(fs))
        self.on_load_bg_t1(fs[0])

    def add_batch_files(self):
        fs = filedialog.askopenfilenames(filetypes=[("TIFF", "*.tif *.tiff")])
        for f in fs:
            if f not in self.t2_files:
                self.t2_files.append(f)
                self.lb_batch.insert(tk.END, Path(f).name)
        self.refresh_queue_status()
    def clear_batch_files(self):
        self.t2_files = []; self.lb_batch.delete(0, tk.END)
        self.refresh_queue_status()

    def apply_session(self, session_path: str):
        try:
            sess = load_session(session_path)
        except Exception as e:
            self.show_error("session_error_title", self.tr("session_error_body").format(err=e))
            return

        notes = []
        geom = session_geometry(sess)
        if geom:
            px_mm = geom.get("px_mm")
            wl_a = geom.get("wl_A")
            dist_mm = geom.get("dist_mm")
            self.session_geometry_fallback = {
                "wavelength_a": float(wl_a) if wl_a is not None else None,
                "distance_m": (float(dist_mm) / 1000.0) if dist_mm is not None else None,
                "pixel1_m": (float(px_mm) / 1000.0) if px_mm is not None else None,
                "pixel2_m": (float(px_mm) / 1000.0) if px_mm is not None else None,
                "energy_kev": (HC_KEV_A / float(wl_a)) if (wl_a is not None and float(wl_a) > 0) else None,
            }
            notes.append("Session geometry loaded (used as consistency fallback when headers are missing).")

        # Optional calibration paths from session payload (forward-compatible)
        cal = sess.get("calibration", {}) if isinstance(sess.get("calibration", {}), dict) else {}
        candidate_paths = {
            "poni": str(cal.get("poni_path", sess.get("poni_path", ""))).strip(),
            "bg": str(cal.get("bg_path", sess.get("bg_path", ""))).strip(),
            "dark": str(cal.get("dark_path", sess.get("dark_path", ""))).strip(),
            "std": str(cal.get("std_path", sess.get("std_path", ""))).strip(),
        }
        if candidate_paths["poni"] and Path(candidate_paths["poni"]).is_file():
            self.global_vars["poni_path"].set(candidate_paths["poni"])
            notes.append(f"PONI loaded from session: {Path(candidate_paths['poni']).name}")
        if candidate_paths["bg"] and Path(candidate_paths["bg"]).is_file():
            self.global_vars["bg_path"].set(candidate_paths["bg"])
            notes.append(f"Background loaded from session: {Path(candidate_paths['bg']).name}")
        if candidate_paths["dark"] and Path(candidate_paths["dark"]).is_file():
            self.global_vars["dark_path"].set(candidate_paths["dark"])
            notes.append(f"Dark loaded from session: {Path(candidate_paths['dark']).name}")
        if candidate_paths["std"] and Path(candidate_paths["std"]).is_file():
            self.t1_files["std"].set(candidate_paths["std"])
            self.on_load_std_t1(candidate_paths["std"])
            notes.append(f"Std image loaded from session std_path: {Path(candidate_paths['std']).name}")

        data_path = str(sess.get("data_path", "")).strip()
        if data_path:
            p = Path(data_path)
            if p.is_file() and p.suffix.lower() in (".tif", ".tiff"):
                self.t1_files["std"].set(str(p))
                self.on_load_std_t1(str(p))
                notes.append(f"Std image loaded from session: {p.name}")
            elif p.is_file():
                notes.append(f"Session data is not TIFF, skipped for Std: {p.name}")
            else:
                notes.append(f"Session data path not found: {data_path}")

        if not notes:
            notes.append("Session loaded.")
        self.show_info("session_loaded_title", "\n".join(notes))


BL19B2_RobustApp = SAXSAbsWorkbenchApp


def main(argv=None):
    parser = argparse.ArgumentParser(description=APP_NAME)
    parser.add_argument("--session", type=str, default="", help="Path to session json")
    parser.add_argument("--lang", choices=SUPPORTED_LANGUAGES, default="en", help="UI language")
    parser.add_argument("--version", action="version", version=f"%(prog)s {APP_VERSION}")
    args = parser.parse_args(argv)

    root = tk.Tk()
    app = SAXSAbsWorkbenchApp(root, language=args.lang)
    if args.session:
        root.after(80, lambda: app.apply_session(args.session))
    root.mainloop()

if __name__ == "__main__":
    main()
